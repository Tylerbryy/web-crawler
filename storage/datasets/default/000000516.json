{
	"title": "vLLM Chat | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/chat/vllm",
	"html": "ComponentsChat modelsvLLM Chat\nvLLM Chat\n\nvLLM can be deployed as a server that mimics the OpenAI API protocol. This allows vLLM to be used as a drop-in replacement for applications using OpenAI API. This server can be queried in the same format as OpenAI API.\n\nThis notebook covers how to get started with vLLM chat models using langchain's ChatOpenAI as it is.\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    HumanMessagePromptTemplate,\n    SystemMessagePromptTemplate,\n)\nfrom langchain.schema import HumanMessage, SystemMessage\n\ninference_server_url = \"http://localhost:8000/v1\"\n\nchat = ChatOpenAI(\n    model=\"mosaicml/mpt-7b\",\n    openai_api_key=\"EMPTY\",\n    openai_api_base=inference_server_url,\n    max_tokens=5,\n    temperature=0,\n)\n\nmessages = [\n    SystemMessage(\n        content=\"You are a helpful assistant that translates English to Italian.\"\n    ),\n    HumanMessage(\n        content=\"Translate the following sentence from English to Italian: I love programming.\"\n    ),\n]\nchat(messages)\n\n    AIMessage(content=' Io amo programmare', additional_kwargs={}, example=False)\n\n\nYou can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.\n\nFor convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:\n\ntemplate = (\n    \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n)\nsystem_message_prompt = SystemMessagePromptTemplate.from_template(template)\nhuman_template = \"{text}\"\nhuman_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\nchat_prompt = ChatPromptTemplate.from_messages(\n    [system_message_prompt, human_message_prompt]\n)\n\n# get a chat completion from the formatted messages\nchat(\n    chat_prompt.format_prompt(\n        input_language=\"English\", output_language=\"Italian\", text=\"I love programming.\"\n    ).to_messages()\n)\n\n    AIMessage(content=' I love programming too.', additional_kwargs={}, example=False)\n\nPrevious\nTongyi Qwen\nNext\nYandexGPT"
}