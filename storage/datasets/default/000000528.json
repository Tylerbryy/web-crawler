{
	"title": "Baseten | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/baseten",
	"html": "ComponentsLLMsBaseten\nBaseten\n\nBaseten provides all the infrastructure you need to deploy and serve ML models performantly, scalably, and cost-efficiently.\n\nThis example demonstrates using Langchain with models deployed on Baseten.\n\nSetup\n\nTo run this notebook, you'll need a Baseten account and an API key.\n\nYou'll also need to install the Baseten Python package:\n\npip install baseten\n\nimport baseten\n\nbaseten.login(\"YOUR_API_KEY\")\n\nSingle model call\n\nFirst, you'll need to deploy a model to Baseten.\n\nYou can deploy foundation models like WizardLM and Alpaca with one click from the Baseten model library or if you have your own model, deploy it with this tutorial.\n\nIn this example, we'll work with WizardLM. Deploy WizardLM here and follow along with the deployed model's version ID.\n\nfrom langchain.llms import Baseten\n\n# Load the model\nwizardlm = Baseten(model=\"MODEL_VERSION_ID\", verbose=True)\n\n# Prompt the model\n\nwizardlm(\"What is the difference between a Wizard and a Sorcerer?\")\n\nChained model calls\n\nWe can chain together multiple calls to one or multiple models, which is the whole point of Langchain!\n\nThis example uses WizardLM to plan a meal with an entree, three sides, and an alcoholic and non-alcoholic beverage pairing.\n\nfrom langchain.chains import LLMChain, SimpleSequentialChain\nfrom langchain.prompts import PromptTemplate\n\n# Build the first link in the chain\n\nprompt = PromptTemplate(\n    input_variables=[\"cuisine\"],\n    template=\"Name a complex entree for a {cuisine} dinner. Respond with just the name of a single dish.\",\n)\n\nlink_one = LLMChain(llm=wizardlm, prompt=prompt)\n\n# Build the second link in the chain\n\nprompt = PromptTemplate(\n    input_variables=[\"entree\"],\n    template=\"What are three sides that would go with {entree}. Respond with only a list of the sides.\",\n)\n\nlink_two = LLMChain(llm=wizardlm, prompt=prompt)\n\n# Build the third link in the chain\n\nprompt = PromptTemplate(\n    input_variables=[\"sides\"],\n    template=\"What is one alcoholic and one non-alcoholic beverage that would go well with this list of sides: {sides}. Respond with only the names of the beverages.\",\n)\n\nlink_three = LLMChain(llm=wizardlm, prompt=prompt)\n\n# Run the full chain!\n\nmenu_maker = SimpleSequentialChain(\n    chains=[link_one, link_two, link_three], verbose=True\n)\nmenu_maker.run(\"South Indian\")\n\nPrevious\nBanana\nNext\nBeam"
}