{
	"title": "Grobid | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/providers/grobid",
	"html": "ProvidersMoreGrobid\nGrobid\n\nGROBID is a machine learning library for extracting, parsing, and re-structuring raw documents.\n\nIt is designed and expected to be used to parse academic papers, where it works particularly well.\n\nNote: if the articles supplied to Grobid are large documents (e.g. dissertations) exceeding a certain number of elements, they might not be processed.\n\nThis page covers how to use the Grobid to parse articles for LangChain.\n\nInstallation‚Äã\n\nThe grobid installation is described in details in https://grobid.readthedocs.io/en/latest/Install-Grobid/. However, it is probably easier and less troublesome to run grobid through a docker container, as documented here.\n\nUse Grobid with LangChain‚Äã\n\nOnce grobid is installed and up and running (you can check by accessing it http://localhost:8070), you're ready to go.\n\nYou can now use the GrobidParser to produce documents\n\nfrom langchain.document_loaders.parsers import GrobidParser\nfrom langchain.document_loaders.generic import GenericLoader\n\n#Produce chunks from article paragraphs\nloader = GenericLoader.from_filesystem(\n    \"/Users/31treehaus/Desktop/Papers/\",\n    glob=\"*\",\n    suffixes=[\".pdf\"],\n    parser= GrobidParser(segment_sentences=False)\n)\ndocs = loader.load()\n\n#Produce chunks from article sentences\nloader = GenericLoader.from_filesystem(\n    \"/Users/31treehaus/Desktop/Papers/\",\n    glob=\"*\",\n    suffixes=[\".pdf\"],\n    parser= GrobidParser(segment_sentences=True)\n)\ndocs = loader.load()\n\n\nChunk metadata will include Bounding Boxes. Although these are a bit funky to parse, they are explained in https://grobid.readthedocs.io/en/latest/Coordinates-in-PDF/\n\nPrevious\nGraphsignal\nNext\nGutenberg"
}