{
	"title": "Tongyi Qwen | ğŸ¦œï¸ğŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/chat/tongyi",
	"html": "ComponentsChat modelsTongyi Qwen\nTongyi Qwen\n\nTongyi Qwen is a large language model developed by Alibaba's Damo Academy. It is capable of understanding user intent through natural language understanding and semantic analysis, based on user input in natural language. It provides services and assistance to users in different domains and tasks. By providing clear and detailed instructions, you can obtain results that better align with your expectations. In this notebook, we will introduce how to use langchain with Tongyi mainly in Chat corresponding to the package langchain/chat_models in langchain\n\n# Install the package\npip install dashscope\n\n# Get a new token: https://help.aliyun.com/document_detail/611472.html?spm=a2c4g.2399481.0.0\nfrom getpass import getpass\n\nDASHSCOPE_API_KEY = getpass()\n\n     Â·Â·Â·Â·Â·Â·Â·Â·\n\nimport os\n\nos.environ[\"DASHSCOPE_API_KEY\"] = DASHSCOPE_API_KEY\n\nfrom langchain.chat_models.tongyi import ChatTongyi\nfrom langchain.schema import HumanMessage\n\nchatLLM = ChatTongyi(\n    streaming=True,\n)\nres = chatLLM.stream([HumanMessage(content=\"hi\")], streaming=True)\nfor r in res:\n    print(\"chat resp:\", r)\n\n    chat resp: content='Hello! How' additional_kwargs={} example=False\n    chat resp: content=' can I assist you today?' additional_kwargs={} example=False\n\nfrom langchain.schema import HumanMessage, SystemMessage\n\nmessages = [\n    SystemMessage(\n        content=\"You are a helpful assistant that translates English to French.\"\n    ),\n    HumanMessage(\n        content=\"Translate this sentence from English to French. I love programming.\"\n    ),\n]\nchatLLM(messages)\n\n    AIMessageChunk(content=\"J'aime programmer.\", additional_kwargs={}, example=False)\n\nPrevious\nPromptLayer ChatOpenAI\nNext\nvLLM Chat"
}