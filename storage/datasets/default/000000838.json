{
	"title": "Baidu Qianfan | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/text_embedding/baidu_qianfan_endpoint",
	"html": "ComponentsText embedding modelsBaidu Qianfan\nBaidu Qianfan\n\nBaidu AI Cloud Qianfan Platform is a one-stop large model development and service operation platform for enterprise developers. Qianfan not only provides including the model of Wenxin Yiyan (ERNIE-Bot) and the third-party open-source models, but also provides various AI development tools and the whole set of development environment, which facilitates customers to use and develop large model applications easily.\n\nBasically, those model are split into the following type:\n\nEmbedding\nChat\nCompletion\n\nIn this notebook, we will introduce how to use langchain with Qianfan mainly in Embedding corresponding to the package langchain/embeddings in langchain:\n\nAPI Initialization‚Äã\n\nTo use the LLM services based on Baidu Qianfan, you have to initialize these parameters:\n\nYou could either choose to init the AK,SK in environment variables or init params:\n\nexport QIANFAN_AK=XXX\nexport QIANFAN_SK=XXX\n\n\"\"\"For basic init and call\"\"\"\nimport os\n\nfrom langchain.embeddings import QianfanEmbeddingsEndpoint\n\nos.environ[\"QIANFAN_AK\"] = \"your_ak\"\nos.environ[\"QIANFAN_SK\"] = \"your_sk\"\n\nembed = QianfanEmbeddingsEndpoint(\n    # qianfan_ak='xxx',\n    # qianfan_sk='xxx'\n)\nres = embed.embed_documents([\"hi\", \"world\"])\n\n\nasync def aioEmbed():\n    res = await embed.aembed_query(\"qianfan\")\n    print(res[:8])\n\n\nawait aioEmbed()\n\n\nasync def aioEmbedDocs():\n    res = await embed.aembed_documents([\"hi\", \"world\"])\n    for r in res:\n        print(\"\", r[:8])\n\n\nawait aioEmbedDocs()\n\n    [INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: trying to refresh access_token\n    [INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: sucessfully refresh access_token\n    [INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: requesting llm api endpoint: /embeddings/embedding-v1\n    [INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: async requesting llm api endpoint: /embeddings/embedding-v1\n    [INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: async requesting llm api endpoint: /embeddings/embedding-v1\n\n\n    [-0.03313107788562775, 0.052325375378131866, 0.04951248690485954, 0.0077608139254152775, -0.05907672271132469, -0.010798933915793896, 0.03741293027997017, 0.013969100080430508]\n     [0.0427522286772728, -0.030367236584424973, -0.14847028255462646, 0.055074431002140045, -0.04177454113960266, -0.059512972831726074, -0.043774791061878204, 0.0028191760648041964]\n     [0.03803155943751335, -0.013231384567916393, 0.0032379645854234695, 0.015074018388986588, -0.006529552862048149, -0.13813287019729614, 0.03297128155827522, 0.044519297778606415]\n\nUse different models in Qianfan‚Äã\n\nIn the case you want to deploy your own model based on Ernie Bot or third-party open sources model, you could follow these steps:\n\nÔºàOptional, if the model are included in the default models, skip itÔºâDeploy your model in Qianfan Console, get your own customized deploy endpoint.\nSet up the field called endpoint in the initialization:\nembed = QianfanEmbeddingsEndpoint(model=\"bge_large_zh\", endpoint=\"bge_large_zh\")\n\nres = embed.embed_documents([\"hi\", \"world\"])\nfor r in res:\n    print(r[:8])\n\n    [INFO] [09-15 20:01:40] logging.py:55 [t:140292313159488]: requesting llm api endpoint: /embeddings/bge_large_zh\n\n\n    [-0.0001582596160005778, -0.025089964270591736, -0.03997539356350899, 0.013156415894627571, 0.000135212714667432, 0.012428865768015385, 0.016216561198234558, -0.04126659780740738]\n    [0.0019113451708108187, -0.008625439368188381, -0.0531032420694828, -0.0018436014652252197, -0.01818147301673889, 0.010310115292668343, -0.008867680095136166, -0.021067561581730843]\n\nPrevious\nAzure OpenAI\nNext\nBedrock"
}