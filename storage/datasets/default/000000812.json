{
	"title": "Multi-language anonymization | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/guides/privacy/presidio_data_anonymization/multi_language",
	"html": "PrivacyData anonymization with Microsoft PresidioMulti-language anonymization\nMulti-language anonymization\nMulti-language data anonymization with Microsoft Presidio\n\nUse caseâ€‹\n\nMulti-language support in data pseudonymization is essential due to differences in language structures and cultural contexts. Different languages may have varying formats for personal identifiers. For example, the structure of names, locations and dates can differ greatly between languages and regions. Furthermore, non-alphanumeric characters, accents, and the direction of writing can impact pseudonymization processes. Without multi-language support, data could remain identifiable or be misinterpreted, compromising data privacy and accuracy. Hence, it enables effective and precise pseudonymization suited for global operations.\n\nOverviewâ€‹\n\nPII detection in Microsoft Presidio relies on several components - in addition to the usual pattern matching (e.g. using regex), the analyser uses a model for Named Entity Recognition (NER) to extract entities such as:\n\nPERSON\nLOCATION\nDATE_TIME\nNRP\nORGANIZATION\n\n[Source]\n\nTo handle NER in specific languages, we utilize unique models from the spaCy library, recognized for its extensive selection covering multiple languages and sizes. However, it's not restrictive, allowing for integration of alternative frameworks such as Stanza or transformers when necessary.\n\nQuickstartâ€‹\n# Install necessary packages\n# ! pip install langchain langchain-experimental openai presidio-analyzer presidio-anonymizer spacy Faker\n# ! python -m spacy download en_core_web_lg\n\nfrom langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer\n\nanonymizer = PresidioReversibleAnonymizer(\n    analyzed_fields=[\"PERSON\"],\n)\n\n\nBy default, PresidioAnonymizer and PresidioReversibleAnonymizer use a model trained on English texts, so they handle other languages moderately well.\n\nFor example, here the model did not detect the person:\n\nanonymizer.anonymize(\"Me llamo SofÃ­a\")  # \"My name is SofÃ­a\" in Spanish\n\n    'Me llamo SofÃ­a'\n\n\nThey may also take words from another language as actual entities. Here, both the word 'Yo' ('I' in Spanish) and SofÃ­a have been classified as PERSON:\n\nanonymizer.anonymize(\"Yo soy SofÃ­a\")  # \"I am SofÃ­a\" in Spanish\n\n    'Kari Lopez soy Mary Walker'\n\n\nIf you want to anonymise texts from other languages, you need to download other models and add them to the anonymiser configuration:\n\n# Download the models for the languages you want to use\n# ! python -m spacy download en_core_web_md\n# ! python -m spacy download es_core_news_md\n\nnlp_config = {\n    \"nlp_engine_name\": \"spacy\",\n    \"models\": [\n        {\"lang_code\": \"en\", \"model_name\": \"en_core_web_md\"},\n        {\"lang_code\": \"es\", \"model_name\": \"es_core_news_md\"},\n    ],\n}\n\n\nWe have therefore added a Spanish language model. Note also that we have downloaded an alternative model for English as well - in this case we have replaced the large model en_core_web_lg (560MB) with its smaller version en_core_web_md (40MB) - the size is therefore reduced by 14 times! If you care about the speed of anonymisation, it is worth considering it.\n\nAll models for the different languages can be found in the spaCy documentation.\n\nNow pass the configuration as the languages_config parameter to Anonymiser. As you can see, both previous examples work flawlessly:\n\nanonymizer = PresidioReversibleAnonymizer(\n    analyzed_fields=[\"PERSON\"],\n    languages_config=nlp_config,\n)\n\nprint(\n    anonymizer.anonymize(\"Me llamo SofÃ­a\", language=\"es\")\n)  # \"My name is SofÃ­a\" in Spanish\nprint(anonymizer.anonymize(\"Yo soy SofÃ­a\", language=\"es\"))  # \"I am SofÃ­a\" in Spanish\n\n    Me llamo Christopher Smith\n    Yo soy Joseph Jenkins\n\n\nBy default, the language indicated first in the configuration will be used when anonymising text (in this case English):\n\nprint(anonymizer.anonymize(\"My name is John\"))\n\n    My name is Shawna Bennett\n\nUsage with other frameworksâ€‹\nLanguage detectionâ€‹\n\nOne of the drawbacks of the presented approach is that we have to pass the language of the input text directly. However, there is a remedy for that - language detection libraries.\n\nWe recommend using one of the following frameworks:\n\nfasttext (recommended)\nlangdetect\n\nFrom our experience fasttext performs a bit better, but you should verify it on your use case.\n\n# Install necessary packages\n# ! pip install fasttext langdetect\n\nlangdetectâ€‹\nimport langdetect\nfrom langchain.schema import runnable\n\n\ndef detect_language(text: str) -> dict:\n    language = langdetect.detect(text)\n    print(language)\n    return {\"text\": text, \"language\": language}\n\n\nchain = runnable.RunnableLambda(detect_language) | (\n    lambda x: anonymizer.anonymize(x[\"text\"], language=x[\"language\"])\n)\n\nchain.invoke(\"Me llamo SofÃ­a\")\n\n    es\n\n\n\n\n\n    'Me llamo Michael Perez III'\n\nchain.invoke(\"My name is John Doe\")\n\n    en\n\n\n\n\n\n    'My name is Ronald Bennett'\n\nfasttextâ€‹\n\nYou need to download the fasttext model first from https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\n\nimport fasttext\n\nmodel = fasttext.load_model(\"lid.176.ftz\")\n\n\ndef detect_language(text: str) -> dict:\n    language = model.predict(text)[0][0].replace(\"__label__\", \"\")\n    print(language)\n    return {\"text\": text, \"language\": language}\n\n\nchain = runnable.RunnableLambda(detect_language) | (\n    lambda x: anonymizer.anonymize(x[\"text\"], language=x[\"language\"])\n)\n\n    Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n\nchain.invoke(\"Yo soy SofÃ­a\")\n\n    es\n\n\n\n\n\n    'Yo soy Angela Werner'\n\nchain.invoke(\"My name is John Doe\")\n\n    en\n\n\n\n\n\n    'My name is Carlos Newton'\n\n\nThis way you only need to initialize the model with the engines corresponding to the relevant languages, but using the tool is fully automated.\n\nAdvanced usageâ€‹\nCustom labels in NER modelâ€‹\n\nIt may be that the spaCy model has different class names than those supported by the Microsoft Presidio by default. Take Polish, for example:\n\n# ! python -m spacy download pl_core_news_md\n\nimport spacy\n\nnlp = spacy.load(\"pl_core_news_md\")\ndoc = nlp(\"Nazywam siÄ™ Wiktoria\")  # \"My name is Wiktoria\" in Polish\n\nfor ent in doc.ents:\n    print(\n        f\"Text: {ent.text}, Start: {ent.start_char}, End: {ent.end_char}, Label: {ent.label_}\"\n    )\n\n    Text: Wiktoria, Start: 12, End: 20, Label: persName\n\n\nThe name Victoria was classified as persName, which does not correspond to the default class names PERSON/PER implemented in Microsoft Presidio (look for CHECK_LABEL_GROUPS in SpacyRecognizer implementation).\n\nYou can find out more about custom labels in spaCy models (including your own, trained ones) in this thread.\n\nThat's why our sentence will not be anonymized:\n\nnlp_config = {\n    \"nlp_engine_name\": \"spacy\",\n    \"models\": [\n        {\"lang_code\": \"en\", \"model_name\": \"en_core_web_md\"},\n        {\"lang_code\": \"es\", \"model_name\": \"es_core_news_md\"},\n        {\"lang_code\": \"pl\", \"model_name\": \"pl_core_news_md\"},\n    ],\n}\n\nanonymizer = PresidioReversibleAnonymizer(\n    analyzed_fields=[\"PERSON\", \"LOCATION\", \"DATE_TIME\"],\n    languages_config=nlp_config,\n)\n\nprint(\n    anonymizer.anonymize(\"Nazywam siÄ™ Wiktoria\", language=\"pl\")\n)  # \"My name is Wiktoria\" in Polish\n\n    Nazywam siÄ™ Wiktoria\n\n\nTo address this, create your own SpacyRecognizer with your own class mapping and add it to the anonymizer:\n\nfrom presidio_analyzer.predefined_recognizers import SpacyRecognizer\n\npolish_check_label_groups = [\n    ({\"LOCATION\"}, {\"placeName\", \"geogName\"}),\n    ({\"PERSON\"}, {\"persName\"}),\n    ({\"DATE_TIME\"}, {\"date\", \"time\"}),\n]\n\nspacy_recognizer = SpacyRecognizer(\n    supported_language=\"pl\",\n    check_label_groups=polish_check_label_groups,\n)\n\nanonymizer.add_recognizer(spacy_recognizer)\n\n\nNow everything works smoothly:\n\nprint(\n    anonymizer.anonymize(\"Nazywam siÄ™ Wiktoria\", language=\"pl\")\n)  # \"My name is Wiktoria\" in Polish\n\n    Nazywam siÄ™ Morgan Walters\n\n\nLet's try on more complex example:\n\nprint(\n    anonymizer.anonymize(\n        \"Nazywam siÄ™ Wiktoria. PÅ‚ock to moje miasto rodzinne. UrodziÅ‚am siÄ™ dnia 6 kwietnia 2001 roku\",\n        language=\"pl\",\n    )\n)  # \"My name is Wiktoria. PÅ‚ock is my home town. I was born on 6 April 2001\" in Polish\n\n    Nazywam siÄ™ Ernest Liu. New Taylorburgh to moje miasto rodzinne. UrodziÅ‚am siÄ™ 1987-01-19\n\n\nAs you can see, thanks to class mapping, the anonymiser can cope with different types of entities.\n\nCustom language-specific operatorsâ€‹\n\nIn the example above, the sentence has been anonymised correctly, but the fake data does not fit the Polish language at all. Custom operators can therefore be added, which will resolve the issue:\n\nfrom faker import Faker\nfrom presidio_anonymizer.entities import OperatorConfig\n\nfake = Faker(locale=\"pl_PL\")  # Setting faker to provide Polish data\n\nnew_operators = {\n    \"PERSON\": OperatorConfig(\"custom\", {\"lambda\": lambda _: fake.first_name_female()}),\n    \"LOCATION\": OperatorConfig(\"custom\", {\"lambda\": lambda _: fake.city()}),\n}\n\nanonymizer.add_operators(new_operators)\n\nprint(\n    anonymizer.anonymize(\n        \"Nazywam siÄ™ Wiktoria. PÅ‚ock to moje miasto rodzinne. UrodziÅ‚am siÄ™ dnia 6 kwietnia 2001 roku\",\n        language=\"pl\",\n    )\n)  # \"My name is Wiktoria. PÅ‚ock is my home town. I was born on 6 April 2001\" in Polish\n\n    Nazywam siÄ™ Marianna. Szczecin to moje miasto rodzinne. UrodziÅ‚am siÄ™ 1976-11-16\n\nLimitationsâ€‹\n\nRemember - results are as good as your recognizers and as your NER models!\n\nLook at the example below - we downloaded the small model for Spanish (12MB) and it no longer performs as well as the medium version (40MB):\n\n# ! python -m spacy download es_core_news_sm\n\nfor model in [\"es_core_news_sm\", \"es_core_news_md\"]:\n    nlp_config = {\n        \"nlp_engine_name\": \"spacy\",\n        \"models\": [\n            {\"lang_code\": \"es\", \"model_name\": model},\n        ],\n    }\n\n    anonymizer = PresidioReversibleAnonymizer(\n        analyzed_fields=[\"PERSON\"],\n        languages_config=nlp_config,\n    )\n\n    print(\n        f\"Model: {model}. Result: {anonymizer.anonymize('Me llamo SofÃ­a', language='es')}\"\n    )\n\n    Model: es_core_news_sm. Result: Me llamo SofÃ­a\n    Model: es_core_news_md. Result: Me llamo Lawrence Davis\n\n\nIn many cases, even the larger models from spaCy will not be sufficient - there are already other, more complex and better methods of detecting named entities, based on transformers. You can read more about this here.\n\nPrevious\nReversible anonymization\nNext\nQA with private data protection"
}