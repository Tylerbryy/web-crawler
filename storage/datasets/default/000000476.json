{
	"title": "Conversational | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/modules/agents/agent_types/chat_conversation_agent",
	"html": "ModulesAgentsAgent TypesConversational\nConversational\n\nThis walkthrough demonstrates how to use an agent optimized for conversation. Other agents are often optimized for using tools to figure out the best response, which is not ideal in a conversational setting where you may want the agent to be able to chat with the user as well.\n\nIf we compare it to the standard ReAct agent, the main difference is the prompt. We want it to be much more conversational.\n\nfrom langchain.agents import AgentType, Tool, initialize_agent\nfrom langchain.llms import OpenAI\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.utilities import SerpAPIWrapper\n\nsearch = SerpAPIWrapper()\ntools = [\n    Tool(\n        name=\"Current Search\",\n        func=search.run,\n        description=\"useful for when you need to answer questions about current events or the current state of the world\",\n    ),\n]\n\nllm = OpenAI(temperature=0)\n\nUsing LCELâ€‹\n\nWe will first show how to create this agent using LCEL\n\nfrom langchain import hub\nfrom langchain.agents.format_scratchpad import format_log_to_str\nfrom langchain.agents.output_parsers import ReActSingleInputOutputParser\nfrom langchain.tools.render import render_text_description\n\nprompt = hub.pull(\"hwchase17/react-chat\")\n\nprompt = prompt.partial(\n    tools=render_text_description(tools),\n    tool_names=\", \".join([t.name for t in tools]),\n)\n\nllm_with_stop = llm.bind(stop=[\"\\nObservation\"])\n\nagent = (\n    {\n        \"input\": lambda x: x[\"input\"],\n        \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n        \"chat_history\": lambda x: x[\"chat_history\"],\n    }\n    | prompt\n    | llm_with_stop\n    | ReActSingleInputOutputParser()\n)\n\nfrom langchain.agents import AgentExecutor\n\nmemory = ConversationBufferMemory(memory_key=\"chat_history\")\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n\nagent_executor.invoke({\"input\": \"hi, i am bob\"})[\"output\"]\n\n    \n    \n    > Entering new AgentExecutor chain...\n    \n    Thought: Do I need to use a tool? No\n    Final Answer: Hi Bob, nice to meet you! How can I help you today?\n    \n    > Finished chain.\n\n\n\n\n\n    'Hi Bob, nice to meet you! How can I help you today?'\n\nagent_executor.invoke({\"input\": \"whats my name?\"})[\"output\"]\n\n    \n    \n    > Entering new AgentExecutor chain...\n    \n    Thought: Do I need to use a tool? No\n    Final Answer: Your name is Bob.\n    \n    > Finished chain.\n\n\n\n\n\n    'Your name is Bob.'\n\nagent_executor.invoke({\"input\": \"what are some movies showing 9/21/2023?\"})[\"output\"]\n\n    \n    \n    > Entering new AgentExecutor chain...\n    \n    Thought: Do I need to use a tool? Yes\n    Action: Current Search\n    Action Input: Movies showing 9/21/2023['September 2023 Movies: The Creator â€¢ Dumb Money â€¢ Expend4bles â€¢ The Kill Room â€¢ The Inventor â€¢ The Equalizer 3 â€¢ PAW Patrol: The Mighty Movie, ...'] Do I need to use a tool? No\n    Final Answer: According to current search, some movies showing on 9/21/2023 are The Creator, Dumb Money, Expend4bles, The Kill Room, The Inventor, The Equalizer 3, and PAW Patrol: The Mighty Movie.\n    \n    > Finished chain.\n\n\n\n\n\n    'According to current search, some movies showing on 9/21/2023 are The Creator, Dumb Money, Expend4bles, The Kill Room, The Inventor, The Equalizer 3, and PAW Patrol: The Mighty Movie.'\n\nUse the off-the-shelf agentâ€‹\n\nWe can also create this agent using the off-the-shelf agent class\n\nagent_executor = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n    verbose=True,\n    memory=memory,\n)\n\nUse a chat modelâ€‹\n\nWe can also use a chat model here. The main difference here is in the prompts used.\n\nfrom langchain import hub\nfrom langchain.chat_models import ChatOpenAI\n\nprompt = hub.pull(\"hwchase17/react-chat-json\")\nchat_model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n\nprompt = prompt.partial(\n    tools=render_text_description(tools),\n    tool_names=\", \".join([t.name for t in tools]),\n)\n\nchat_model_with_stop = chat_model.bind(stop=[\"\\nObservation\"])\n\nfrom langchain.agents.format_scratchpad import format_log_to_messages\nfrom langchain.agents.output_parsers import JSONAgentOutputParser\n\n# We need some extra steering, or the chat model forgets how to respond sometimes\nTEMPLATE_TOOL_RESPONSE = \"\"\"TOOL RESPONSE: \n---------------------\n{observation}\n\nUSER'S INPUT\n--------------------\n\nOkay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else - even if you just want to respond to the user. Do NOT respond with anything except a JSON snippet no matter what!\"\"\"\n\nagent = (\n    {\n        \"input\": lambda x: x[\"input\"],\n        \"agent_scratchpad\": lambda x: format_log_to_messages(\n            x[\"intermediate_steps\"], template_tool_response=TEMPLATE_TOOL_RESPONSE\n        ),\n        \"chat_history\": lambda x: x[\"chat_history\"],\n    }\n    | prompt\n    | chat_model_with_stop\n    | JSONAgentOutputParser()\n)\n\nfrom langchain.agents import AgentExecutor\n\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)\n\nagent_executor.invoke({\"input\": \"hi, i am bob\"})[\"output\"]\n\n    \n    \n    > Entering new AgentExecutor chain...\n    ```json\n    {\n        \"action\": \"Final Answer\",\n        \"action_input\": \"Hello Bob, how can I assist you today?\"\n    }\n    ```\n    \n    > Finished chain.\n\n\n\n\n\n    'Hello Bob, how can I assist you today?'\n\nagent_executor.invoke({\"input\": \"whats my name?\"})[\"output\"]\n\n    \n    \n    > Entering new AgentExecutor chain...\n    ```json\n    {\n        \"action\": \"Final Answer\",\n        \"action_input\": \"Your name is Bob.\"\n    }\n    ```\n    \n    > Finished chain.\n\n\n\n\n\n    'Your name is Bob.'\n\nagent_executor.invoke({\"input\": \"what are some movies showing 9/21/2023?\"})[\"output\"]\n\n    \n    \n    > Entering new AgentExecutor chain...\n    ```json\n    {\n        \"action\": \"Current Search\",\n        \"action_input\": \"movies showing on 9/21/2023\"\n    }\n    ```['September 2023 Movies: The Creator â€¢ Dumb Money â€¢ Expend4bles â€¢ The Kill Room â€¢ The Inventor â€¢ The Equalizer 3 â€¢ PAW Patrol: The Mighty Movie, ...']```json\n    {\n        \"action\": \"Final Answer\",\n        \"action_input\": \"Some movies that are showing on 9/21/2023 include 'The Creator', 'Dumb Money', 'Expend4bles', 'The Kill Room', 'The Inventor', 'The Equalizer 3', and 'PAW Patrol: The Mighty Movie'.\"\n    }\n    ```\n    \n    > Finished chain.\n\n\n\n\n\n    \"Some movies that are showing on 9/21/2023 include 'The Creator', 'Dumb Money', 'Expend4bles', 'The Kill Room', 'The Inventor', 'The Equalizer 3', and 'PAW Patrol: The Mighty Movie'.\"\n\n\nWe can also initialize the agent executor with a predefined agent type\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\nllm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)\nagent_chain = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n    verbose=True,\n    memory=memory,\n)\n\nPrevious\nAgent Types\nNext\nOpenAI assistants"
}