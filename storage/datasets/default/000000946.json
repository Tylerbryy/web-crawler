{
	"title": "Serialization | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/prompt_serialization",
	"html": "ModulesModel I/OPromptsPrompt templatesSerialization\nSerialization\n\nIt is often preferable to store prompts not as python code but as files. This can make it easy to share, store, and version prompts. This notebook covers how to do that in LangChain, walking through all the different types of prompts and the different serialization options.\n\nAt a high level, the following design principles are applied to serialization:\n\nBoth JSON and YAML are supported. We want to support serialization methods that are human readable on disk, and YAML and JSON are two of the most popular methods for that. Note that this rule applies to prompts. For other assets, like examples, different serialization methods may be supported.\n\nWe support specifying everything in one file, or storing different components (templates, examples, etc) in different files and referencing them. For some cases, storing everything in file makes the most sense, but for others it is preferable to split up some of the assets (long templates, large examples, reusable components). LangChain supports both.\n\nThere is also a single entry point to load prompts from disk, making it easy to load any type of prompt.\n\n# All prompts are loaded through the `load_prompt` function.\nfrom langchain.prompts import load_prompt\n\nPromptTemplate‚Äã\n\nThis section covers examples for loading a PromptTemplate.\n\nLoading from YAML‚Äã\n\nThis shows an example of loading a PromptTemplate from YAML.\n\ncat simple_prompt.yaml\n\n    _type: prompt\n    input_variables:\n        [\"adjective\", \"content\"]\n    template: \n        Tell me a {adjective} joke about {content}.\n\nprompt = load_prompt(\"simple_prompt.yaml\")\nprint(prompt.format(adjective=\"funny\", content=\"chickens\"))\n\n    Tell me a funny joke about chickens.\n\nLoading from JSON‚Äã\n\nThis shows an example of loading a PromptTemplate from JSON.\n\ncat simple_prompt.json\n\n    {\n        \"_type\": \"prompt\",\n        \"input_variables\": [\"adjective\", \"content\"],\n        \"template\": \"Tell me a {adjective} joke about {content}.\"\n    }\n\nprompt = load_prompt(\"simple_prompt.json\")\nprint(prompt.format(adjective=\"funny\", content=\"chickens\"))\n\n\nTell me a funny joke about chickens.\n\nLoading template from a file‚Äã\n\nThis shows an example of storing the template in a separate file and then referencing it in the config. Notice that the key changes from template to template_path.\n\ncat simple_template.txt\n\n    Tell me a {adjective} joke about {content}.\n\ncat simple_prompt_with_template_file.json\n\n    {\n        \"_type\": \"prompt\",\n        \"input_variables\": [\"adjective\", \"content\"],\n        \"template_path\": \"simple_template.txt\"\n    }\n\nprompt = load_prompt(\"simple_prompt_with_template_file.json\")\nprint(prompt.format(adjective=\"funny\", content=\"chickens\"))\n\n    Tell me a funny joke about chickens.\n\nFewShotPromptTemplate‚Äã\n\nThis section covers examples for loading few-shot prompt templates.\n\nExamples‚Äã\n\nThis shows an example of what examples stored as json might look like.\n\ncat examples.json\n\n    [\n        {\"input\": \"happy\", \"output\": \"sad\"},\n        {\"input\": \"tall\", \"output\": \"short\"}\n    ]\n\n\nAnd here is what the same examples stored as yaml might look like.\n\ncat examples.yaml\n\n    - input: happy\n      output: sad\n    - input: tall\n      output: short\n\nLoading from YAML‚Äã\n\nThis shows an example of loading a few-shot example from YAML.\n\ncat few_shot_prompt.yaml\n\n    _type: few_shot\n    input_variables:\n        [\"adjective\"]\n    prefix: \n        Write antonyms for the following words.\n    example_prompt:\n        _type: prompt\n        input_variables:\n            [\"input\", \"output\"]\n        template:\n            \"Input: {input}\\nOutput: {output}\"\n    examples:\n        examples.json\n    suffix:\n        \"Input: {adjective}\\nOutput:\"\n\nprompt = load_prompt(\"few_shot_prompt.yaml\")\nprint(prompt.format(adjective=\"funny\"))\n\n    Write antonyms for the following words.\n    \n    Input: happy\n    Output: sad\n    \n    Input: tall\n    Output: short\n    \n    Input: funny\n    Output:\n\n\nThe same would work if you loaded examples from the yaml file.\n\ncat few_shot_prompt_yaml_examples.yaml\n\n    _type: few_shot\n    input_variables:\n        [\"adjective\"]\n    prefix: \n        Write antonyms for the following words.\n    example_prompt:\n        _type: prompt\n        input_variables:\n            [\"input\", \"output\"]\n        template:\n            \"Input: {input}\\nOutput: {output}\"\n    examples:\n        examples.yaml\n    suffix:\n        \"Input: {adjective}\\nOutput:\"\n\nprompt = load_prompt(\"few_shot_prompt_yaml_examples.yaml\")\nprint(prompt.format(adjective=\"funny\"))\n\n    Write antonyms for the following words.\n    \n    Input: happy\n    Output: sad\n    \n    Input: tall\n    Output: short\n    \n    Input: funny\n    Output:\n\nLoading from JSON‚Äã\n\nThis shows an example of loading a few-shot example from JSON.\n\ncat few_shot_prompt.json\n\n    {\n        \"_type\": \"few_shot\",\n        \"input_variables\": [\"adjective\"],\n        \"prefix\": \"Write antonyms for the following words.\",\n        \"example_prompt\": {\n            \"_type\": \"prompt\",\n            \"input_variables\": [\"input\", \"output\"],\n            \"template\": \"Input: {input}\\nOutput: {output}\"\n        },\n        \"examples\": \"examples.json\",\n        \"suffix\": \"Input: {adjective}\\nOutput:\"\n    }   \n\nprompt = load_prompt(\"few_shot_prompt.json\")\nprint(prompt.format(adjective=\"funny\"))\n\n    Write antonyms for the following words.\n    \n    Input: happy\n    Output: sad\n    \n    Input: tall\n    Output: short\n    \n    Input: funny\n    Output:\n\nExamples in the config‚Äã\n\nThis shows an example of referencing the examples directly in the config.\n\ncat few_shot_prompt_examples_in.json\n\n    {\n        \"_type\": \"few_shot\",\n        \"input_variables\": [\"adjective\"],\n        \"prefix\": \"Write antonyms for the following words.\",\n        \"example_prompt\": {\n            \"_type\": \"prompt\",\n            \"input_variables\": [\"input\", \"output\"],\n            \"template\": \"Input: {input}\\nOutput: {output}\"\n        },\n        \"examples\": [\n            {\"input\": \"happy\", \"output\": \"sad\"},\n            {\"input\": \"tall\", \"output\": \"short\"}\n        ],\n        \"suffix\": \"Input: {adjective}\\nOutput:\"\n    }   \n\nprompt = load_prompt(\"few_shot_prompt_examples_in.json\")\nprint(prompt.format(adjective=\"funny\"))\n\n    Write antonyms for the following words.\n    \n    Input: happy\n    Output: sad\n    \n    Input: tall\n    Output: short\n    \n    Input: funny\n    Output:\n\nExample prompt from a file‚Äã\n\nThis shows an example of loading the PromptTemplate that is used to format the examples from a separate file. Note that the key changes from example_prompt to example_prompt_path.\n\ncat example_prompt.json\n\n    {\n        \"_type\": \"prompt\",\n        \"input_variables\": [\"input\", \"output\"],\n        \"template\": \"Input: {input}\\nOutput: {output}\" \n    }\n\ncat few_shot_prompt_example_prompt.json\n\n    {\n        \"_type\": \"few_shot\",\n        \"input_variables\": [\"adjective\"],\n        \"prefix\": \"Write antonyms for the following words.\",\n        \"example_prompt_path\": \"example_prompt.json\",\n        \"examples\": \"examples.json\",\n        \"suffix\": \"Input: {adjective}\\nOutput:\"\n    }   \n\nprompt = load_prompt(\"few_shot_prompt_example_prompt.json\")\nprint(prompt.format(adjective=\"funny\"))\n\n    Write antonyms for the following words.\n    \n    Input: happy\n    Output: sad\n    \n    Input: tall\n    Output: short\n    \n    Input: funny\n    Output:\n\nPromptTemplate with OutputParser‚Äã\n\nThis shows an example of loading a prompt along with an OutputParser from a file.\n\ncat prompt_with_output_parser.json\n\n    {\n        \"input_variables\": [\n            \"question\",\n            \"student_answer\"\n        ],\n        \"output_parser\": {\n            \"regex\": \"(.*?)\\\\nScore: (.*)\",\n            \"output_keys\": [\n                \"answer\",\n                \"score\"\n            ],\n            \"default_output_key\": null,\n            \"_type\": \"regex_parser\"\n        },\n        \"partial_variables\": {},\n        \"template\": \"Given the following question and student answer, provide a correct answer and score the student answer.\\nQuestion: {question}\\nStudent Answer: {student_answer}\\nCorrect Answer:\",\n        \"template_format\": \"f-string\",\n        \"validate_template\": true,\n        \"_type\": \"prompt\"\n    }\n\nprompt = load_prompt(\"prompt_with_output_parser.json\")\n\nprompt.output_parser.parse(\n    \"George Washington was born in 1732 and died in 1799.\\nScore: 1/2\"\n)\n\n    {'answer': 'George Washington was born in 1732 and died in 1799.',\n     'score': '1/2'}\n\nPrevious\nComposition\nNext\nPrompt pipelining"
}