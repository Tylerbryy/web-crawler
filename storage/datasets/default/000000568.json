{
	"title": "PipelineAI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/pipelineai",
	"html": "ComponentsLLMsPipelineAI\nPipelineAI\n\nPipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.\n\nThis notebook goes over how to use Langchain with PipelineAI.\n\nPipelineAI example‚Äã\n\nThis example shows how PipelineAI integrated with LangChain and it is created by PipelineAI.\n\nSetup‚Äã\n\nThe pipeline-ai library is required to use the PipelineAI API, AKA Pipeline Cloud. Install pipeline-ai using pip install pipeline-ai.\n\n# Install the package\npip install pipeline-ai\n\nExample‚Äã\nImports‚Äã\nimport os\n\nfrom langchain.chains import LLMChain\nfrom langchain.llms import PipelineAI\nfrom langchain.prompts import PromptTemplate\n\nSet the Environment API Key‚Äã\n\nMake sure to get your API key from PipelineAI. Check out the cloud quickstart guide. You'll be given a 30 day free trial with 10 hours of serverless GPU compute to test different models.\n\nos.environ[\"PIPELINE_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n\nCreate the PipelineAI instance‚Äã\n\nWhen instantiating PipelineAI, you need to specify the id or tag of the pipeline you want to use, e.g. pipeline_key = \"public/gpt-j:base\". You then have the option of passing additional pipeline-specific keyword arguments:\n\nllm = PipelineAI(pipeline_key=\"YOUR_PIPELINE_KEY\", pipeline_kwargs={...})\n\nCreate a Prompt Template‚Äã\n\nWe will create a prompt template for Question and Answer.\n\ntemplate = \"\"\"Question: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\nInitiate the LLMChain‚Äã\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\nRun the LLMChain‚Äã\n\nProvide a question and run the LLMChain.\n\nquestion = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n\nllm_chain.run(question)\n\nPrevious\nPetals\nNext\nPredibase"
}