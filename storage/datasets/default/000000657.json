{
	"title": "Datadog Tracing | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/providers/datadog",
	"html": "ProvidersMoreDatadog Tracing\nDatadog Tracing\n\nddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.\n\nKey features of the ddtrace integration for LangChain:\n\nTraces: Capture LangChain requests, parameters, prompt-completions, and help visualize LangChain operations.\nMetrics: Capture LangChain request latency, errors, and token/cost usage (for OpenAI LLMs and chat models).\nLogs: Store prompt completion data for each LangChain operation.\nDashboard: Combine metrics, logs, and trace data into a single plane to monitor LangChain requests.\nMonitors: Provide alerts in response to spikes in LangChain request latency or error rate.\n\nNote: The ddtrace LangChain integration currently provides tracing for LLMs, chat models, Text Embedding Models, Chains, and Vectorstores.\n\nInstallation and Setup‚Äã\nEnable APM and StatsD in your Datadog Agent, along with a Datadog API key. For example, in Docker:\ndocker run -d --cgroupns host \\\n              --pid host \\\n              -v /var/run/docker.sock:/var/run/docker.sock:ro \\\n              -v /proc/:/host/proc/:ro \\\n              -v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro \\\n              -e DD_API_KEY=<DATADOG_API_KEY> \\\n              -p 127.0.0.1:8126:8126/tcp \\\n              -p 127.0.0.1:8125:8125/udp \\\n              -e DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true \\\n              -e DD_APM_ENABLED=true \\\n              gcr.io/datadoghq/agent:latest\n\nInstall the Datadog APM Python library.\npip install ddtrace>=1.17\n\nThe LangChain integration can be enabled automatically when you prefix your LangChain Python application command with ddtrace-run:\nDD_SERVICE=\"my-service\" DD_ENV=\"staging\" DD_API_KEY=<DATADOG_API_KEY> ddtrace-run python <your-app>.py\n\n\nNote: If the Agent is using a non-default hostname or port, be sure to also set DD_AGENT_HOST, DD_TRACE_AGENT_PORT, or DD_DOGSTATSD_PORT.\n\nAdditionally, the LangChain integration can be enabled programmatically by adding patch_all() or patch(langchain=True) before the first import of langchain in your application.\n\nNote that using ddtrace-run or patch_all() will also enable the requests and aiohttp integrations which trace HTTP requests to LLM providers, as well as the openai integration which traces requests to the OpenAI library.\n\nfrom ddtrace import config, patch\n\n# Note: be sure to configure the integration before calling ``patch()``!\n# e.g. config.langchain[\"logs_enabled\"] = True\n\npatch(langchain=True)\n\n# to trace synchronous HTTP requests\n# patch(langchain=True, requests=True)\n\n# to trace asynchronous HTTP requests (to the OpenAI library)\n# patch(langchain=True, aiohttp=True)\n\n# to include underlying OpenAI spans from the OpenAI integration\n# patch(langchain=True, openai=True)patch_all\n\n\nSee the [APM Python library documentation][https://ddtrace.readthedocs.io/en/stable/installation_quickstart.html] for more advanced usage.\n\nConfiguration‚Äã\n\nSee the [APM Python library documentation][https://ddtrace.readthedocs.io/en/stable/integrations.html#langchain] for all the available configuration options.\n\nLog Prompt & Completion Sampling‚Äã\n\nTo enable log prompt and completion sampling, set the DD_LANGCHAIN_LOGS_ENABLED=1 environment variable. By default, 10% of traced requests will emit logs containing the prompts and completions.\n\nTo adjust the log sample rate, see the [APM library documentation][https://ddtrace.readthedocs.io/en/stable/integrations.html#langchain].\n\nNote: Logs submission requires DD_API_KEY to be specified when running ddtrace-run.\n\nTroubleshooting‚Äã\n\nNeed help? Create an issue on ddtrace or contact [Datadog support][https://docs.datadoghq.com/help/].\n\nPrevious\nDatabricks\nNext\nDatadog Logs"
}