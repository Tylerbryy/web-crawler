{
	"title": "Airbyte Zendesk Support | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/document_loaders/airbyte_zendesk_support",
	"html": "ComponentsDocument loadersAirbyte Zendesk Support\nAirbyte Zendesk Support\n\nAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.\n\nThis loader exposes the Zendesk Support connector as a document loader, allowing you to load various objects as documents.\n\nInstallation‚Äã\n\nFirst, you need to install the airbyte-source-zendesk-support python package.\n\n#!pip install airbyte-source-zendesk-support\n\nExample‚Äã\n\nCheck out the Airbyte documentation page for details about how to configure the reader. The JSON schema the config object should adhere to can be found on Github: https://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-zendesk-support/source_zendesk_support/spec.json.\n\nThe general shape looks like this:\n\n{\n  \"subdomain\": \"<your zendesk subdomain>\",\n  \"start_date\": \"<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>\",\n  \"credentials\": {\n    \"credentials\": \"api_token\",\n    \"email\": \"<your email>\",\n    \"api_token\": \"<your api token>\"\n  }\n}\n\n\nBy default all fields are stored as metadata in the documents and the text is set to an empty string. Construct the text of the document by transforming the documents returned by the reader.\n\nfrom langchain.document_loaders.airbyte import AirbyteZendeskSupportLoader\n\nconfig = {\n    # your zendesk-support configuration\n}\n\nloader = AirbyteZendeskSupportLoader(\n    config=config, stream_name=\"tickets\"\n)  # check the documentation linked above for a list of all streams\n\n\nNow you can load documents the usual way\n\ndocs = loader.load()\n\n\nAs load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:\n\ndocs_iterator = loader.lazy_load()\n\n\nKeep in mind that by default the page content is empty and the metadata object contains all the information from the record. To create documents in a different, pass in a record_handler function when creating the loader:\n\nfrom langchain.docstore.document import Document\n\n\ndef handle_record(record, id):\n    return Document(page_content=record.data[\"title\"], metadata=record.data)\n\n\nloader = AirbyteZendeskSupportLoader(\n    config=config, record_handler=handle_record, stream_name=\"tickets\"\n)\ndocs = loader.load()\n\nIncremental loads‚Äã\n\nSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.\n\nTo take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.\n\nlast_state = loader.last_state  # store safely\n\nincremental_loader = AirbyteZendeskSupportLoader(\n    config=config, stream_name=\"tickets\", state=last_state\n)\n\nnew_docs = incremental_loader.load()\n\nPrevious\nAirbyte Typeform\nNext\nAirtable"
}