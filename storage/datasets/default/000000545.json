{
	"title": "Google Cloud Vertex AI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/google_vertex_ai_palm",
	"html": "ComponentsLLMsGoogle Cloud Vertex AI\nGoogle Cloud Vertex AI\n\nNote: This is separate from the Google PaLM integration, it exposes Vertex AI PaLM API on Google Cloud.\n\nSetting up‚Äã\n\nBy default, Google Cloud does not use customer data to train its foundation models as part of Google Cloud's AI/ML Privacy Commitment. More details about how Google processes data can also be found in Google's Customer Data Processing Addendum (CDPA).\n\nTo use Vertex AI PaLM you must have the google-cloud-aiplatform Python package installed and either:\n\nHave credentials configured for your environment (gcloud, workload identity, etc...)\nStore the path to a service account JSON file as the GOOGLE_APPLICATION_CREDENTIALS environment variable\n\nThis codebase uses the google.auth library which first looks for the application credentials variable mentioned above, and then looks for system-level auth.\n\nFor more information, see:\n\nhttps://cloud.google.com/docs/authentication/application-default-credentials#GAC\nhttps://googleapis.dev/python/google-auth/latest/reference/google.auth.html#module-google.auth\n#!pip install langchain google-cloud-aiplatform\n\nfrom langchain.llms import VertexAI\n\nllm = VertexAI()\nprint(llm(\"What are some of the pros and cons of Python as a programming language?\"))\n\n     Python is a widely used, interpreted, object-oriented, and high-level programming language with dynamic semantics, used for general-purpose programming. It is known for its readability, simplicity, and versatility. Here are some of the pros and cons of Python:\n    \n    **Pros:**\n    \n    - **Easy to learn:** Python is known for its simple and intuitive syntax, making it easy for beginners to learn. It has a relatively shallow learning curve compared to other programming languages.\n    \n    - **Versatile:** Python is a general-purpose programming language, meaning it can be used for a wide variety of tasks, including web development, data science, machine\n\nUsing in a chain‚Äã\nfrom langchain.prompts import PromptTemplate\n\ntemplate = \"\"\"Question: {question}\n\nAnswer: Let's think step by step.\"\"\"\nprompt = PromptTemplate.from_template(template)\n\nchain = prompt | llm\n\nquestion = \"Who was the president in the year Justin Beiber was born?\"\nprint(chain.invoke({\"question\": question}))\n\n     Justin Bieber was born on March 1, 1994. Bill Clinton was the president of the United States from January 20, 1993, to January 20, 2001.\n    The final answer is Bill Clinton\n\nCode generation example‚Äã\n\nYou can now leverage the Codey API for code generation within Vertex AI.\n\nThe model names are:\n\ncode-bison: for code suggestion\ncode-gecko: for code completion\nllm = VertexAI(model_name=\"code-bison\", max_output_tokens=1000, temperature=0.3)\n\nquestion = \"Write a python function that checks if a string is a valid email address\"\n\nprint(llm(question))\n\n    ```python\n    import re\n    \n    def is_valid_email(email):\n        pattern = re.compile(r\"[^@]+@[^@]+\\.[^@]+\")\n        return pattern.match(email)\n    ```\n\nFull generation info‚Äã\n\nWe can use the generate method to get back extra metadata like safety attributes and not just text completions\n\nresult = llm.generate([question])\nresult.generations\n\n    [[GenerationChunk(text='```python\\nimport re\\n\\ndef is_valid_email(email):\\n    pattern = re.compile(r\"[^@]+@[^@]+\\\\.[^@]+\")\\n    return pattern.match(email)\\n```', generation_info={'is_blocked': False, 'safety_attributes': {'Health': 0.1}})]]\n\nAsynchronous calls‚Äã\n\nWith agenerate we can make asynchronous calls\n\n# If running in a Jupyter notebook you'll need to install nest_asyncio\n\n# !pip install nest_asyncio\n\nimport asyncio\n\n# import nest_asyncio\n# nest_asyncio.apply()\n\nasyncio.run(llm.agenerate([question]))\n\n    LLMResult(generations=[[GenerationChunk(text='```python\\nimport re\\n\\ndef is_valid_email(email):\\n    pattern = re.compile(r\"[^@]+@[^@]+\\\\.[^@]+\")\\n    return pattern.match(email)\\n```', generation_info={'is_blocked': False, 'safety_attributes': {'Health': 0.1}})]], llm_output=None, run=[RunInfo(run_id=UUID('caf74e91-aefb-48ac-8031-0c505fcbbcc6'))])\n\nStreaming calls‚Äã\n\nWith stream we can stream results from the model\n\nimport sys\n\nfor chunk in llm.stream(question):\n    sys.stdout.write(chunk)\n    sys.stdout.flush()\n\n    ```python\n    import re\n    \n    def is_valid_email(email):\n      \"\"\"\n      Checks if a string is a valid email address.\n    \n      Args:\n        email: The string to check.\n    \n      Returns:\n        True if the string is a valid email address, False otherwise.\n      \"\"\"\n    \n      # Check for a valid email address format.\n      if not re.match(r\"^[A-Za-z0-9\\.\\+_-]+@[A-Za-z0-9\\._-]+\\.[a-zA-Z]*$\", email):\n        return False\n    \n      # Check if the domain name exists.\n      try:\n        domain = email.split(\"@\")[1]\n        socket.gethostbyname(domain)\n      except socket.gaierror:\n        return False\n    \n      return True\n    ```\n\nVertex Model Garden‚Äã\n\nVertex Model Garden exposes open-sourced models that can be deployed and served on Vertex AI. If you have successfully deployed a model from Vertex Model Garden, you can find a corresponding Vertex AI endpoint in the console or via API.\n\nfrom langchain.llms import VertexAIModelGarden\n\nllm = VertexAIModelGarden(project=\"YOUR PROJECT\", endpoint_id=\"YOUR ENDPOINT_ID\")\n\nprint(llm(\"What is the meaning of life?\"))\n\n\nLike all LLMs, we can then compose it with other components:\n\nprompt = PromptTemplate.from_template(\"What is the meaning of {thing}?\")\n\nchain = prompt | llm\nprint(chain.invoke({\"thing\": \"life\"}))\n\nPrevious\nGigaChat\nNext\nGooseAI"
}