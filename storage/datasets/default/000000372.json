{
	"title": "GPT4All | 🦜️🔗 Langchain",
	"url": "https://python.langchain.com/docs/integrations/text_embedding/gpt4all",
	"html": "ComponentsText embedding modelsGPT4All\nGPT4All\n\nGPT4All is a free-to-use, locally running, privacy-aware chatbot. There is no GPU or internet required. It features popular models and its own models such as GPT4All Falcon, Wizard, etc.\n\nThis notebook explains how to use GPT4All embeddings with LangChain.\n\nInstall GPT4All's Python Bindings​\n%pip install gpt4all > /dev/null\n\n\nNote: you may need to restart the kernel to use updated packages.\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\ngpt4all_embd = GPT4AllEmbeddings()\n\n    100%|████████████████████████| 45.5M/45.5M [00:02<00:00, 18.5MiB/s]\n\n\n    Model downloaded at:  /Users/rlm/.cache/gpt4all/ggml-all-MiniLM-L6-v2-f16.bin\n\n\n    objc[45711]: Class GGMLMetalClass is implemented in both /Users/rlm/anaconda3/envs/lcn2/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x29fe18208) and /Users/rlm/anaconda3/envs/lcn2/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x2a0244208). One of the two will be used. Which one is undefined.\n\ntext = \"This is a test document.\"\n\nEmbed the Textual Data​\nquery_result = gpt4all_embd.embed_query(text)\n\n\nWith embed_documents you can embed multiple pieces of text. You can also map these embeddings with Nomic's Atlas to see a visual representation of your data.\n\ndoc_result = gpt4all_embd.embed_documents([text])\n\nPrevious\nGoogle Vertex AI PaLM\nNext\nGradient"
}