{
	"title": "Memory in the Multi-Input Chain | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/modules/memory/adding_memory_chain_multiple_inputs",
	"html": "ModulesMoreMemoryMemory in the Multi-Input Chain\nMemory in the Multi-Input Chain\n\nMost memory objects assume a single input. In this notebook, we go over how to add memory to a chain that has multiple inputs. We will add memory to a question/answering chain. This chain takes as inputs both related documents and a user question.\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\nwith open(\"../../state_of_the_union.txt\") as f:\n    state_of_the_union = f.read()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_text(state_of_the_union)\n\nembeddings = OpenAIEmbeddings()\n\ndocsearch = Chroma.from_texts(\n    texts, embeddings, metadatas=[{\"source\": i} for i in range(len(texts))]\n)\n\n    Running Chroma using direct local API.\n    Using DuckDB in-memory for database. Data will be transient.\n\nquery = \"What did the president say about Justice Breyer\"\ndocs = docsearch.similarity_search(query)\n\nfrom langchain.chains.question_answering import load_qa_chain\nfrom langchain.llms import OpenAI\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.prompts import PromptTemplate\n\ntemplate = \"\"\"You are a chatbot having a conversation with a human.\n\nGiven the following extracted parts of a long document and a question, create a final answer.\n\n{context}\n\n{chat_history}\nHuman: {human_input}\nChatbot:\"\"\"\n\nprompt = PromptTemplate(\n    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n)\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")\nchain = load_qa_chain(\n    OpenAI(temperature=0), chain_type=\"stuff\", memory=memory, prompt=prompt\n)\n\nquery = \"What did the president say about Justice Breyer\"\nchain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)\n\n    {'output_text': ' Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.'}\n\nprint(chain.memory.buffer)\n\n    \n    Human: What did the president say about Justice Breyer\n    AI:  Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\n\nPrevious\nMemory in LLMChain\nNext\nMemory in Agent"
}