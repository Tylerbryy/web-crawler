{
	"title": "RELLM | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/rellm_experimental",
	"html": "ComponentsLLMsRELLM\nRELLM\n\nRELLM is a library that wraps local Hugging Face pipeline models for structured decoding.\n\nIt works by generating tokens one at a time. At each step, it masks tokens that don't conform to the provided partial regular expression.\n\nWarning - this module is still experimental\n\npip install rellm > /dev/null\n\nHugging Face Baselineâ€‹\n\nFirst, let's establish a qualitative baseline by checking the output of the model without structured decoding.\n\nimport logging\n\nlogging.basicConfig(level=logging.ERROR)\nprompt = \"\"\"Human: \"What's the capital of the United States?\"\nAI Assistant:{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"The capital of the United States is Washington D.C.\"\n}\nHuman: \"What's the capital of Pennsylvania?\"\nAI Assistant:{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"The capital of Pennsylvania is Harrisburg.\"\n}\nHuman: \"What 2 + 5?\"\nAI Assistant:{\n  \"action\": \"Final Answer\",\n  \"action_input\": \"2 + 5 = 7.\"\n}\nHuman: 'What's the capital of Maryland?'\nAI Assistant:\"\"\"\n\nfrom langchain.llms import HuggingFacePipeline\nfrom transformers import pipeline\n\nhf_model = pipeline(\n    \"text-generation\", model=\"cerebras/Cerebras-GPT-590M\", max_new_tokens=200\n)\n\noriginal_model = HuggingFacePipeline(pipeline=hf_model)\n\ngenerated = original_model.generate([prompt], stop=[\"Human:\"])\nprint(generated)\n\n    Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n    generations=[[Generation(text=' \"What\\'s the capital of Maryland?\"\\n', generation_info=None)]] llm_output=None\n\n\nThat's not so impressive, is it? It didn't answer the question and it didn't follow the JSON format at all! Let's try with the structured decoder.\n\nRELLM LLM Wrapperâ€‹\n\nLet's try that again, now providing a regex to match the JSON structured format.\n\nimport regex  # Note this is the regex library NOT python's re stdlib module\n\n# We'll choose a regex that matches to a structured json string that looks like:\n# {\n#  \"action\": \"Final Answer\",\n# \"action_input\": string or dict\n# }\npattern = regex.compile(\n    r'\\{\\s*\"action\":\\s*\"Final Answer\",\\s*\"action_input\":\\s*(\\{.*\\}|\"[^\"]*\")\\s*\\}\\nHuman:'\n)\n\nfrom langchain_experimental.llms import RELLM\n\nmodel = RELLM(pipeline=hf_model, regex=pattern, max_new_tokens=200)\n\ngenerated = model.predict(prompt, stop=[\"Human:\"])\nprint(generated)\n\n    {\"action\": \"Final Answer\",\n      \"action_input\": \"The capital of Maryland is Baltimore.\"\n    }\n    \n\n\nVoila! Free of parsing errors.\n\nPrevious\nPromptLayer OpenAI\nNext\nReplicate"
}