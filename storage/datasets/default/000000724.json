{
	"title": "Exact Match | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/guides/evaluation/string/exact_match",
	"html": "EvaluationString EvaluatorsExact Match\nExact Match\n\nProbably the simplest ways to evaluate an LLM or runnable's string output against a reference label is by a simple string equivalence.\n\nThis can be accessed using the exact_match evaluator.\n\nfrom langchain.evaluation import ExactMatchStringEvaluator\n\nevaluator = ExactMatchStringEvaluator()\n\n\nAlternatively via the loader:\n\nfrom langchain.evaluation import load_evaluator\n\nevaluator = load_evaluator(\"exact_match\")\n\nevaluator.evaluate_strings(\n    prediction=\"1 LLM.\",\n    reference=\"2 llm\",\n)\n\n    {'score': 0}\n\nevaluator.evaluate_strings(\n    prediction=\"LangChain\",\n    reference=\"langchain\",\n)\n\n    {'score': 0}\n\nConfigure the ExactMatchStringEvaluator‚Äã\n\nYou can relax the \"exactness\" when comparing strings.\n\nevaluator = ExactMatchStringEvaluator(\n    ignore_case=True,\n    ignore_numbers=True,\n    ignore_punctuation=True,\n)\n\n# Alternatively\n# evaluator = load_evaluator(\"exact_match\", ignore_case=True, ignore_numbers=True, ignore_punctuation=True)\n\nevaluator.evaluate_strings(\n    prediction=\"1 LLM.\",\n    reference=\"2 llm\",\n)\n\n    {'score': 1}\n\nPrevious\nEmbedding Distance\nNext\nEvaluating Structured Output: JSON Evaluators"
}