{
	"title": "Ollama | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/chat/ollama",
	"html": "ComponentsChat modelsOllama\nOllama\n\nOllama allows you to run open-source large language models, such as LLaMA2, locally.\n\nOllama bundles model weights, configuration, and data into a single package, defined by a Modelfile.\n\nIt optimizes setup and configuration details, including GPU usage.\n\nFor a complete list of supported models and model variants, see the Ollama model library.\n\nSetup‚Äã\n\nFirst, follow these instructions to set up and run a local Ollama instance:\n\nDownload\nFetch a model via ollama pull <model family>\ne.g., for Llama-7b: ollama pull llama2\nThis will download the most basic version of the model (e.g., minimum # parameters and 4-bit quantization)\nOn Mac, it will download to:\n\n~/.ollama/models/manifests/registry.ollama.ai/library/<model family>/latest\n\nAnd we can specify a particular version, e.g., for ollama pull vicuna:13b-v1.5-16k-q4_0\nThe file is here with the model version in place of latest\n\n~/.ollama/models/manifests/registry.ollama.ai/library/vicuna/13b-v1.5-16k-q4_0\n\nYou can easily access models in a few ways:\n\n1/ if the app is running:\n\nAll of your local models are automatically served on localhost:11434\nSelect your model when setting llm = Ollama(..., model=\"<model family>:<version>\")\nIf you set llm = Ollama(..., model=\"<model family\") withoout a version it will simply look for latest\n\n2/ if building from source or just running the binary:\n\nThen you must run ollama serve\nAll of your local models are automatically served on localhost:11434\nThen, select as shown above\nUsage‚Äã\n\nYou can see a full list of supported parameters on the API reference page.\n\nIf you are using a LLaMA chat model (e.g., ollama pull llama2:7b-chat) then you can use the ChatOllama interface.\n\nThis includes special tokens for system message and user input.\n\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nfrom langchain.chat_models import ChatOllama\n\nchat_model = ChatOllama(\n    model=\"llama2:7b-chat\",\n    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n)\n\n\nWith StreamingStdOutCallbackHandler, you will see tokens streamed.\n\nfrom langchain.schema import HumanMessage\n\nmessages = [HumanMessage(content=\"Tell me about the history of AI\")]\nchat_model(messages)\n\n     Artificial intelligence (AI) has a rich and varied history that spans several decades. Hinweis: The following is a brief overview of the major milestones in the history of AI, but it is by no means exhaustive.\n    \n    1. Early Beginnings (1950s-1960s): The term \"Artificial Intelligence\" was coined in 1956 by computer scientist John McCarthy. However, the concept of creating machines that can think and learn like humans dates back to ancient times. In the 1950s and 1960s, researchers began exploring the possibilities of AI using simple algorithms and machine learning techniques.\n    2. Rule-Based Systems (1970s-1980s): In the 1970s and 1980s, AI research focused on developing rule-based systems, which use predefined rules to reason and make decisions. This led to the development of expert systems, which were designed to mimic the decision-making abilities of human experts in specific domains.\n    3. Machine Learning (1980s-1990s): The 1980s saw a shift towards machine learning, which enables machines to learn from data without being explicitly programmed. This led to the development of algorithms such as decision trees, neural networks, and support vector machines.\n    4. Deep Learning (2000s-present): In the early 2000s, deep learning emerged as a subfield of machine learning, focusing on neural networks with multiple layers. These networks can learn complex representations of data, leading to breakthroughs in image and speech recognition, natural language processing, and other areas.\n    5. Natural Language Processing (NLP) (1980s-present): NLP has been an active area of research since the 1980s, with a focus on developing algorithms that can understand and generate human language. This has led to applications such as chatbots, voice assistants, and language translation systems.\n    6. Robotics (1970s-present): The development of robotics has been closely tied to AI research, with a focus on creating machines that can perform tasks that typically require human intelligence, such as manipulation and locomotion.\n    7. Computer Vision (1980s-present): Computer vision has been an active area of research since the 1980s, with a focus on enabling machines to interpret and understand visual data from the world around us. This has led to applications such as image recognition, object detection, and autonomous driving.\n    8. Ethics and Society (1990s-present): As AI technology has become more advanced and integrated into various aspects of society, there has been a growing concern about the ethical implications of AI. This includes issues related to privacy, bias, and job displacement.\n    9. Reinforcement Learning (2000s-present): Reinforcement learning is a subfield of machine learning that involves training machines to make decisions based on feedback from their environment. This has led to breakthroughs in areas such as game playing, robotics, and autonomous driving.\n    10. Generative Models (2010s-present): Generative models are a class of AI algorithms that can generate new data that is similar to a given dataset. This has led to applications such as image synthesis, music generation, and language creation.\n    \n    These are just a few of the many developments in the history of AI. As the field continues to evolve, we can expect even more exciting breakthroughs and innovations in the years to come.\n\n\n\n\n    AIMessage(content=' Artificial intelligence (AI) has a rich and varied history that spans several decades. Hinweis: The following is a brief overview of the major milestones in the history of AI, but it is by no means exhaustive.\\n\\n1. Early Beginnings (1950s-1960s): The term \"Artificial Intelligence\" was coined in 1956 by computer scientist John McCarthy. However, the concept of creating machines that can think and learn like humans dates back to ancient times. In the 1950s and 1960s, researchers began exploring the possibilities of AI using simple algorithms and machine learning techniques.\\n2. Rule-Based Systems (1970s-1980s): In the 1970s and 1980s, AI research focused on developing rule-based systems, which use predefined rules to reason and make decisions. This led to the development of expert systems, which were designed to mimic the decision-making abilities of human experts in specific domains.\\n3. Machine Learning (1980s-1990s): The 1980s saw a shift towards machine learning, which enables machines to learn from data without being explicitly programmed. This led to the development of algorithms such as decision trees, neural networks, and support vector machines.\\n4. Deep Learning (2000s-present): In the early 2000s, deep learning emerged as a subfield of machine learning, focusing on neural networks with multiple layers. These networks can learn complex representations of data, leading to breakthroughs in image and speech recognition, natural language processing, and other areas.\\n5. Natural Language Processing (NLP) (1980s-present): NLP has been an active area of research since the 1980s, with a focus on developing algorithms that can understand and generate human language. This has led to applications such as chatbots, voice assistants, and language translation systems.\\n6. Robotics (1970s-present): The development of robotics has been closely tied to AI research, with a focus on creating machines that can perform tasks that typically require human intelligence, such as manipulation and locomotion.\\n7. Computer Vision (1980s-present): Computer vision has been an active area of research since the 1980s, with a focus on enabling machines to interpret and understand visual data from the world around us. This has led to applications such as image recognition, object detection, and autonomous driving.\\n8. Ethics and Society (1990s-present): As AI technology has become more advanced and integrated into various aspects of society, there has been a growing concern about the ethical implications of AI. This includes issues related to privacy, bias, and job displacement.\\n9. Reinforcement Learning (2000s-present): Reinforcement learning is a subfield of machine learning that involves training machines to make decisions based on feedback from their environment. This has led to breakthroughs in areas such as game playing, robotics, and autonomous driving.\\n10. Generative Models (2010s-present): Generative models are a class of AI algorithms that can generate new data that is similar to a given dataset. This has led to applications such as image synthesis, music generation, and language creation.\\n\\nThese are just a few of the many developments in the history of AI. As the field continues to evolve, we can expect even more exciting breakthroughs and innovations in the years to come.', additional_kwargs={}, example=False)\n\nRAG‚Äã\n\nWe can use Olama with RAG, just as shown here.\n\nLet's use the 13b model:\n\nollama pull llama2:13b\n\n\nLet's also use local embeddings from OllamaEmbeddings and Chroma.\n\npip install chromadb\n\nfrom langchain.document_loaders import WebBaseLoader\n\nloader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\ndata = loader.load()\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\nall_splits = text_splitter.split_documents(data)\n\nfrom langchain.embeddings import OllamaEmbeddings\nfrom langchain.vectorstores import Chroma\n\nvectorstore = Chroma.from_documents(documents=all_splits, embedding=OllamaEmbeddings())\n\nquestion = \"What are the approaches to Task Decomposition?\"\ndocs = vectorstore.similarity_search(question)\nlen(docs)\n\n    4\n\nfrom langchain.prompts import PromptTemplate\n\n# Prompt\ntemplate = \"\"\"[INST] <<SYS>> Use the following pieces of context to answer the question at the end. \nIf you don't know the answer, just say that you don't know, don't try to make up an answer. \nUse three sentences maximum and keep the answer as concise as possible. <</SYS>>\n{context}\nQuestion: {question}\nHelpful Answer:[/INST]\"\"\"\nQA_CHAIN_PROMPT = PromptTemplate(\n    input_variables=[\"context\", \"question\"],\n    template=template,\n)\n\n# Chat model\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nfrom langchain.chat_models import ChatOllama\n\nchat_model = ChatOllama(\n    model=\"llama2:13b\",\n    verbose=True,\n    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n)\n\n# QA chain\nfrom langchain.chains import RetrievalQA\n\nqa_chain = RetrievalQA.from_chain_type(\n    chat_model,\n    retriever=vectorstore.as_retriever(),\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n)\n\nquestion = \"What are the various approaches to Task Decomposition for AI Agents?\"\nresult = qa_chain({\"query\": question})\n\n     Based on the provided context, there are three approaches to task decomposition for AI agents:\n    \n    1. LLM with simple prompting, such as \"Steps for XYZ.\" or \"What are the subgoals for achieving XYZ?\"\n    2. Task-specific instructions, such as \"Write a story outline\" for writing a novel.\n    3. Human inputs.\n\n\nYou can also get logging for tokens.\n\nfrom langchain.callbacks.base import BaseCallbackHandler\nfrom langchain.schema import LLMResult\n\n\nclass GenerationStatisticsCallback(BaseCallbackHandler):\n    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n        print(response.generations[0][0].generation_info)\n\n\ncallback_manager = CallbackManager(\n    [StreamingStdOutCallbackHandler(), GenerationStatisticsCallback()]\n)\n\nchat_model = ChatOllama(\n    model=\"llama2:13b-chat\", verbose=True, callback_manager=callback_manager\n)\n\nqa_chain = RetrievalQA.from_chain_type(\n    chat_model,\n    retriever=vectorstore.as_retriever(),\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n)\n\nquestion = \"What are the approaches to Task Decomposition?\"\nresult = qa_chain({\"query\": question})\n\n     Based on the given context, here is the answer to the question \"What are the approaches to Task Decomposition?\"\n    \n    There are three approaches to task decomposition:\n    \n    1. LLM with simple prompting, such as \"Steps for XYZ.\" or \"What are the subgoals for achieving XYZ?\"\n    2. Using task-specific instructions, like \"Write a story outline\" for writing a novel.\n    3. With human inputs.{'model': 'llama2:13b-chat', 'created_at': '2023-08-23T15:37:51.469127Z', 'done': True, 'context': [1, 29871, 1, 29961, 25580, 29962, 518, 25580, 29962, 518, 25580, 29962, 3532, 14816, 29903, 6778, 4803, 278, 1494, 12785, 310, 3030, 304, 1234, 278, 1139, 472, 278, 1095, 29889, 29871, 13, 3644, 366, 1016, 29915, 29873, 1073, 278, 1234, 29892, 925, 1827, 393, 366, 1016, 29915, 29873, 1073, 29892, 1016, 29915, 29873, 1018, 304, 1207, 701, 385, 1234, 29889, 29871, 13, 11403, 2211, 25260, 7472, 322, 3013, 278, 1234, 408, 3022, 895, 408, 1950, 29889, 529, 829, 14816, 29903, 6778, 13, 5398, 26227, 508, 367, 2309, 313, 29896, 29897, 491, 365, 26369, 411, 2560, 9508, 292, 763, 376, 7789, 567, 363, 1060, 29979, 29999, 7790, 29876, 29896, 19602, 376, 5618, 526, 278, 1014, 1484, 1338, 363, 3657, 15387, 1060, 29979, 29999, 29973, 613, 313, 29906, 29897, 491, 773, 3414, 29899, 14940, 11994, 29936, 321, 29889, 29887, 29889, 376, 6113, 263, 5828, 27887, 1213, 363, 5007, 263, 9554, 29892, 470, 313, 29941, 29897, 411, 5199, 10970, 29889, 13, 13, 5398, 26227, 508, 367, 2309, 313, 29896, 29897, 491, 365, 26369, 411, 2560, 9508, 292, 763, 376, 7789, 567, 363, 1060, 29979, 29999, 7790, 29876, 29896, 19602, 376, 5618, 526, 278, 1014, 1484, 1338, 363, 3657, 15387, 1060, 29979, 29999, 29973, 613, 313, 29906, 29897, 491, 773, 3414, 29899, 14940, 11994, 29936, 321, 29889, 29887, 29889, 376, 6113, 263, 5828, 27887, 1213, 363, 5007, 263, 9554, 29892, 470, 313, 29941, 29897, 411, 5199, 10970, 29889, 13, 13, 1451, 16047, 267, 297, 1472, 29899, 8489, 18987, 322, 3414, 26227, 29901, 1858, 9450, 975, 263, 3309, 29891, 4955, 322, 17583, 3902, 8253, 278, 1650, 2913, 3933, 18066, 292, 29889, 365, 26369, 29879, 21117, 304, 10365, 13900, 746, 20050, 411, 15668, 4436, 29892, 3907, 963, 3109, 16424, 9401, 304, 25618, 1058, 5110, 515, 14260, 322, 1059, 29889, 13, 13, 1451, 16047, 267, 297, 1472, 29899, 8489, 18987, 322, 3414, 26227, 29901, 1858, 9450, 975, 263, 3309, 29891, 4955, 322, 17583, 3902, 8253, 278, 1650, 2913, 3933, 18066, 292, 29889, 365, 26369, 29879, 21117, 304, 10365, 13900, 746, 20050, 411, 15668, 4436, 29892, 3907, 963, 3109, 16424, 9401, 304, 25618, 1058, 5110, 515, 14260, 322, 1059, 29889, 13, 16492, 29901, 1724, 526, 278, 13501, 304, 9330, 897, 510, 3283, 29973, 13, 29648, 1319, 673, 10834, 29914, 25580, 29962, 518, 29914, 25580, 29962, 518, 29914, 25580, 29962, 29871, 16564, 373, 278, 2183, 3030, 29892, 1244, 338, 278, 1234, 304, 278, 1139, 376, 5618, 526, 278, 13501, 304, 9330, 897, 510, 3283, 3026, 13, 13, 8439, 526, 2211, 13501, 304, 3414, 26227, 29901, 13, 13, 29896, 29889, 365, 26369, 411, 2560, 9508, 292, 29892, 1316, 408, 376, 7789, 567, 363, 1060, 29979, 29999, 1213, 470, 376, 5618, 526, 278, 1014, 1484, 1338, 363, 3657, 15387, 1060, 29979, 29999, 3026, 13, 29906, 29889, 5293, 3414, 29899, 14940, 11994, 29892, 763, 376, 6113, 263, 5828, 27887, 29908, 363, 5007, 263, 9554, 29889, 13, 29941, 29889, 2973, 5199, 10970, 29889, 2], 'total_duration': 9514823750, 'load_duration': 795542, 'sample_count': 99, 'sample_duration': 68732000, 'prompt_eval_count': 146, 'prompt_eval_duration': 6206275000, 'eval_count': 98, 'eval_duration': 3229641000}\n\n\neval_count / (eval_duration/10e9) gets tok / s\n\n98 / (3229641000 / 1000 / 1000 / 1000)\n\n    30.343929867127645\n\nPrevious\nMiniMax\nNext\nOpenAI"
}