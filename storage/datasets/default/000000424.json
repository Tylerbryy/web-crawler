{
	"title": "Caching | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/modules/data_connection/text_embedding/caching_embeddings",
	"html": "ModulesRetrievalText embedding modelsCaching\nCaching\n\nEmbeddings can be stored or temporarily cached to avoid needing to recompute them.\n\nCaching embeddings can be done using a CacheBackedEmbeddings. The cache backed embedder is a wrapper around an embedder that caches embeddings in a key-value store. The text is hashed and the hash is used as the key in the cache.\n\nThe main supported way to initialized a CacheBackedEmbeddings is from_bytes_store. This takes in the following parameters:\n\nunderlying_embedder: The embedder to use for embedding.\ndocument_embedding_cache: The cache to use for storing document embeddings.\nnamespace: (optional, defaults to \"\") The namespace to use for document cache. This namespace is used to avoid collisions with other caches. For example, set it to the name of the embedding model used.\n\nAttention: Be sure to set the namespace parameter to avoid collisions of the same text embedded using different embeddings models.\n\nfrom langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings\nfrom langchain.storage import (\n    InMemoryStore,\n    LocalFileStore,\n    RedisStore,\n    UpstashRedisStore,\n)\n\nUsing with a vector store‚Äã\n\nFirst, let's see an example that uses the local file system for storing embeddings and uses FAISS vector store for retrieval.\n\nfrom langchain.document_loaders import TextLoader\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\n\nunderlying_embeddings = OpenAIEmbeddings()\n\nfs = LocalFileStore(\"./cache/\")\n\ncached_embedder = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings, fs, namespace=underlying_embeddings.model\n)\n\n\nThe cache is empty prior to embedding:\n\nlist(fs.yield_keys())\n\n    []\n\n\nLoad the document, split it into chunks, embed each chunk and load it into the vector store.\n\nraw_documents = TextLoader(\"../state_of_the_union.txt\").load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocuments = text_splitter.split_documents(raw_documents)\n\n\nCreate the vector store:\n\ndb = FAISS.from_documents(documents, cached_embedder)\n\n    CPU times: user 608 ms, sys: 58.9 ms, total: 667 ms\n    Wall time: 1.3 s\n\n\nIf we try to create the vector store again, it'll be much faster since it does not need to re-compute any embeddings.\n\ndb2 = FAISS.from_documents(documents, cached_embedder)\n\n    CPU times: user 33.6 ms, sys: 3.96 ms, total: 37.6 ms\n    Wall time: 36.8 ms\n\n\nAnd here are some of the embeddings that got created:\n\nlist(fs.yield_keys())[:5]\n\n    ['text-embedding-ada-002614d7cf6-46f1-52fa-9d3a-740c39e7a20e',\n     'text-embedding-ada-0020fc1ede2-407a-5e14-8f8f-5642214263f5',\n     'text-embedding-ada-002e4ad20ef-dfaa-5916-9459-f90c6d8e8159',\n     'text-embedding-ada-002a5ef11e4-0474-5725-8d80-81c91943b37f',\n     'text-embedding-ada-00281426526-23fe-58be-9e84-6c7c72c8ca9a']\n\nIn Memory‚Äã\n\nThis section shows how to set up an in memory cache for embeddings. This type of cache is primarily useful for unit tests or prototyping. Do not use this cache if you need to actually store the embeddings.\n\nstore = InMemoryStore()\n\nunderlying_embeddings = OpenAIEmbeddings()\nembedder = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings, store, namespace=underlying_embeddings.model\n)\n\nembeddings = embedder.embed_documents([\"hello\", \"goodbye\"])\n\n    CPU times: user 10.9 ms, sys: 916 ¬µs, total: 11.8 ms\n    Wall time: 159 ms\n\n\nThe second time we try to embed the embedding time is only 2 ms because the embeddings are looked up in the cache.\n\nembeddings_from_cache = embedder.embed_documents([\"hello\", \"goodbye\"])\n\n    CPU times: user 1.67 ms, sys: 342 ¬µs, total: 2.01 ms\n    Wall time: 2.01 ms\n\nembeddings == embeddings_from_cache\n\n    True\n\nFile system‚Äã\n\nThis section covers how to use a file system store.\n\nfs = LocalFileStore(\"./test_cache/\")\n\nembedder2 = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings, fs, namespace=underlying_embeddings.model\n)\n\nembeddings = embedder2.embed_documents([\"hello\", \"goodbye\"])\n\n    CPU times: user 6.89 ms, sys: 4.89 ms, total: 11.8 ms\n    Wall time: 184 ms\n\nembeddings = embedder2.embed_documents([\"hello\", \"goodbye\"])\n\n    CPU times: user 0 ns, sys: 3.24 ms, total: 3.24 ms\n    Wall time: 2.84 ms\n\n\nHere are the embeddings that have been persisted to the directory ./test_cache.\n\nNotice that the embedder takes a namespace parameter.\n\nlist(fs.yield_keys())\n\n    ['text-embedding-ada-002e885db5b-c0bd-5fbc-88b1-4d1da6020aa5',\n     'text-embedding-ada-0026ba52e44-59c9-5cc9-a084-284061b13c80']\n\nUpstash Redis Store‚Äã\nfrom langchain.storage.upstash_redis import UpstashRedisStore\n\nfrom upstash_redis import Redis\n\nURL = \"<UPSTASH_REDIS_REST_URL>\"\nTOKEN = \"<UPSTASH_REDIS_REST_TOKEN>\"\n\nredis_client = Redis(url=URL, token=TOKEN)\nstore = UpstashRedisStore(client=redis_client, ttl=None, namespace=\"test-ns\")\n\nunderlying_embeddings = OpenAIEmbeddings()\nembedder = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings, store, namespace=underlying_embeddings.model\n)\n\nembeddings = embedder.embed_documents([\"welcome\", \"goodbye\"])\n\nembeddings = embedder.embed_documents([\"welcome\", \"goodbye\"])\n\nlist(store.yield_keys())\n\nlist(store.client.scan(0))\n\nRedis Store‚Äã\nfrom langchain.storage import RedisStore\n\n# For cache isolation can use a separate DB\n# Or additional namepace\nstore = RedisStore(\n    redis_url=\"redis://localhost:6379\",\n    client_kwargs={\"db\": 2},\n    namespace=\"embedding_caches\",\n)\n\nunderlying_embeddings = OpenAIEmbeddings()\nembedder = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings, store, namespace=underlying_embeddings.model\n)\n\nembeddings = embedder.embed_documents([\"hello\", \"goodbye\"])\n\n    CPU times: user 3.99 ms, sys: 0 ns, total: 3.99 ms\n    Wall time: 3.5 ms\n\nembeddings = embedder.embed_documents([\"hello\", \"goodbye\"])\n\n    CPU times: user 2.47 ms, sys: 767 ¬µs, total: 3.24 ms\n    Wall time: 2.75 ms\n\nlist(store.yield_keys())\n\n    ['text-embedding-ada-002e885db5b-c0bd-5fbc-88b1-4d1da6020aa5',\n     'text-embedding-ada-0026ba52e44-59c9-5cc9-a084-284061b13c80']\n\nlist(store.client.scan_iter())\n\n    [b'embedding_caches/text-embedding-ada-002e885db5b-c0bd-5fbc-88b1-4d1da6020aa5',\n     b'embedding_caches/text-embedding-ada-0026ba52e44-59c9-5cc9-a084-284061b13c80']\n\nPrevious\nText embedding models\nNext\nVector stores"
}