{
	"title": "Trajectory Evaluators | ğŸ¦œï¸ğŸ”— Langchain",
	"url": "https://python.langchain.com/docs/guides/evaluation/trajectory/",
	"html": "EvaluationTrajectory Evaluators\nTrajectory Evaluators\n\nTrajectory Evaluators in LangChain provide a more holistic approach to evaluating an agent. These evaluators assess the full sequence of actions taken by an agent and their corresponding responses, which we refer to as the \"trajectory\". This allows you to better measure an agent's effectiveness and capabilities.\n\nA Trajectory Evaluator implements the AgentTrajectoryEvaluator interface, which requires two main methods:\n\nevaluate_agent_trajectory: This method synchronously evaluates an agent's trajectory.\naevaluate_agent_trajectory: This asynchronous counterpart allows evaluations to be run in parallel for efficiency.\n\nBoth methods accept three main parameters:\n\ninput: The initial input given to the agent.\nprediction: The final predicted response from the agent.\nagent_trajectory: The intermediate steps taken by the agent, given as a list of tuples.\n\nThese methods return a dictionary. It is recommended that custom implementations return a score (a float indicating the effectiveness of the agent) and reasoning (a string explaining the reasoning behind the score).\n\nYou can capture an agent's trajectory by initializing the agent with the return_intermediate_steps=True parameter. This lets you collect all intermediate steps without relying on special callbacks.\n\nFor a deeper dive into the implementation and use of Trajectory Evaluators, refer to the sections below.\n\nğŸ“„ï¸ Custom Trajectory Evaluator\n\nOpen In Colab\n\nğŸ“„ï¸ Agent Trajectory\n\nOpen In Colab\n\nPrevious\nCustom pairwise evaluator\nNext\nCustom Trajectory Evaluator"
}