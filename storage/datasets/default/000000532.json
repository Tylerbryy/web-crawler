{
	"title": "CerebriumAI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/cerebriumai",
	"html": "ComponentsLLMsCerebriumAI\nCerebriumAI\n\nCerebrium is an AWS Sagemaker alternative. It also provides API access to several LLM models.\n\nThis notebook goes over how to use Langchain with CerebriumAI.\n\nInstall cerebrium‚Äã\n\nThe cerebrium package is required to use the CerebriumAI API. Install cerebrium using pip3 install cerebrium.\n\n# Install the package\npip3 install cerebrium\n\nImports‚Äã\nimport os\n\nfrom langchain.chains import LLMChain\nfrom langchain.llms import CerebriumAI\nfrom langchain.prompts import PromptTemplate\n\nSet the Environment API Key‚Äã\n\nMake sure to get your API key from CerebriumAI. See here. You are given a 1 hour free of serverless GPU compute to test different models.\n\nos.environ[\"CEREBRIUMAI_API_KEY\"] = \"YOUR_KEY_HERE\"\n\nCreate the CerebriumAI instance‚Äã\n\nYou can specify different parameters such as the model endpoint url, max length, temperature, etc. You must provide an endpoint url.\n\nllm = CerebriumAI(endpoint_url=\"YOUR ENDPOINT URL HERE\")\n\nCreate a Prompt Template‚Äã\n\nWe will create a prompt template for Question and Answer.\n\ntemplate = \"\"\"Question: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\nInitiate the LLMChain‚Äã\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\nRun the LLMChain‚Äã\n\nProvide a question and run the LLMChain.\n\nquestion = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n\nllm_chain.run(question)\n\nPrevious\nBittensor\nNext\nChatGLM"
}