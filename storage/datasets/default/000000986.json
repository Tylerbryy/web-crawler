{
	"title": "Streamlit | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/memory/streamlit_chat_message_history",
	"html": "ComponentsMemoryStreamlit\nStreamlit\n\nStreamlit is an open-source Python library that makes it easy to create and share beautiful, custom web apps for machine learning and data science.\n\nThis notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in Streamlit session state at the specified key=. The default key is \"langchain_messages\".\n\nNote, StreamlitChatMessageHistory only works when run in a Streamlit app.\nYou may also be interested in StreamlitCallbackHandler for LangChain.\nFor more on Streamlit check out their getting started documentation.\n\nYou can see the full app example running here, and more examples in github.com/langchain-ai/streamlit-agent.\n\nfrom langchain.memory import StreamlitChatMessageHistory\n\nhistory = StreamlitChatMessageHistory(key=\"chat_messages\")\n\nhistory.add_user_message(\"hi!\")\nhistory.add_ai_message(\"whats up?\")\n\nhistory.messages\n\n\nYou can integrate StreamlitChatMessageHistory into ConversationBufferMemory and chains or agents as usual. The history will be persisted across re-runs of the Streamlit app within a given user session. A given StreamlitChatMessageHistory will NOT be persisted or shared across user sessions.\n\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.memory.chat_message_histories import StreamlitChatMessageHistory\n\n# Optionally, specify your own session_state key for storing messages\nmsgs = StreamlitChatMessageHistory(key=\"special_app_key\")\n\nmemory = ConversationBufferMemory(memory_key=\"history\", chat_memory=msgs)\nif len(msgs.messages) == 0:\n    msgs.add_ai_message(\"How can I help you?\")\n\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\ntemplate = \"\"\"You are an AI chatbot having a conversation with a human.\n\n{history}\nHuman: {human_input}\nAI: \"\"\"\nprompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=template)\n\n# Add the memory to an LLMChain as usual\nllm_chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)\n\n\nConversational Streamlit apps will often re-draw each previous chat message on every re-run. This is easy to do by iterating through StreamlitChatMessageHistory.messages:\n\nimport streamlit as st\n\nfor msg in msgs.messages:\n    st.chat_message(msg.type).write(msg.content)\n\nif prompt := st.chat_input():\n    st.chat_message(\"human\").write(prompt)\n\n    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.\n    response = llm_chain.run(prompt)\n    st.chat_message(\"ai\").write(response)\n\n\nView the final app.\n\nPrevious\nSQLite\nNext\nUpstash Redis"
}