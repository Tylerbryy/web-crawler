{
	"title": "Time-weighted vector store retriever | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/modules/data_connection/retrievers/time_weighted_vectorstore",
	"html": "ModulesRetrievalRetrieversTime-weighted vector store retriever\nTime-weighted vector store retriever\n\nThis retriever uses a combination of semantic similarity and a time decay.\n\nThe algorithm for scoring them is:\n\nsemantic_similarity + (1.0 - decay_rate) ^ hours_passed\n\n\nNotably, hours_passed refers to the hours passed since the object in the retriever was last accessed, not since it was created. This means that frequently accessed objects remain \"fresh\".\n\nimport faiss\n\nfrom datetime import datetime, timedelta\nfrom langchain.docstore import InMemoryDocstore\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.retrievers import TimeWeightedVectorStoreRetriever\nfrom langchain.schema import Document\nfrom langchain.vectorstores import FAISS\n\nLow decay rate‚Äã\n\nA low decay rate (in this, to be extreme, we will set it close to 0) means memories will be \"remembered\" for longer. A decay rate of 0 means memories never be forgotten, making this retriever equivalent to the vector lookup.\n\n# Define your embedding model\nembeddings_model = OpenAIEmbeddings()\n# Initialize the vectorstore as empty\nembedding_size = 1536\nindex = faiss.IndexFlatL2(embedding_size)\nvectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\nretriever = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, decay_rate=.0000000000000000000000001, k=1)\n\nyesterday = datetime.now() - timedelta(days=1)\nretriever.add_documents([Document(page_content=\"hello world\", metadata={\"last_accessed_at\": yesterday})])\nretriever.add_documents([Document(page_content=\"hello foo\")])\n\n    ['d7f85756-2371-4bdf-9140-052780a0f9b3']\n\n# \"Hello World\" is returned first because it is most salient, and the decay rate is close to 0., meaning it's still recent enough\nretriever.get_relevant_documents(\"hello world\")\n\n    [Document(page_content='hello world', metadata={'last_accessed_at': datetime.datetime(2023, 5, 13, 21, 0, 27, 678341), 'created_at': datetime.datetime(2023, 5, 13, 21, 0, 27, 279596), 'buffer_idx': 0})]\n\nHigh decay rate‚Äã\n\nWith a high decay rate (e.g., several 9's), the recency score quickly goes to 0! If you set this all the way to 1, recency is 0 for all objects, once again making this equivalent to a vector lookup.\n\n# Define your embedding model\nembeddings_model = OpenAIEmbeddings()\n# Initialize the vectorstore as empty\nembedding_size = 1536\nindex = faiss.IndexFlatL2(embedding_size)\nvectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\nretriever = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, decay_rate=.999, k=1)\n\nyesterday = datetime.now() - timedelta(days=1)\nretriever.add_documents([Document(page_content=\"hello world\", metadata={\"last_accessed_at\": yesterday})])\nretriever.add_documents([Document(page_content=\"hello foo\")])\n\n    ['40011466-5bbe-4101-bfd1-e22e7f505de2']\n\n# \"Hello Foo\" is returned first because \"hello world\" is mostly forgotten\nretriever.get_relevant_documents(\"hello world\")\n\n    [Document(page_content='hello foo', metadata={'last_accessed_at': datetime.datetime(2023, 4, 16, 22, 9, 2, 494798), 'created_at': datetime.datetime(2023, 4, 16, 22, 9, 2, 178722), 'buffer_idx': 1})]\n\nVirtual time‚Äã\n\nUsing some utils in LangChain, you can mock out the time component.\n\nfrom langchain.utils import mock_now\nimport datetime\n\n# Notice the last access time is that date time\nwith mock_now(datetime.datetime(2011, 2, 3, 10, 11)):\n    print(retriever.get_relevant_documents(\"hello world\"))\n\n    [Document(page_content='hello world', metadata={'last_accessed_at': MockDateTime(2011, 2, 3, 10, 11), 'created_at': datetime.datetime(2023, 5, 13, 21, 0, 27, 279596), 'buffer_idx': 0})]\n\nPrevious\nSelf-querying\nNext\nVector store-backed retriever"
}