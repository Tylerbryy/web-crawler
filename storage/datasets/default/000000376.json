{
	"title": "OpenAI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/text_embedding/openai",
	"html": "ComponentsText embedding modelsOpenAI\nOpenAI\n\nLet's load the OpenAI Embedding class.\n\nfrom langchain.embeddings import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\n\ntext = \"This is a test document.\"\n\nquery_result = embeddings.embed_query(text)\n\nquery_result[:5]\n\n    [-0.003186025367556387,\n     0.011071979803637493,\n     -0.004020420763285827,\n     -0.011658221276953042,\n     -0.0010534035786864363]\n\ndoc_result = embeddings.embed_documents([text])\n\ndoc_result[0][:5]\n\n    [-0.003186025367556387,\n     0.011071979803637493,\n     -0.004020420763285827,\n     -0.011658221276953042,\n     -0.0010534035786864363]\n\n\nLet's load the OpenAI Embedding class with first generation models (e.g. text-search-ada-doc-001/text-search-ada-query-001). Note: These are not recommended models - see here\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings(model=\"text-search-ada-doc-001\")\n\ntext = \"This is a test document.\"\n\nquery_result = embeddings.embed_query(text)\n\nquery_result[:5]\n\n    [0.004452846988523035,\n     0.034550655976098514,\n     -0.015029939040690051,\n     0.03827273883655212,\n     0.005785414075152477]\n\ndoc_result = embeddings.embed_documents([text])\n\ndoc_result[0][:5]\n\n    [0.004452846988523035,\n     0.034550655976098514,\n     -0.015029939040690051,\n     0.03827273883655212,\n     0.005785414075152477]\n\n# if you are behind an explicit proxy, you can use the OPENAI_PROXY environment variable to pass through\nos.environ[\"OPENAI_PROXY\"] = \"http://proxy.yourcompany.com:8080\"\n\nPrevious\nOpenClip\nNext\nSageMaker"
}