{
	"title": "Ensemble Retriever | ğŸ¦œï¸ğŸ”— Langchain",
	"url": "https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble",
	"html": "ModulesRetrievalRetrieversEnsemble Retriever\nEnsemble Retriever\n\nThe EnsembleRetriever takes a list of retrievers as input and ensemble the results of their get_relevant_documents() methods and rerank the results based on the Reciprocal Rank Fusion algorithm.\n\nBy leveraging the strengths of different algorithms, the EnsembleRetriever can achieve better performance than any single algorithm.\n\nThe most common pattern is to combine a sparse retriever (like BM25) with a dense retriever (like embedding similarity), because their strengths are complementary. It is also known as \"hybrid search\". The sparse retriever is good at finding relevant documents based on keywords, while the dense retriever is good at finding relevant documents based on semantic similarity.\n\nfrom langchain.retrievers import BM25Retriever, EnsembleRetriever\nfrom langchain.vectorstores import FAISS\n\ndoc_list = [\n    \"I like apples\",\n    \"I like oranges\",\n    \"Apples and oranges are fruits\",\n]\n\n# initialize the bm25 retriever and faiss retriever\nbm25_retriever = BM25Retriever.from_texts(doc_list)\nbm25_retriever.k = 2\n\nembedding = OpenAIEmbeddings()\nfaiss_vectorstore = FAISS.from_texts(doc_list, embedding)\nfaiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 2})\n\n# initialize the ensemble retriever\nensemble_retriever = EnsembleRetriever(\n    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n)\n\ndocs = ensemble_retriever.get_relevant_documents(\"apples\")\ndocs\n\n    [Document(page_content='I like apples', metadata={}),\n     Document(page_content='Apples and oranges are fruits', metadata={})]\n\nPrevious\nContextual compression\nNext\nMultiVector Retriever"
}