{
	"title": "ForefrontAI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/forefrontai",
	"html": "ComponentsLLMsForefrontAI\nForefrontAI\n\nThe Forefront platform gives you the ability to fine-tune and use open-source large language models.\n\nThis notebook goes over how to use Langchain with ForefrontAI.\n\nImports‚Äã\nimport os\n\nfrom langchain.chains import LLMChain\nfrom langchain.llms import ForefrontAI\nfrom langchain.prompts import PromptTemplate\n\nSet the Environment API Key‚Äã\n\nMake sure to get your API key from ForefrontAI. You are given a 5 day free trial to test different models.\n\n# get a new token: https://docs.forefront.ai/forefront/api-reference/authentication\n\nfrom getpass import getpass\n\nFOREFRONTAI_API_KEY = getpass()\n\nos.environ[\"FOREFRONTAI_API_KEY\"] = FOREFRONTAI_API_KEY\n\nCreate the ForefrontAI instance‚Äã\n\nYou can specify different parameters such as the model endpoint url, length, temperature, etc. You must provide an endpoint url.\n\nllm = ForefrontAI(endpoint_url=\"YOUR ENDPOINT URL HERE\")\n\nCreate a Prompt Template‚Äã\n\nWe will create a prompt template for Question and Answer.\n\ntemplate = \"\"\"Question: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\nInitiate the LLMChain‚Äã\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\nRun the LLMChain‚Äã\n\nProvide a question and run the LLMChain.\n\nquestion = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n\nllm_chain.run(question)\n\nPrevious\nFireworks\nNext\nGigaChat"
}