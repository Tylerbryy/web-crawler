{
	"title": "Airbyte CDK | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/document_loaders/airbyte_cdk",
	"html": "ComponentsDocument loadersAirbyte CDK\nAirbyte CDK\n\nAirbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.\n\nA lot of source connectors are implemented using the Airbyte CDK. This loader allows to run any of these connectors and return the data as documents.\n\nInstallation‚Äã\n\nFirst, you need to install the airbyte-cdk python package.\n\n#!pip install airbyte-cdk\n\n\nThen, either install an existing connector from the Airbyte Github repository or create your own connector using the Airbyte CDK.\n\nFor example, to install the Github connector, run\n\n#!pip install \"source_github@git+https://github.com/airbytehq/airbyte.git@master#subdirectory=airbyte-integrations/connectors/source-github\"\n\n\nSome sources are also published as regular packages on PyPI\n\nExample‚Äã\n\nNow you can create an AirbyteCDKLoader based on the imported source. It takes a config object that's passed to the connector. You also have to pick the stream you want to retrieve records from by name (stream_name). Check the connectors documentation page and spec definition for more information on the config object and available streams. For the Github connectors these are:\n\nhttps://github.com/airbytehq/airbyte/blob/master/airbyte-integrations/connectors/source-github/source_github/spec.json.\nhttps://docs.airbyte.com/integrations/sources/github/\nfrom langchain.document_loaders.airbyte import AirbyteCDKLoader\nfrom source_github.source import SourceGithub  # plug in your own source here\n\nconfig = {\n    # your github configuration\n    \"credentials\": {\"api_url\": \"api.github.com\", \"personal_access_token\": \"<token>\"},\n    \"repository\": \"<repo>\",\n    \"start_date\": \"<date from which to start retrieving records from in ISO format, e.g. 2020-10-20T00:00:00Z>\",\n}\n\nissues_loader = AirbyteCDKLoader(\n    source_class=SourceGithub, config=config, stream_name=\"issues\"\n)\n\n\nNow you can load documents the usual way\n\ndocs = issues_loader.load()\n\n\nAs load returns a list, it will block until all documents are loaded. To have better control over this process, you can also you the lazy_load method which returns an iterator instead:\n\ndocs_iterator = issues_loader.lazy_load()\n\n\nKeep in mind that by default the page content is empty and the metadata object contains all the information from the record. To create documents in a different, pass in a record_handler function when creating the loader:\n\nfrom langchain.docstore.document import Document\n\n\ndef handle_record(record, id):\n    return Document(\n        page_content=record.data[\"title\"] + \"\\n\" + (record.data[\"body\"] or \"\"),\n        metadata=record.data,\n    )\n\n\nissues_loader = AirbyteCDKLoader(\n    source_class=SourceGithub,\n    config=config,\n    stream_name=\"issues\",\n    record_handler=handle_record,\n)\n\ndocs = issues_loader.load()\n\nIncremental loads‚Äã\n\nSome streams allow incremental loading, this means the source keeps track of synced records and won't load them again. This is useful for sources that have a high volume of data and are updated frequently.\n\nTo take advantage of this, store the last_state property of the loader and pass it in when creating the loader again. This will ensure that only new records are loaded.\n\nlast_state = issues_loader.last_state  # store safely\n\nincremental_issue_loader = AirbyteCDKLoader(\n    source_class=SourceGithub, config=config, stream_name=\"issues\", state=last_state\n)\n\nnew_docs = incremental_issue_loader.load()\n\nPrevious\nacreom\nNext\nAirbyte Gong"
}