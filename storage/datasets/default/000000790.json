{
	"title": "Weights & Biases | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/providers/wandb_tracking",
	"html": "ProvidersMoreWeights & Biases\nWeights & Biases\n\nThis notebook goes over how to track your LangChain experiments into one centralized Weights and Biases dashboard. To learn more about prompt engineering and the callback please refer to this Report which explains both alongside the resultant dashboards you can expect to see.\n\nView Report\n\nNote: the WandbCallbackHandler is being deprecated in favour of the WandbTracer . In future please use the WandbTracer as it is more flexible and allows for more granular logging. To know more about the WandbTracer refer to the agent_with_wandb_tracing.html notebook or use the following colab notebook. To know more about Weights & Biases Prompts refer to the following prompts documentation.\n\npip install wandb\npip install pandas\npip install textstat\npip install spacy\npython -m spacy download en_core_web_sm\n\nimport os\n\nos.environ[\"WANDB_API_KEY\"] = \"\"\n# os.environ[\"OPENAI_API_KEY\"] = \"\"\n# os.environ[\"SERPAPI_API_KEY\"] = \"\"\n\nfrom datetime import datetime\n\nfrom langchain.callbacks import StdOutCallbackHandler, WandbCallbackHandler\nfrom langchain.llms import OpenAI\n\nCallback Handler that logs to Weights and Biases.\n\nParameters:\n    job_type (str): The type of job.\n    project (str): The project to log to.\n    entity (str): The entity to log to.\n    tags (list): The tags to log.\n    group (str): The group to log to.\n    name (str): The name of the run.\n    notes (str): The notes to log.\n    visualize (bool): Whether to visualize the run.\n    complexity_metrics (bool): Whether to log complexity metrics.\n    stream_logs (bool): Whether to stream callback actions to W&B\n\nDefault values for WandbCallbackHandler(...)\n\nvisualize: bool = False,\ncomplexity_metrics: bool = False,\nstream_logs: bool = False,\n\n\nNOTE: For beta workflows we have made the default analysis based on textstat and the visualizations based on spacy\n\n\"\"\"Main function.\n\nThis function is used to try the callback handler.\nScenarios:\n1. OpenAI LLM\n2. Chain with multiple SubChains on multiple generations\n3. Agent with Tools\n\"\"\"\nsession_group = datetime.now().strftime(\"%m.%d.%Y_%H.%M.%S\")\nwandb_callback = WandbCallbackHandler(\n    job_type=\"inference\",\n    project=\"langchain_callback_demo\",\n    group=f\"minimal_{session_group}\",\n    name=\"llm\",\n    tags=[\"test\"],\n)\ncallbacks = [StdOutCallbackHandler(), wandb_callback]\nllm = OpenAI(temperature=0, callbacks=callbacks)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharrison-chase\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\nTracking run with wandb version 0.14.0\n\nRun data is saved locally in <code>/Users/harrisonchase/workplace/langchain/docs/ecosystem/wandb/run-20230318_150408-e47j1914</code>\n\nSyncing run <strong><a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/e47j1914' target=\"_blank\">llm</a></strong> to <a href='https://wandb.ai/harrison-chase/langchain_callback_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>\n\nView project at <a href='https://wandb.ai/harrison-chase/langchain_callback_demo' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo</a>\n\nView run at <a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/e47j1914' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo/runs/e47j1914</a>\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The wandb callback is currently in beta and is subject to change based on updates to `langchain`. Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n\n# Defaults for WandbCallbackHandler.flush_tracker(...)\n\nreset: bool = True,\nfinish: bool = False,\n\n\nThe flush_tracker function is used to log LangChain sessions to Weights & Biases. It takes in the LangChain module or agent, and logs at minimum the prompts and generations alongside the serialized form of the LangChain module to the specified Weights & Biases project. By default we reset the session as opposed to concluding the session outright.\n\n# SCENARIO 1 - LLM\nllm_result = llm.generate([\"Tell me a joke\", \"Tell me a poem\"] * 3)\nwandb_callback.flush_tracker(llm, name=\"simple_sequential\")\n\nWaiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>\n\nView run <strong style=\"color:#cdcd00\">llm</strong> at: <a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/e47j1914' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo/runs/e47j1914</a><br/>Synced 5 W&B file(s), 2 media file(s), 5 artifact file(s) and 0 other file(s)\n\nFind logs at: <code>./wandb/run-20230318_150408-e47j1914/logs</code>\n\nVBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016745895149999985, max=1.0‚Ä¶\n\nTracking run with wandb version 0.14.0\n\nRun data is saved locally in <code>/Users/harrisonchase/workplace/langchain/docs/ecosystem/wandb/run-20230318_150534-jyxma7hu</code>\n\nSyncing run <strong><a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/jyxma7hu' target=\"_blank\">simple_sequential</a></strong> to <a href='https://wandb.ai/harrison-chase/langchain_callback_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>\n\nView project at <a href='https://wandb.ai/harrison-chase/langchain_callback_demo' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo</a>\n\nView run at <a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/jyxma7hu' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo/runs/jyxma7hu</a>\n\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\n\n# SCENARIO 2 - Chain\ntemplate = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\nTitle: {title}\nPlaywright: This is a synopsis for the above play:\"\"\"\nprompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\nsynopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)\n\ntest_prompts = [\n    {\n        \"title\": \"documentary about good video games that push the boundary of game design\"\n    },\n    {\"title\": \"cocaine bear vs heroin wolf\"},\n    {\"title\": \"the best in class mlops tooling\"},\n]\nsynopsis_chain.apply(test_prompts)\nwandb_callback.flush_tracker(synopsis_chain, name=\"agent\")\n\nWaiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>\n\nView run <strong style=\"color:#cdcd00\">simple_sequential</strong> at: <a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/jyxma7hu' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo/runs/jyxma7hu</a><br/>Synced 4 W&B file(s), 2 media file(s), 6 artifact file(s) and 0 other file(s)\n\nFind logs at: <code>./wandb/run-20230318_150534-jyxma7hu/logs</code>\n\nVBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016736786816666675, max=1.0‚Ä¶\n\nTracking run with wandb version 0.14.0\n\nRun data is saved locally in <code>/Users/harrisonchase/workplace/langchain/docs/ecosystem/wandb/run-20230318_150550-wzy59zjq</code>\n\nSyncing run <strong><a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/wzy59zjq' target=\"_blank\">agent</a></strong> to <a href='https://wandb.ai/harrison-chase/langchain_callback_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>\n\nView project at <a href='https://wandb.ai/harrison-chase/langchain_callback_demo' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo</a>\n\nView run at <a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/wzy59zjq' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo/runs/wzy59zjq</a>\n\nfrom langchain.agents import AgentType, initialize_agent, load_tools\n\n# SCENARIO 3 - Agent with Tools\ntools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\nagent = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n)\nagent.run(\n    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\",\n    callbacks=callbacks,\n)\nwandb_callback.flush_tracker(agent, reset=False, finish=True)\n\n> Entering new AgentExecutor chain...\n I need to find out who Leo DiCaprio's girlfriend is and then calculate her age raised to the 0.43 power.\nAction: Search\nAction Input: \"Leo DiCaprio girlfriend\"\nObservation: DiCaprio had a steady girlfriend in Camila Morrone. He had been with the model turned actress for nearly five years, as they were first said to be dating at the end of 2017. And the now 26-year-old Morrone is no stranger to Hollywood.\nThought: I need to calculate her age raised to the 0.43 power.\nAction: Calculator\nAction Input: 26^0.43\nObservation: Answer: 4.059182145592686\n\nThought: I now know the final answer.\nFinal Answer: Leo DiCaprio's girlfriend is Camila Morrone and her current age raised to the 0.43 power is 4.059182145592686.\n\n> Finished chain.\n\nWaiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>\n\nView run <strong style=\"color:#cdcd00\">agent</strong> at: <a href='https://wandb.ai/harrison-chase/langchain_callback_demo/runs/wzy59zjq' target=\"_blank\">https://wandb.ai/harrison-chase/langchain_callback_demo/runs/wzy59zjq</a><br/>Synced 5 W&B file(s), 2 media file(s), 7 artifact file(s) and 0 other file(s)\n\nFind logs at: <code>./wandb/run-20230318_150550-wzy59zjq/logs</code>\n\nPrevious\nWandB Tracing\nNext\nWeather"
}