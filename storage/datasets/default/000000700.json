{
	"title": "Konko | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/providers/konko",
	"html": "ProvidersMoreKonko\nKonko\n\nThis page covers how to run models on Konko within LangChain.\n\nKonko API is a fully managed API designed to help application developers:\n\nSelect the right LLM(s) for their application Prototype with various open-source and proprietary LLMs Move to production in-line with their security, privacy, throughput, latency SLAs without infrastructure set-up or administration using Konko AI's SOC 2 compliant infrastructure\n\nInstallation and Setup‚Äã\nFirst you'll need an API key‚Äã\n\nYou can request it by messaging support@konko.ai\n\nInstall Konko AI's Python SDK‚Äã\n1. Enable a Python3.8+ environment‚Äã\n2. Set API Keys‚Äã\nOption 1: Set Environment Variables‚Äã\n\nYou can set environment variables for\n\nKONKO_API_KEY (Required)\nOPENAI_API_KEY (Optional)\n\nIn your current shell session, use the export command:\n\nexport KONKO_API_KEY={your_KONKO_API_KEY_here}\nexport OPENAI_API_KEY={your_OPENAI_API_KEY_here} #Optional\n\n\nAlternatively, you can add the above lines directly to your shell startup script (such as .bashrc or .bash_profile for Bash shell and .zshrc for Zsh shell) to have them set automatically every time a new shell session starts.\n\nOption 2: Set API Keys Programmatically‚Äã\n\nIf you prefer to set your API keys directly within your Python script or Jupyter notebook, you can use the following commands:\n\nkonko.set_api_key('your_KONKO_API_KEY_here')  \nkonko.set_openai_api_key('your_OPENAI_API_KEY_here') # Optional\n\n3. Install the SDK‚Äã\npip install konko\n\n4. Verify Installation & Authentication‚Äã\n#Confirm konko has installed successfully\nimport konko\n#Confirm API keys from Konko and OpenAI are set properly\nkonko.Model.list()\n\nCalling a model‚Äã\n\nFind a model on the Konko Introduction page\n\nFor example, for this LLama 2 model. The model id would be: \"meta-llama/Llama-2-13b-chat-hf\"\n\nAnother way to find the list of models running on the Konko instance is through this endpoint.\n\nFrom here, we can initialize our model:\n\nchat_instance = ChatKonko(max_tokens=10, model = 'meta-llama/Llama-2-13b-chat-hf')\n\n\nAnd run it:\n\nmsg = HumanMessage(content=\"Hi\")\nchat_response = chat_instance([msg])\n\nPrevious\nJohnsnowlabs\nNext\nLanceDB"
}