{
	"title": "Arxiv | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/retrievers/arxiv",
	"html": "ComponentsRetrieversArxiv\nArxiv\n\narXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.\n\nThis notebook shows how to retrieve scientific articles from Arxiv.org into the Document format that is used downstream.\n\nInstallationâ€‹\n\nFirst, you need to install arxiv python package.\n\n#!pip install arxiv\n\n\nArxivRetriever has these arguments:\n\noptional load_max_docs: default=100. Use it to limit number of downloaded documents. It takes time to download all 100 documents, so use a small number for experiments. There is a hard limit of 300 for now.\noptional load_all_available_meta: default=False. By default only the most important fields downloaded: Published (date when document was published/last updated), Title, Authors, Summary. If True, other fields also downloaded.\n\nget_relevant_documents() has one argument, query: free text which used to find documents in Arxiv.org\n\nExamplesâ€‹\nRunning retrieverâ€‹\nfrom langchain.retrievers import ArxivRetriever\n\nretriever = ArxivRetriever(load_max_docs=2)\n\ndocs = retriever.get_relevant_documents(query=\"1605.08386\")\n\ndocs[0].metadata  # meta-information of the Document\n\n    {'Published': '2016-05-26',\n     'Title': 'Heat-bath random walks with Markov bases',\n     'Authors': 'Caprice Stanley, Tobias Windisch',\n     'Summary': 'Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.'}\n\ndocs[0].page_content[:400]  # a content of the Document\n\n    'arXiv:1605.08386v1  [math.CO]  26 May 2016\\nHEAT-BATH RANDOM WALKS WITH MARKOV BASES\\nCAPRICE STANLEY AND TOBIAS WINDISCH\\nAbstract. Graphs on lattice points are studied whose edges come from a ï¬nite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on ï¬bers of a\\nï¬xed integer matrix can be bounded from above by a constant. We then study the mixing\\nbehaviour of heat-b'\n\nQuestion Answering on factsâ€‹\n# get a token: https://platform.openai.com/account/api-keys\n\nfrom getpass import getpass\n\nOPENAI_API_KEY = getpass()\n\n     Â·Â·Â·Â·Â·Â·Â·Â·\n\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.chat_models import ChatOpenAI\n\nmodel = ChatOpenAI(model_name=\"gpt-3.5-turbo\")  # switch to 'gpt-4'\nqa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)\n\nquestions = [\n    \"What are Heat-bath random walks with Markov base?\",\n    \"What is the ImageBind model?\",\n    \"How does Compositional Reasoning with Large Language Models works?\",\n]\nchat_history = []\n\nfor question in questions:\n    result = qa({\"question\": question, \"chat_history\": chat_history})\n    chat_history.append((question, result[\"answer\"]))\n    print(f\"-> **Question**: {question} \\n\")\n    print(f\"**Answer**: {result['answer']} \\n\")\n\n    -> **Question**: What are Heat-bath random walks with Markov base? \n    \n    **Answer**: I'm not sure, as I don't have enough context to provide a definitive answer. The term \"Heat-bath random walks with Markov base\" is not mentioned in the given text. Could you provide more information or context about where you encountered this term? \n    \n    -> **Question**: What is the ImageBind model? \n    \n    **Answer**: ImageBind is an approach developed by Facebook AI Research to learn a joint embedding across six different modalities, including images, text, audio, depth, thermal, and IMU data. The approach uses the binding property of images to align each modality's embedding to image embeddings and achieve an emergent alignment across all modalities. This enables novel multimodal capabilities, including cross-modal retrieval, embedding-space arithmetic, and audio-to-image generation, among others. The approach sets a new state-of-the-art on emergent zero-shot recognition tasks across modalities, outperforming specialist supervised models. Additionally, it shows strong few-shot recognition results and serves as a new way to evaluate vision models for visual and non-visual tasks. \n    \n    -> **Question**: How does Compositional Reasoning with Large Language Models works? \n    \n    **Answer**: Compositional reasoning with large language models refers to the ability of these models to correctly identify and represent complex concepts by breaking them down into smaller, more basic parts and combining them in a structured way. This involves understanding the syntax and semantics of language and using that understanding to build up more complex meanings from simpler ones. \n    \n    In the context of the paper \"Does CLIP Bind Concepts? Probing Compositionality in Large Image Models\", the authors focus specifically on the ability of a large pretrained vision and language model (CLIP) to encode compositional concepts and to bind variables in a structure-sensitive way. They examine CLIP's ability to compose concepts in a single-object setting, as well as in situations where concept binding is needed. \n    \n    The authors situate their work within the tradition of research on compositional distributional semantics models (CDSMs), which seek to bridge the gap between distributional models and formal semantics by building architectures which operate over vectors yet still obey traditional theories of linguistic composition. They compare the performance of CLIP with several architectures from research on CDSMs to evaluate its ability to encode and reason about compositional concepts. \n    \n\nquestions = [\n    \"What are Heat-bath random walks with Markov base? Include references to answer.\",\n]\nchat_history = []\n\nfor question in questions:\n    result = qa({\"question\": question, \"chat_history\": chat_history})\n    chat_history.append((question, result[\"answer\"]))\n    print(f\"-> **Question**: {question} \\n\")\n    print(f\"**Answer**: {result['answer']} \\n\")\n\n    -> **Question**: What are Heat-bath random walks with Markov base? Include references to answer. \n    \n    **Answer**: Heat-bath random walks with Markov base (HB-MB) is a class of stochastic processes that have been studied in the field of statistical mechanics and condensed matter physics. In these processes, a particle moves in a lattice by making a transition to a neighboring site, which is chosen according to a probability distribution that depends on the energy of the particle and the energy of its surroundings.\n    \n    The HB-MB process was introduced by Bortz, Kalos, and Lebowitz in 1975 as a way to simulate the dynamics of interacting particles in a lattice at thermal equilibrium. The method has been used to study a variety of physical phenomena, including phase transitions, critical behavior, and transport properties.\n    \n    References:\n    \n    Bortz, A. B., Kalos, M. H., & Lebowitz, J. L. (1975). A new algorithm for Monte Carlo simulation of Ising spin systems. Journal of Computational Physics, 17(1), 10-18.\n    \n    Binder, K., & Heermann, D. W. (2010). Monte Carlo simulation in statistical physics: an introduction. Springer Science & Business Media. \n    \n\nPrevious\nArcee Retriever\nNext\nAzure Cognitive Search"
}