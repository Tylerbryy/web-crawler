{
	"title": "Parallelize steps | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/expression_language/how_to/map",
	"html": "LangChain Expression LanguageHow toParallelize steps\nParallelize steps\n\nRunnableParallel (aka. RunnableMap) makes it easy to execute multiple Runnables in parallel, and to return the output of these Runnables as a map.\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.schema.runnable import RunnableParallel\n\nmodel = ChatOpenAI()\njoke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\npoem_chain = (\n    ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\") | model\n)\n\nmap_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n\nmap_chain.invoke({\"topic\": \"bear\"})\n\n    {'joke': AIMessage(content=\"Why don't bears wear shoes? \\n\\nBecause they have bear feet!\", additional_kwargs={}, example=False),\n     'poem': AIMessage(content=\"In woodland depths, bear prowls with might,\\nSilent strength, nature's sovereign, day and night.\", additional_kwargs={}, example=False)}\n\nManipulating outputs/inputs‚Äã\n\nMaps can be useful for manipulating the output of one Runnable to match the input format of the next Runnable in a sequence.\n\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.vectorstores import FAISS\n\nvectorstore = FAISS.from_texts(\n    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n)\nretriever = vectorstore.as_retriever()\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\nretrieval_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\nretrieval_chain.invoke(\"where did harrison work?\")\n\n    'Harrison worked at Kensho.'\n\n\nHere the input to prompt is expected to be a map with keys \"context\" and \"question\". The user input is just the question. So we need to get the context using our retriever and passthrough the user input under the \"question\" key.\n\nNote that when composing a RunnableMap when another Runnable we don't even need to wrap our dictionary in the RunnableMap class ‚Äî¬†the type conversion is handled for us.\n\nParallelism‚Äã\n\nRunnableMaps are also useful for running independent processes in parallel, since each Runnable in the map is executed in parallel. For example, we can see our earlier joke_chain, poem_chain and map_chain all have about the same runtime, even though map_chain executes both of the other two.\n\njoke_chain.invoke({\"topic\": \"bear\"})\n\n    958 ms ¬± 402 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\npoem_chain.invoke({\"topic\": \"bear\"})\n\n    1.22 s ¬± 508 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\nmap_chain.invoke({\"topic\": \"bear\"})\n\n    1.15 s ¬± 119 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n\nPrevious\nStream custom generator functions\nNext\nAdd message history (memory)"
}