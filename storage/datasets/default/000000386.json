{
	"title": "Structured output parser | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/modules/model_io/output_parsers/structured",
	"html": "ModulesModel I/OOutput parsersStructured output parser\nStructured output parser\n\nThis output parser can be used when you want to return multiple fields. While the Pydantic/JSON parser is more powerful, we initially experimented with data structures having text fields only.\n\nfrom langchain.output_parsers import StructuredOutputParser, ResponseSchema\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\nfrom langchain.llms import OpenAI\nfrom langchain.chat_models import ChatOpenAI\n\n\nHere we define the response schema we want to receive.\n\nresponse_schemas = [\n    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n    ResponseSchema(name=\"source\", description=\"source used to answer the user's question, should be a website.\")\n]\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n\n\nWe now get a string that contains instructions for how the response should be formatted, and we then insert that into our prompt.\n\nformat_instructions = output_parser.get_format_instructions()\nprompt = PromptTemplate(\n    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n    input_variables=[\"question\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n\nWe can now use this to format a prompt to send to the language model, and then parse the returned result.\n\nmodel = OpenAI(temperature=0)\n\n_input = prompt.format_prompt(question=\"what's the capital of france?\")\noutput = model(_input.to_string())\n\noutput_parser.parse(output)\n\n    {'answer': 'Paris',\n     'source': 'https://www.worldatlas.com/articles/what-is-the-capital-of-france.html'}\n\n\nAnd here's an example of using this in a chat model\n\nchat_model = ChatOpenAI(temperature=0)\n\nprompt = ChatPromptTemplate(\n    messages=[\n        HumanMessagePromptTemplate.from_template(\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\")\n    ],\n    input_variables=[\"question\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n_input = prompt.format_prompt(question=\"what's the capital of france?\")\noutput = chat_model(_input.to_messages())\n\noutput_parser.parse(output.content)\n\n    {'answer': 'Paris', 'source': 'https://en.wikipedia.org/wiki/Paris'}\n\nPrevious\nRetry parser\nNext\nXML parser"
}