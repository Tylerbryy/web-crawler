{
	"title": "SearchApi | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/tools/searchapi",
	"html": "ComponentsToolsSearchApi\nSearchApi\n\nThis notebook shows examples of how to use SearchApi to search the web. Go to https://www.searchapi.io/ to sign up for a free account and get API key.\n\nimport os\n\nos.environ[\"SEARCHAPI_API_KEY\"] = \"\"\n\nfrom langchain.utilities import SearchApiAPIWrapper\n\nsearch = SearchApiAPIWrapper()\n\nsearch.run(\"Obama's first name?\")\n\n    'Barack Hussein Obama II'\n\nUsing as part of a Self Ask With Search Chain‚Äã\nos.environ[\"OPENAI_API_KEY\"] = \"\"\n\nfrom langchain.agents import AgentType, Tool, initialize_agent\nfrom langchain.llms.openai import OpenAI\nfrom langchain.utilities import SearchApiAPIWrapper\n\nllm = OpenAI(temperature=0)\nsearch = SearchApiAPIWrapper()\ntools = [\n    Tool(\n        name=\"Intermediate Answer\",\n        func=search.run,\n        description=\"useful for when you need to ask with search\",\n    )\n]\n\nself_ask_with_search = initialize_agent(\n    tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True\n)\nself_ask_with_search.run(\"Who lived longer: Plato, Socrates, or Aristotle?\")\n\n    \n    \n    > Entering new AgentExecutor chain...\n     Yes.\n    Follow up: How old was Plato when he died?\n    Intermediate answer: eighty\n    Follow up: How old was Socrates when he died?\n    Intermediate answer: | Socrates | \n    | -------- | \n    | Born | c. 470 BC Deme Alopece, Athens | \n    | Died | 399 BC (aged approximately 71) Athens | \n    | Cause of death | Execution by forced suicide by poisoning | \n    | Spouse(s) | Xanthippe, Myrto | \n    \n    Follow up: How old was Aristotle when he died?\n    Intermediate answer: 62 years\n    So the final answer is: Plato\n    \n    > Finished chain.\n\n\n\n\n\n    'Plato'\n\nCustom parameters‚Äã\n\nSearchApi wrapper can be customized to use different engines like Google News, Google Jobs, Google Scholar, or others which can be found in SearchApi documentation. All parameters supported by SearchApi can be passed when executing the query.\n\nsearch = SearchApiAPIWrapper(engine=\"google_jobs\")\n\nsearch.run(\"AI Engineer\", location=\"Portugal\", gl=\"pt\")[0:500]\n\n    'Azure AI Engineer Be an XpanderCandidatar-meCandidatar-meCandidatar-me\\n\\nShare:\\n\\nAzure AI Engineer\\n\\nA √°rea Digital Xperience da Xpand IT √© uma equipa tecnol√≥gica de r√°pido crescimento que se concentra em tecnologias Microsoft e Mobile. A sua principal miss√£o √© fornecer solu√ß√µes de software de alta qualidade que atendam √†s necessidades do utilizador final, num mundo tecnol√≥gico continuamente exigente e em ritmo acelerado, proporcionando a melhor experi√™ncia em termos de personaliza√ß√£o, performance'\n\nGetting results with metadata‚Äã\nimport pprint\n\nsearch = SearchApiAPIWrapper(engine=\"google_scholar\")\nresults = search.results(\"Large Language Models\")\npprint.pp(results)\n\n    {'search_metadata': {'id': 'search_qVdXG2jzvrlqTzayeYoaOb8A',\n                         'status': 'Success',\n                         'created_at': '2023-09-25T15:22:30Z',\n                         'request_time_taken': 3.21,\n                         'parsing_time_taken': 0.03,\n                         'total_time_taken': 3.24,\n                         'request_url': 'https://scholar.google.com/scholar?q=Large+Language+Models&hl=en',\n                         'html_url': 'https://www.searchapi.io/api/v1/searches/search_qVdXG2jzvrlqTzayeYoaOb8A.html',\n                         'json_url': 'https://www.searchapi.io/api/v1/searches/search_qVdXG2jzvrlqTzayeYoaOb8A'},\n     'search_parameters': {'engine': 'google_scholar',\n                           'q': 'Large Language Models',\n                           'hl': 'en'},\n     'search_information': {'query_displayed': 'Large Language Models',\n                            'total_results': 6420000,\n                            'page': 1,\n                            'time_taken_displayed': 0.06},\n     'organic_results': [{'position': 1,\n                          'title': 'ChatGPT for good? On opportunities and '\n                                   'challenges of large language models for '\n                                   'education',\n                          'data_cid': 'uthwmf2nU3EJ',\n                          'link': 'https://www.sciencedirect.com/science/article/pii/S1041608023000195',\n                          'publication': 'E Kasneci, K Se√üler, S K√ºchemann, M '\n                                         'Bannert‚Ä¶ - Learning and individual ‚Ä¶, '\n                                         '2023 - Elsevier',\n                          'snippet': '‚Ä¶ state of large language models and their '\n                                     'applications. We then highlight how these '\n                                     'models can be ‚Ä¶ With regard to challenges, '\n                                     'we argue that large language models in '\n                                     'education require ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '8166055256995715258',\n                                                        'total': 410,\n                                                        'link': 'https://scholar.google.com/scholar?cites=8166055256995715258&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '8166055256995715258',\n                                                        'total': 10,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=8166055256995715258&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:uthwmf2nU3EJ:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'edarxiv.org',\n                                       'format': 'PDF',\n                                       'link': 'https://edarxiv.org/5er8f/download?format=pdf'},\n                          'authors': [{'name': 'E Kasneci',\n                                       'id': 'bZVkVvoAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=bZVkVvoAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'K Se√üler',\n                                       'id': 'MbMBoN4AAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=MbMBoN4AAAAJ&hl=en&oi=sra'},\n                                      {'name': 'S K√ºchemann',\n                                       'id': 'g1jX5QUAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=g1jX5QUAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'M Bannert',\n                                       'id': 'TjfQ8QkAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=TjfQ8QkAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 2,\n                          'title': 'Large language models in medicine',\n                          'data_cid': 'Ph9AwHTmhzAJ',\n                          'link': 'https://www.nature.com/articles/s41591-023-02448-8',\n                          'publication': 'AJ Thirunavukarasu, DSJ Ting, K '\n                                         'Elangovan‚Ä¶ - Nature medicine, 2023 - '\n                                         'nature.com',\n                          'snippet': '‚Ä¶ HuggingChat offers a free-to-access '\n                                     'chatbot with a similar interface to ChatGPT '\n                                     'but uses Large Language Model Meta AI '\n                                     '(LLaMA) as its backend model 30 . Finally, '\n                                     'cheap imitations of ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '3497017024792502078',\n                                                        'total': 25,\n                                                        'link': 'https://scholar.google.com/scholar?cites=3497017024792502078&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '3497017024792502078',\n                                                        'total': 3,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=3497017024792502078&hl=en&as_sdt=0,33'}},\n                          'authors': [{'name': 'AJ Thirunavukarasu',\n                                       'id': '3qb1AYwAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=3qb1AYwAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'DSJ Ting',\n                                       'id': 'KbrpC8cAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=KbrpC8cAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'K Elangovan',\n                                       'id': 'BE_lVTQAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=BE_lVTQAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 3,\n                          'title': 'Extracting training data from large language '\n                                   'models',\n                          'data_cid': 'mEYsWK6bWKoJ',\n                          'link': 'https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting',\n                          'publication': 'N Carlini, F Tramer, E Wallace, M '\n                                         'Jagielski‚Ä¶ - 30th USENIX Security ‚Ä¶, '\n                                         '2021 - usenix.org',\n                          'snippet': '‚Ä¶ language model trained on scrapes of the '\n                                     'public Internet, and are able to extract '\n                                     'hundreds of verbatim text sequences from the '\n                                     'model‚Äô‚Ä¶ models are more vulnerable than '\n                                     'smaller models. ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '12274731957504198296',\n                                                        'total': 742,\n                                                        'link': 'https://scholar.google.com/scholar?cites=12274731957504198296&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '12274731957504198296',\n                                                        'total': 8,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=12274731957504198296&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:mEYsWK6bWKoJ:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33',\n                                           'cached_page_link': 'https://scholar.googleusercontent.com/scholar?q=cache:mEYsWK6bWKoJ:scholar.google.com/+Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'usenix.org',\n                                       'format': 'PDF',\n                                       'link': 'https://www.usenix.org/system/files/sec21-carlini-extracting.pdf'},\n                          'authors': [{'name': 'N Carlini',\n                                       'id': 'q4qDvAoAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=q4qDvAoAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'F Tramer',\n                                       'id': 'ijH0-a8AAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=ijH0-a8AAAAJ&hl=en&oi=sra'},\n                                      {'name': 'E Wallace',\n                                       'id': 'SgST3LkAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=SgST3LkAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'M Jagielski',\n                                       'id': '_8rw_GMAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=_8rw_GMAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 4,\n                          'title': 'Emergent abilities of large language models',\n                          'data_cid': 'hG0iVOrOguoJ',\n                          'link': 'https://arxiv.org/abs/2206.07682',\n                          'publication': 'J Wei, Y Tay, R Bommasani, C Raffel, B '\n                                         'Zoph‚Ä¶ - arXiv preprint arXiv ‚Ä¶, 2022 - '\n                                         'arxiv.org',\n                          'snippet': 'Scaling up language models has been shown to '\n                                     'predictably improve performance and sample '\n                                     'efficiency on a wide range of downstream '\n                                     'tasks. This paper instead discusses an ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '16898296257676733828',\n                                                        'total': 621,\n                                                        'link': 'https://scholar.google.com/scholar?cites=16898296257676733828&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '16898296257676733828',\n                                                        'total': 12,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=16898296257676733828&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:hG0iVOrOguoJ:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33',\n                                           'cached_page_link': 'https://scholar.googleusercontent.com/scholar?q=cache:hG0iVOrOguoJ:scholar.google.com/+Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'arxiv.org',\n                                       'format': 'PDF',\n                                       'link': 'https://arxiv.org/pdf/2206.07682.pdf?trk=cndc-detail'},\n                          'authors': [{'name': 'J Wei',\n                                       'id': 'wA5TK_0AAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=wA5TK_0AAAAJ&hl=en&oi=sra'},\n                                      {'name': 'Y Tay',\n                                       'id': 'VBclY_cAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=VBclY_cAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'R Bommasani',\n                                       'id': 'WMBXw1EAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=WMBXw1EAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'C Raffel',\n                                       'id': 'I66ZBYwAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=I66ZBYwAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'B Zoph',\n                                       'id': 'NL_7iTwAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=NL_7iTwAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 5,\n                          'title': 'A survey on evaluation of large language '\n                                   'models',\n                          'data_cid': 'ZYohnzOz-XgJ',\n                          'link': 'https://arxiv.org/abs/2307.03109',\n                          'publication': 'Y Chang, X Wang, J Wang, Y Wu, K Zhu‚Ä¶ - '\n                                         'arXiv preprint arXiv ‚Ä¶, 2023 - arxiv.org',\n                          'snippet': '‚Ä¶ 3.1 Natural Language Processing Tasks ‚Ä¶ '\n                                     'the development of language models, '\n                                     'particularly large language models, was to '\n                                     'enhance performance on natural language '\n                                     'processing tasks, ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '8717195588046785125',\n                                                        'total': 31,\n                                                        'link': 'https://scholar.google.com/scholar?cites=8717195588046785125&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '8717195588046785125',\n                                                        'total': 3,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=8717195588046785125&hl=en&as_sdt=0,33'},\n                                           'cached_page_link': 'https://scholar.googleusercontent.com/scholar?q=cache:ZYohnzOz-XgJ:scholar.google.com/+Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'arxiv.org',\n                                       'format': 'PDF',\n                                       'link': 'https://arxiv.org/pdf/2307.03109'},\n                          'authors': [{'name': 'X Wang',\n                                       'id': 'Q7Ieos8AAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=Q7Ieos8AAAAJ&hl=en&oi=sra'},\n                                      {'name': 'J Wang',\n                                       'id': 'YomxTXQAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=YomxTXQAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'Y Wu',\n                                       'id': 'KVeRu2QAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=KVeRu2QAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'K Zhu',\n                                       'id': 'g75dFLYAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=g75dFLYAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 6,\n                          'title': 'Evaluating large language models trained on '\n                                   'code',\n                          'data_cid': '3tNvW3l5nU4J',\n                          'link': 'https://arxiv.org/abs/2107.03374',\n                          'publication': 'M Chen, J Tworek, H Jun, Q Yuan, HPO '\n                                         'Pinto‚Ä¶ - arXiv preprint arXiv ‚Ä¶, 2021 - '\n                                         'arxiv.org',\n                          'snippet': '‚Ä¶ We introduce Codex, a GPT language model '\n                                     'finetuned on publicly available code from '\n                                     'GitHub, and study its Python code-writing '\n                                     'capabilities. A distinct production version '\n                                     'of Codex ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '5664817468434011102',\n                                                        'total': 941,\n                                                        'link': 'https://scholar.google.com/scholar?cites=5664817468434011102&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '5664817468434011102',\n                                                        'total': 2,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=5664817468434011102&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:3tNvW3l5nU4J:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33',\n                                           'cached_page_link': 'https://scholar.googleusercontent.com/scholar?q=cache:3tNvW3l5nU4J:scholar.google.com/+Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'arxiv.org',\n                                       'format': 'PDF',\n                                       'link': 'https://arxiv.org/pdf/2107.03374.pdf?trk=public_post_comment-text'},\n                          'authors': [{'name': 'M Chen',\n                                       'id': '5fU-QMwAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=5fU-QMwAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'J Tworek',\n                                       'id': 'ZPuESCQAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=ZPuESCQAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'Q Yuan',\n                                       'id': 'B059m2EAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=B059m2EAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 7,\n                          'title': 'Large language models in machine translation',\n                          'data_cid': 'sY5m_Y3-0Y4J',\n                          'link': 'http://research.google/pubs/pub33278.pdf',\n                          'publication': 'T Brants, AC Popat, P Xu, FJ Och, J Dean '\n                                         '- 2007 - research.google',\n                          'snippet': '‚Ä¶ the benefits of largescale statistical '\n                                     'language modeling in ma‚Ä¶ trillion tokens, '\n                                     'resulting in language models having up to '\n                                     '300 ‚Ä¶ is inexpensive to train on large data '\n                                     'sets and approaches the ‚Ä¶',\n                          'type': 'PDF',\n                          'inline_links': {'cited_by': {'cites_id': '10291286509313494705',\n                                                        'total': 737,\n                                                        'link': 'https://scholar.google.com/scholar?cites=10291286509313494705&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '10291286509313494705',\n                                                        'total': 31,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=10291286509313494705&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:sY5m_Y3-0Y4J:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33',\n                                           'cached_page_link': 'https://scholar.googleusercontent.com/scholar?q=cache:sY5m_Y3-0Y4J:scholar.google.com/+Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'research.google',\n                                       'format': 'PDF',\n                                       'link': 'http://research.google/pubs/pub33278.pdf'},\n                          'authors': [{'name': 'FJ Och',\n                                       'id': 'ITGdg6oAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=ITGdg6oAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'J Dean',\n                                       'id': 'NMS69lQAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=NMS69lQAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 8,\n                          'title': 'A watermark for large language models',\n                          'data_cid': 'BlSyLHT4iiEJ',\n                          'link': 'https://arxiv.org/abs/2301.10226',\n                          'publication': 'J Kirchenbauer, J Geiping, Y Wen, J '\n                                         'Katz‚Ä¶ - arXiv preprint arXiv ‚Ä¶, 2023 - '\n                                         'arxiv.org',\n                          'snippet': '‚Ä¶ To derive this watermark, we examine what '\n                                     'happens in the language model just before it '\n                                     'produces a probability vector. The last '\n                                     'layer of the language model outputs a vector '\n                                     'of logits l(t). ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '2417017327887471622',\n                                                        'total': 104,\n                                                        'link': 'https://scholar.google.com/scholar?cites=2417017327887471622&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '2417017327887471622',\n                                                        'total': 4,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=2417017327887471622&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:BlSyLHT4iiEJ:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33',\n                                           'cached_page_link': 'https://scholar.googleusercontent.com/scholar?q=cache:BlSyLHT4iiEJ:scholar.google.com/+Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'arxiv.org',\n                                       'format': 'PDF',\n                                       'link': 'https://arxiv.org/pdf/2301.10226.pdf?curius=1419'},\n                          'authors': [{'name': 'J Kirchenbauer',\n                                       'id': '48GJrbsAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=48GJrbsAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'J Geiping',\n                                       'id': '206vNCEAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=206vNCEAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'Y Wen',\n                                       'id': 'oUYfjg0AAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=oUYfjg0AAAAJ&hl=en&oi=sra'},\n                                      {'name': 'J Katz',\n                                       'id': 'yPw4WjoAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=yPw4WjoAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 9,\n                          'title': 'ChatGPT and other large language models are '\n                                   'double-edged swords',\n                          'data_cid': 'So0q8TRvxhYJ',\n                          'link': 'https://pubs.rsna.org/doi/full/10.1148/radiol.230163',\n                          'publication': 'Y Shen, L Heacock, J Elias, KD Hentel, B '\n                                         'Reig, G Shih‚Ä¶ - Radiology, 2023 - '\n                                         'pubs.rsna.org',\n                          'snippet': '‚Ä¶ Large Language Models (LLMs) are deep '\n                                     'learning models trained to understand and '\n                                     'generate natural language. Recent studies '\n                                     'demonstrated that LLMs achieve great success '\n                                     'in a ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '1641121387398204746',\n                                                        'total': 231,\n                                                        'link': 'https://scholar.google.com/scholar?cites=1641121387398204746&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '1641121387398204746',\n                                                        'total': 3,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=1641121387398204746&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:So0q8TRvxhYJ:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'authors': [{'name': 'Y Shen',\n                                       'id': 'XaeN2zgAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=XaeN2zgAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'L Heacock',\n                                       'id': 'tYYM5IkAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=tYYM5IkAAAAJ&hl=en&oi=sra'}]},\n                         {'position': 10,\n                          'title': 'Pythia: A suite for analyzing large language '\n                                   'models across training and scaling',\n                          'data_cid': 'aaIDvsMAD8QJ',\n                          'link': 'https://proceedings.mlr.press/v202/biderman23a.html',\n                          'publication': 'S Biderman, H Schoelkopf‚Ä¶ - '\n                                         'International ‚Ä¶, 2023 - '\n                                         'proceedings.mlr.press',\n                          'snippet': '‚Ä¶ large language models, we prioritize '\n                                     'consistency in model ‚Ä¶ out the most '\n                                     'performance from each model. For example, we '\n                                     '‚Ä¶ models, as it is becoming widely used for '\n                                     'the largest models, ‚Ä¶',\n                          'inline_links': {'cited_by': {'cites_id': '14127511396791067241',\n                                                        'total': 89,\n                                                        'link': 'https://scholar.google.com/scholar?cites=14127511396791067241&as_sdt=5,33&sciodt=0,33&hl=en'},\n                                           'versions': {'cluster_id': '14127511396791067241',\n                                                        'total': 3,\n                                                        'link': 'https://scholar.google.com/scholar?cluster=14127511396791067241&hl=en&as_sdt=0,33'},\n                                           'related_articles_link': 'https://scholar.google.com/scholar?q=related:aaIDvsMAD8QJ:scholar.google.com/&scioq=Large+Language+Models&hl=en&as_sdt=0,33',\n                                           'cached_page_link': 'https://scholar.googleusercontent.com/scholar?q=cache:aaIDvsMAD8QJ:scholar.google.com/+Large+Language+Models&hl=en&as_sdt=0,33'},\n                          'resource': {'name': 'mlr.press',\n                                       'format': 'PDF',\n                                       'link': 'https://proceedings.mlr.press/v202/biderman23a/biderman23a.pdf'},\n                          'authors': [{'name': 'S Biderman',\n                                       'id': 'bO7H0DAAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=bO7H0DAAAAAJ&hl=en&oi=sra'},\n                                      {'name': 'H Schoelkopf',\n                                       'id': 'XLahYIYAAAAJ',\n                                       'link': 'https://scholar.google.com/citations?user=XLahYIYAAAAJ&hl=en&oi=sra'}]}],\n     'related_searches': [{'query': 'large language models machine',\n                           'highlighted': ['machine'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=1&q=large+language+models+machine&qst=ib'},\n                          {'query': 'large language models pruning',\n                           'highlighted': ['pruning'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=2&q=large+language+models+pruning&qst=ib'},\n                          {'query': 'large language models multitask learners',\n                           'highlighted': ['multitask learners'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=3&q=large+language+models+multitask+learners&qst=ib'},\n                          {'query': 'large language models speech recognition',\n                           'highlighted': ['speech recognition'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=4&q=large+language+models+speech+recognition&qst=ib'},\n                          {'query': 'large language models machine translation',\n                           'highlighted': ['machine translation'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=5&q=large+language+models+machine+translation&qst=ib'},\n                          {'query': 'emergent abilities of large language models',\n                           'highlighted': ['emergent abilities of'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=6&q=emergent+abilities+of+large+language+models&qst=ir'},\n                          {'query': 'language models privacy risks',\n                           'highlighted': ['privacy risks'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=7&q=language+models+privacy+risks&qst=ir'},\n                          {'query': 'language model fine tuning',\n                           'highlighted': ['fine tuning'],\n                           'link': 'https://scholar.google.com/scholar?hl=en&as_sdt=0,33&qsp=8&q=language+model+fine+tuning&qst=ir'}],\n     'pagination': {'current': 1,\n                    'next': 'https://scholar.google.com/scholar?start=10&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                    'other_pages': {'2': 'https://scholar.google.com/scholar?start=10&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '3': 'https://scholar.google.com/scholar?start=20&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '4': 'https://scholar.google.com/scholar?start=30&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '5': 'https://scholar.google.com/scholar?start=40&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '6': 'https://scholar.google.com/scholar?start=50&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '7': 'https://scholar.google.com/scholar?start=60&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '8': 'https://scholar.google.com/scholar?start=70&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '9': 'https://scholar.google.com/scholar?start=80&q=Large+Language+Models&hl=en&as_sdt=0,33',\n                                    '10': 'https://scholar.google.com/scholar?start=90&q=Large+Language+Models&hl=en&as_sdt=0,33'}}}\n\nPrevious\nSearch Tools\nNext\nSearxNG Search"
}