{
	"title": "Google Vertex AI Vector Search | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/vectorstores/matchingengine",
	"html": "ComponentsVector storesGoogle Vertex AI Vector Search\nGoogle Vertex AI Vector Search\n\nThis notebook shows how to use functionality related to the Google Cloud Vertex AI Vector Search vector database.\n\nGoogle Vertex AI Vector Search, formerly known as Vertex AI Matching Engine, provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.\n\nNote: This module expects an endpoint and deployed index already created as the creation time takes close to one hour. To see how to create an index refer to the section Create Index and deploy it to an Endpoint\n\nCreate VectorStore from texts‚Äã\nfrom langchain.vectorstores import MatchingEngine\n\ntexts = [\n    \"The cat sat on\",\n    \"the mat.\",\n    \"I like to\",\n    \"eat pizza for\",\n    \"dinner.\",\n    \"The sun sets\",\n    \"in the west.\",\n]\n\n\nvector_store = MatchingEngine.from_components(\n    texts=texts,\n    project_id=\"<my_project_id>\",\n    region=\"<my_region>\",\n    gcs_bucket_uri=\"<my_gcs_bucket>\",\n    index_id=\"<my_matching_engine_index_id>\",\n    endpoint_id=\"<my_matching_engine_endpoint_id>\",\n)\n\nvector_store.add_texts(texts=texts)\n\nvector_store.similarity_search(\"lunch\", k=2)\n\nCreate Index and deploy it to an Endpoint‚Äã\nImports, Constants and Configs‚Äã\n# Installing dependencies.\npip install tensorflow \\\n            google-cloud-aiplatform \\\n            tensorflow-hub \\\n            tensorflow-text\n\nimport json\n\nimport tensorflow_hub as hub\nfrom google.cloud import aiplatform\n\nPROJECT_ID = \"<my_project_id>\"\nREGION = \"<my_region>\"\nVPC_NETWORK = \"<my_vpc_network_name>\"\nPEERING_RANGE_NAME = \"ann-langchain-me-range\"  # Name for creating the VPC peering.\nBUCKET_URI = \"gs://<bucket_uri>\"\n# The number of dimensions for the tensorflow universal sentence encoder.\n# If other embedder is used, the dimensions would probably need to change.\nDIMENSIONS = 512\nDISPLAY_NAME = \"index-test-name\"\nEMBEDDING_DIR = f\"{BUCKET_URI}/banana\"\nDEPLOYED_INDEX_ID = \"endpoint-test-name\"\n\nPROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\nPROJECT_NUMBER = PROJECT_NUMBER[0]\nVPC_NETWORK_FULL = f\"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}\"\n\n# Change this if you need the VPC to be created.\nCREATE_VPC = False\n\n# Set the project id\n gcloud config set project {PROJECT_ID}\n\n# Remove the if condition to run the encapsulated code\nif CREATE_VPC:\n    # Create a VPC network\n gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}\n\n    # Add necessary firewall rules\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389\n gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22\n\n    # Reserve IP range\n gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description=\"peering range\"\n\n    # Set up peering with service networking\n    # Your account must have the \"Compute Network Admin\" role to run the following.\n gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}\n\n# Creating bucket.\n gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI\n\nUsing Tensorflow Universal Sentence Encoder as an Embedder‚Äã\n# Load the Universal Sentence Encoder module\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\nmodel = hub.load(module_url)\n\n# Generate embeddings for each word\nembeddings = model([\"banana\"])\n\nInserting a test embedding‚Äã\ninitial_config = {\n    \"id\": \"banana_id\",\n    \"embedding\": [float(x) for x in list(embeddings.numpy()[0])],\n}\n\nwith open(\"data.json\", \"w\") as f:\n    json.dump(initial_config, f)\ngsutil cp data.json {EMBEDDING_DIR}/file.json\n\naiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n\nCreating Index‚Äã\nmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n    display_name=DISPLAY_NAME,\n    contents_delta_uri=EMBEDDING_DIR,\n    dimensions=DIMENSIONS,\n    approximate_neighbors_count=150,\n    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n)\n\nCreating Endpoint‚Äã\nmy_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n    display_name=f\"{DISPLAY_NAME}-endpoint\",\n    network=VPC_NETWORK_FULL,\n)\n\nDeploy Index‚Äã\nmy_index_endpoint = my_index_endpoint.deploy_index(\n    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID\n)\n\nmy_index_endpoint.deployed_indexes\n\nPrevious\nMarqo\nNext\nMeilisearch"
}