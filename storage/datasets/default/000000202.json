{
	"title": "Alibaba Cloud MaxCompute | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/document_loaders/alibaba_cloud_maxcompute",
	"html": "ComponentsDocument loadersAlibaba Cloud MaxCompute\nAlibaba Cloud MaxCompute\n\nAlibaba Cloud MaxCompute (previously known as ODPS) is a general purpose, fully managed, multi-tenancy data processing platform for large-scale data warehousing. MaxCompute supports various data importing solutions and distributed computing models, enabling users to effectively query massive datasets, reduce production costs, and ensure data security.\n\nThe MaxComputeLoader lets you execute a MaxCompute SQL query and loads the results as one document per row.\n\npip install pyodps\n\n    Collecting pyodps\n      Downloading pyodps-0.11.4.post0-cp39-cp39-macosx_10_9_universal2.whl (2.0 MB)\n         â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.0/2.0 MB 1.7 MB/s eta 0:00:0000:0100:010m\n    Requirement already satisfied: charset-normalizer>=2 in /Users/newboy/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyodps) (3.1.0)\n    Requirement already satisfied: urllib3<2.0,>=1.26.0 in /Users/newboy/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyodps) (1.26.15)\n    Requirement already satisfied: idna>=2.5 in /Users/newboy/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyodps) (3.4)\n    Requirement already satisfied: certifi>=2017.4.17 in /Users/newboy/anaconda3/envs/langchain/lib/python3.9/site-packages (from pyodps) (2023.5.7)\n    Installing collected packages: pyodps\n    Successfully installed pyodps-0.11.4.post0\n\nBasic Usageâ€‹\n\nTo instantiate the loader you'll need a SQL query to execute, your MaxCompute endpoint and project name, and you access ID and secret access key. The access ID and secret access key can either be passed in direct via the access_id and secret_access_key parameters or they can be set as environment variables MAX_COMPUTE_ACCESS_ID and MAX_COMPUTE_SECRET_ACCESS_KEY.\n\nfrom langchain.document_loaders import MaxComputeLoader\n\nbase_query = \"\"\"\nSELECT *\nFROM (\n    SELECT 1 AS id, 'content1' AS content, 'meta_info1' AS meta_info\n    UNION ALL\n    SELECT 2 AS id, 'content2' AS content, 'meta_info2' AS meta_info\n    UNION ALL\n    SELECT 3 AS id, 'content3' AS content, 'meta_info3' AS meta_info\n) mydata;\n\"\"\"\n\nendpoint = \"<ENDPOINT>\"\nproject = \"<PROJECT>\"\nACCESS_ID = \"<ACCESS ID>\"\nSECRET_ACCESS_KEY = \"<SECRET ACCESS KEY>\"\n\nloader = MaxComputeLoader.from_params(\n    base_query,\n    endpoint,\n    project,\n    access_id=ACCESS_ID,\n    secret_access_key=SECRET_ACCESS_KEY,\n)\ndata = loader.load()\n\nprint(data)\n\n    [Document(page_content='id: 1\\ncontent: content1\\nmeta_info: meta_info1', metadata={}), Document(page_content='id: 2\\ncontent: content2\\nmeta_info: meta_info2', metadata={}), Document(page_content='id: 3\\ncontent: content3\\nmeta_info: meta_info3', metadata={})]\n\nprint(data[0].page_content)\n\n    id: 1\n    content: content1\n    meta_info: meta_info1\n\nprint(data[0].metadata)\n\n    {}\n\nSpecifying Which Columns are Content vs Metadataâ€‹\n\nYou can configure which subset of columns should be loaded as the contents of the Document and which as the metadata using the page_content_columns and metadata_columns parameters.\n\nloader = MaxComputeLoader.from_params(\n    base_query,\n    endpoint,\n    project,\n    page_content_columns=[\"content\"],  # Specify Document page content\n    metadata_columns=[\"id\", \"meta_info\"],  # Specify Document metadata\n    access_id=ACCESS_ID,\n    secret_access_key=SECRET_ACCESS_KEY,\n)\ndata = loader.load()\n\nprint(data[0].page_content)\n\n    content: content1\n\nprint(data[0].metadata)\n\n    {'id': 1, 'meta_info': 'meta_info1'}\n\nPrevious\nAirtable\nNext\nApify Dataset"
}