{
	"title": "Run custom functions | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/expression_language/how_to/functions",
	"html": "LangChain Expression LanguageHow toRun custom functions\nRun custom functions\n\nYou can use arbitrary functions in the pipeline\n\nNote that all inputs to these functions need to be a SINGLE argument. If you have a function that accepts multiple arguments, you should write a wrapper that accepts a single input and unpacks it into multiple argument.\n\nfrom operator import itemgetter\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.schema.runnable import RunnableLambda\n\n\ndef length_function(text):\n    return len(text)\n\n\ndef _multiple_length_function(text1, text2):\n    return len(text1) * len(text2)\n\n\ndef multiple_length_function(_dict):\n    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n\n\nprompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\nmodel = ChatOpenAI()\n\nchain1 = prompt | model\n\nchain = (\n    {\n        \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n        | RunnableLambda(multiple_length_function),\n    }\n    | prompt\n    | model\n)\n\nchain.invoke({\"foo\": \"bar\", \"bar\": \"gah\"})\n\n    AIMessage(content='3 + 9 equals 12.', additional_kwargs={}, example=False)\n\nAccepting a Runnable Config‚Äã\n\nRunnable lambdas can optionally accept a RunnableConfig, which they can use to pass callbacks, tags, and other configuration information to nested runs.\n\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain.schema.runnable import RunnableConfig\n\nimport json\n\n\ndef parse_or_fix(text: str, config: RunnableConfig):\n    fixing_chain = (\n        ChatPromptTemplate.from_template(\n            \"Fix the following text:\\n\\n```text\\n{input}\\n```\\nError: {error}\"\n            \" Don't narrate, just respond with the fixed data.\"\n        )\n        | ChatOpenAI()\n        | StrOutputParser()\n    )\n    for _ in range(3):\n        try:\n            return json.loads(text)\n        except Exception as e:\n            text = fixing_chain.invoke({\"input\": text, \"error\": e}, config)\n    return \"Failed to parse\"\n\nfrom langchain.callbacks import get_openai_callback\n\nwith get_openai_callback() as cb:\n    RunnableLambda(parse_or_fix).invoke(\n        \"{foo: bar}\", {\"tags\": [\"my-tag\"], \"callbacks\": [cb]}\n    )\n    print(cb)\n\n    Tokens Used: 65\n        Prompt Tokens: 56\n        Completion Tokens: 9\n    Successful Requests: 1\n    Total Cost (USD): $0.00010200000000000001\n\nPrevious\nAdd fallbacks\nNext\nStream custom generator functions"
}