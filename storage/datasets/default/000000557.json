{
	"title": "Modal | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/modal",
	"html": "ComponentsLLMsModal\nModal\n\nThe Modal cloud platform provides convenient, on-demand access to serverless cloud compute from Python scripts on your local computer. Use modal to run your own custom LLM models instead of depending on LLM APIs.\n\nThis example goes over how to use LangChain to interact with a modal HTTPS web endpoint.\n\nQuestion-answering with LangChain is another example of how to use LangChain alonside Modal. In that example, Modal runs the LangChain application end-to-end and uses OpenAI as its LLM API.\n\npip install modal\n\n# Register an account with Modal and get a new token.\nmodal token new\n\n    Launching login page in your browser window...\n    If this is not showing up, please copy this URL into your web browser manually:\n    https://modal.com/token-flow/tf-Dzm3Y01234mqmm1234Vcu3\n\n\nThe langchain.llms.modal.Modal integration class requires that you deploy a Modal application with a web endpoint that complies with the following JSON interface:\n\nThe LLM prompt is accepted as a str value under the key \"prompt\"\nThe LLM response returned as a str value under the key \"prompt\"\n\nExample request JSON:\n\n{\n    \"prompt\": \"Identify yourself, bot!\",\n    \"extra\": \"args are allowed\",\n}\n\n\nExample response JSON:\n\n{\n    \"prompt\": \"This is the LLM speaking\",\n}\n\n\nAn example 'dummy' Modal web endpoint function fulfilling this interface would be\n\n...\n...\n\nclass Request(BaseModel):\n    prompt: str\n\n@stub.function()\n@modal.web_endpoint(method=\"POST\")\ndef web(request: Request):\n    _ = request  # ignore input\n    return {\"prompt\": \"hello world\"}\n\nSee Modal's web endpoints guide for the basics of setting up an endpoint that fulfils this interface.\nSee Modal's 'Run Falcon-40B with AutoGPTQ' open-source LLM example as a starting point for your custom LLM!\n\nOnce you have a deployed Modal web endpoint, you can pass its URL into the langchain.llms.modal.Modal LLM class. This class can then function as a building block in your chain.\n\nfrom langchain.chains import LLMChain\nfrom langchain.llms import Modal\nfrom langchain.prompts import PromptTemplate\n\ntemplate = \"\"\"Question: {question}\n\nAnswer: Let's think step by step.\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\nendpoint_url = \"https://ecorp--custom-llm-endpoint.modal.run\"  # REPLACE ME with your deployed Modal web endpoint's URL\nllm = Modal(endpoint_url=endpoint_url)\n\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\nquestion = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n\nllm_chain.run(question)\n\nPrevious\nMinimax\nNext\nMosaicML"
}