{
	"title": "Cohere | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/chat/cohere",
	"html": "ComponentsChat modelsCohere\nCohere\n\nThis notebook covers how to get started with Cohere chat models.\n\nfrom langchain.chat_models import ChatCohere\nfrom langchain.schema import HumanMessage\n\nchat = ChatCohere()\n\nmessages = [HumanMessage(content=\"knock knock\")]\nchat(messages)\n\n    AIMessage(content=\"Who's there?\")\n\nChatCohere also supports async and streaming functionality:‚Äã\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nawait chat.agenerate([messages])\n\n    Who's there?\n\n\n\n\n    LLMResult(generations=[[ChatGenerationChunk(text=\"Who's there?\", message=AIMessageChunk(content=\"Who's there?\"))]], llm_output={}, run=[RunInfo(run_id=UUID('1e9eaefc-9c99-4fa9-8297-ef9975d4751e'))])\n\nchat = ChatCohere(\n    streaming=True,\n    verbose=True,\n    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n)\nchat(messages)\n\n    Who's there?\n\n\n\n\n    AIMessageChunk(content=\"Who's there?\")\n\nPrevious\nBedrock Chat\nNext\nERNIE-Bot Chat"
}