{
	"title": "Streaming | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/modules/model_io/chat/streaming",
	"html": "ModulesModel I/OChat modelsStreaming\nStreaming\n\nAll ChatModels implement the Runnable interface, which comes with default implementations of all methods, ie. ainvoke, batch, abatch, stream, astream. This gives all ChatModels basic support for streaming.\n\nStreaming support defaults to returning an Iterator (or AsyncIterator in the case of async streaming) of a single value, the final result returned by the underlying ChatModel provider. This obviously doesn't give you token-by-token streaming, which requires native support from the ChatModel provider, but ensures your code that expects an iterator of tokens can work for any of our ChatModel integrations.\n\nSee which integrations support token-by-token streaming here.\n\nfrom langchain.chat_models import ChatAnthropic\n\nchat = ChatAnthropic(model=\"claude-2\")\nfor chunk in chat.stream(\"Write me a song about goldfish on the moon\"):\n    print(chunk.content, end=\"\", flush=True)\n\n     Here's a song I just improvised about goldfish on the moon:\n    \n    Floating in space, looking for a place \n    To call their home, all alone\n    Swimming through stars, these goldfish from Mars\n    Left their fishbowl behind, a new life to find\n    On the moon, where the craters loom\n    Searching for food, maybe some lunar food\n    Out of their depth, close to death\n    How they wish, for just one small fish\n    To join them up here, their future unclear\n    On the moon, where the Earth looms\n    Dreaming of home, filled with foam\n    Their bodies adapt, continuing to last \n    On the moon, where they learn to swoon\n    Over cheese that astronauts tease\n    As they stare back at Earth, the planet of birth\n    These goldfish out of water, swim on and on\n    Lunar pioneers, conquering their fears\n    On the moon, where they happily swoon\n\nPrevious\nPrompts\nNext\nTracking token usage"
}