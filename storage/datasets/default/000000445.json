{
	"title": "kNN | ğŸ¦œï¸ğŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/retrievers/knn",
	"html": "ComponentsRetrieverskNN\nkNN\n\nIn statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover. It is used for classification and regression.\n\nThis notebook goes over how to use a retriever that under the hood uses an kNN.\n\nLargely based on https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.html\n\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.retrievers import KNNRetriever\n\nCreate New Retriever with Textsâ€‹\nretriever = KNNRetriever.from_texts(\n    [\"foo\", \"bar\", \"world\", \"hello\", \"foo bar\"], OpenAIEmbeddings()\n)\n\nUse Retrieverâ€‹\n\nWe can now use the retriever!\n\nresult = retriever.get_relevant_documents(\"foo\")\n\nresult\n\n    [Document(page_content='foo', metadata={}),\n     Document(page_content='foo bar', metadata={}),\n     Document(page_content='hello', metadata={}),\n     Document(page_content='bar', metadata={})]\n\nPrevious\nKay.ai\nNext\nLOTR (Merger Retriever)"
}