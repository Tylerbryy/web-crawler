{
	"title": "Redis | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/providers/redis",
	"html": "ProvidersMoreRedis\nRedis\n\nRedis (Remote Dictionary Server) is an open-source in-memory storage, used as a distributed, in-memory key‚Äìvalue database, cache and message broker, with optional durability. Because it holds all data in memory and because of its design, Redis offers low-latency reads and writes, making it particularly suitable for use cases that require a cache. Redis is the most popular NoSQL database, and one of the most popular databases overall.\n\nThis page covers how to use the Redis ecosystem within LangChain. It is broken into two parts: installation and setup, and then references to specific Redis wrappers.\n\nInstallation and Setup‚Äã\n\nInstall the Python SDK:\n\npip install redis\n\nWrappers‚Äã\n\nAll wrappers need a redis url connection string to connect to the database support either a stand alone Redis server or a High-Availability setup with Replication and Redis Sentinels.\n\nRedis Standalone connection url‚Äã\n\nFor standalone Redis server, the official redis connection url formats can be used as describe in the python redis modules \"from_url()\" method Redis.from_url\n\nExample: redis_url = \"redis://:secret-pass@localhost:6379/0\"\n\nRedis Sentinel connection url‚Äã\n\nFor Redis sentinel setups the connection scheme is \"redis+sentinel\". This is an unofficial extensions to the official IANA registered protocol schemes as long as there is no connection url for Sentinels available.\n\nExample: redis_url = \"redis+sentinel://:secret-pass@sentinel-host:26379/mymaster/0\"\n\nThe format is redis+sentinel://[[username]:[password]]@[host-or-ip]:[port]/[service-name]/[db-number] with the default values of \"service-name = mymaster\" and \"db-number = 0\" if not set explicit. The service-name is the redis server monitoring group name as configured within the Sentinel.\n\nThe current url format limits the connection string to one sentinel host only (no list can be given) and booth Redis server and sentinel must have the same password set (if used).\n\nRedis Cluster connection url‚Äã\n\nRedis cluster is not supported right now for all methods requiring a \"redis_url\" parameter. The only way to use a Redis Cluster is with LangChain classes accepting a preconfigured Redis client like RedisCache (example below).\n\nCache‚Äã\n\nThe Cache wrapper allows for Redis to be used as a remote, low-latency, in-memory cache for LLM prompts and responses.\n\nStandard Cache‚Äã\n\nThe standard cache is the Redis bread & butter of use case in production for both open-source and enterprise users globally.\n\nTo import this cache:\n\nfrom langchain.cache import RedisCache\n\n\nTo use this cache with your LLMs:\n\nfrom langchain.globals import set_llm_cache\nimport redis\n\nredis_client = redis.Redis.from_url(...)\nset_llm_cache(RedisCache(redis_client))\n\nSemantic Cache‚Äã\n\nSemantic caching allows users to retrieve cached prompts based on semantic similarity between the user input and previously cached results. Under the hood it blends Redis as both a cache and a vectorstore.\n\nTo import this cache:\n\nfrom langchain.cache import RedisSemanticCache\n\n\nTo use this cache with your LLMs:\n\nfrom langchain.globals import set_llm_cache\nimport redis\n\n# use any embedding provider...\nfrom tests.integration_tests.vectorstores.fake_embeddings import FakeEmbeddings\n\nredis_url = \"redis://localhost:6379\"\n\nset_llm_cache(RedisSemanticCache(\n    embedding=FakeEmbeddings(),\n    redis_url=redis_url\n))\n\nVectorStore‚Äã\n\nThe vectorstore wrapper turns Redis into a low-latency vector database for semantic search or LLM content retrieval.\n\nTo import this vectorstore:\n\nfrom langchain.vectorstores import Redis\n\n\nFor a more detailed walkthrough of the Redis vectorstore wrapper, see this notebook.\n\nRetriever‚Äã\n\nThe Redis vector store retriever wrapper generalizes the vectorstore class to perform low-latency document retrieval. To create the retriever, simply call .as_retriever() on the base vectorstore class.\n\nMemory‚Äã\n\nRedis can be used to persist LLM conversations.\n\nVector Store Retriever Memory‚Äã\n\nFor a more detailed walkthrough of the VectorStoreRetrieverMemory wrapper, see this notebook.\n\nChat Message History Memory‚Äã\n\nFor a detailed example of Redis to cache conversation message history, see this notebook.\n\nPrevious\nReddit\nNext\nReplicate"
}