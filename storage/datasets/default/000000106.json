{
	"title": "self-query-supabase | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/templates/self-query-supabase",
	"html": "Templatesself-query-supabase\nself-query-supabase\n\nThis templates allows natural language structured quering of Supabase.\n\nSupabase is an open-source alternative to Firebase, built on top of PostgreSQL.\n\nIt uses pgvector to store embeddings within your tables.\n\nEnvironment Setup‚Äã\n\nSet the OPENAI_API_KEY environment variable to access the OpenAI models.\n\nTo get your OPENAI_API_KEY, navigate to API keys on your OpenAI account and create a new secret key.\n\nTo find your SUPABASE_URL and SUPABASE_SERVICE_KEY, head to your Supabase project's API settings.\n\nSUPABASE_URL corresponds to the Project URL\nSUPABASE_SERVICE_KEY corresponds to the service_role API key\nexport SUPABASE_URL=\nexport SUPABASE_SERVICE_KEY=\nexport OPENAI_API_KEY=\n\nSetup Supabase Database‚Äã\n\nUse these steps to setup your Supabase database if you haven't already.\n\nHead over to https://database.new to provision your Supabase database.\n\nIn the studio, jump to the SQL editor and run the following script to enable pgvector and setup your database as a vector store:\n\n-- Enable the pgvector extension to work with embedding vectors\ncreate extension if not exists vector;\n\n-- Create a table to store your documents\ncreate table\n  documents (\n    id uuid primary key,\n    content text, -- corresponds to Document.pageContent\n    metadata jsonb, -- corresponds to Document.metadata\n    embedding vector (1536) -- 1536 works for OpenAI embeddings, change as needed\n  );\n\n-- Create a function to search for documents\ncreate function match_documents (\n  query_embedding vector (1536),\n  filter jsonb default '{}'\n) returns table (\n  id uuid,\n  content text,\n  metadata jsonb,\n  similarity float\n) language plpgsql as $$\n#variable_conflict use_column\nbegin\n  return query\n  select\n    id,\n    content,\n    metadata,\n    1 - (documents.embedding <=> query_embedding) as similarity\n  from documents\n  where metadata @> filter\n  order by documents.embedding <=> query_embedding;\nend;\n$$;\n\nUsage‚Äã\n\nTo use this package, install the LangChain CLI first:\n\npip install -U langchain-cli\n\n\nCreate a new LangChain project and install this package as the only one:\n\nlangchain app new my-app --package self-query-supabase\n\n\nTo add this to an existing project, run:\n\nlangchain app add self-query-supabase\n\n\nAdd the following code to your server.py file:\n\nfrom self_query_supabase.chain import chain as self_query_supabase_chain\n\nadd_routes(app, self_query_supabase_chain, path=\"/self-query-supabase\")\n\n\n(Optional) If you have access to LangSmith, configure it to help trace, monitor and debug LangChain applications. If you don't have access, skip this section.\n\nexport LANGCHAIN_TRACING_V2=true\nexport LANGCHAIN_API_KEY=<your-api-key>\nexport LANGCHAIN_PROJECT=<your-project>  # if not specified, defaults to \"default\"\n\n\nIf you are inside this directory, then you can spin up a LangServe instance directly by:\n\nlangchain serve\n\n\nThis will start the FastAPI app with a server running locally at http://localhost:8000\n\nYou can see all templates at http://127.0.0.1:8000/docs Access the playground at http://127.0.0.1:8000/self-query-supabase/playground\n\nAccess the template from code with:\n\nfrom langserve.client import RemoteRunnable\n\nrunnable = RemoteRunnable(\"http://localhost:8000/self-query-supabase\")\n\n\nTODO: Instructions to set up the Supabase database and install the package.\n\nPrevious\nself-query-qdrant\nNext\nsolo-performance-prompting-agent"
}