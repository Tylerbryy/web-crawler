{
	"title": "self-query-qdrant | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/templates/self-query-qdrant",
	"html": "Templatesself-query-qdrant\nself-query-qdrant\n\nThis template performs self-querying using Qdrant and OpenAI. By default, it uses an artificial dataset of 10 documents, but you can replace it with your own dataset.\n\nEnvironment Setup‚Äã\n\nSet the OPENAI_API_KEY environment variable to access the OpenAI models.\n\nSet the QDRANT_URL to the URL of your Qdrant instance. If you use Qdrant Cloud you have to set the QDRANT_API_KEY environment variable as well. If you do not set any of them, the template will try to connect a local Qdrant instance at http://localhost:6333.\n\nexport QDRANT_URL=\nexport QDRANT_API_KEY=\n\nexport OPENAI_API_KEY=\n\nUsage‚Äã\n\nTo use this package, install the LangChain CLI first:\n\npip install -U \"langchain-cli[serve]\"\n\n\nCreate a new LangChain project and install this package as the only one:\n\nlangchain app new my-app --package self-query-qdrant\n\n\nTo add this to an existing project, run:\n\nlangchain app add self-query-qdrant\n\nDefaults‚Äã\n\nBefore you launch the server, you need to create a Qdrant collection and index the documents. It can be done by running the following command:\n\nfrom self_query_qdrant.chain import initialize\n\ninitialize()\n\n\nAdd the following code to your app/server.py file:\n\nfrom self_query_qdrant.chain import chain\n\nadd_routes(app, chain, path=\"/self-query-qdrant\")\n\n\nThe default dataset consists 10 documents about dishes, along with their price and restaurant information. You can find the documents in the packages/self-query-qdrant/self_query_qdrant/defaults.py file. Here is one of the documents:\n\nfrom langchain.schema import Document\n\nDocument(\n    page_content=\"Spaghetti with meatballs and tomato sauce\",\n    metadata={\n        \"price\": 12.99,\n        \"restaurant\": {\n            \"name\": \"Olive Garden\",\n            \"location\": [\"New York\", \"Chicago\", \"Los Angeles\"],\n        },\n    },\n)\n\n\nThe self-querying allows performing semantic search over the documents, with some additional filtering based on the metadata. For example, you can search for the dishes that cost less than $15 and are served in New York.\n\nCustomization‚Äã\n\nAll the examples above assume that you want to launch the template with just the defaults. If you want to customize the template, you can do it by passing the parameters to the create_chain function in the app/server.py file:\n\nfrom langchain.llms import Cohere\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains.query_constructor.schema import AttributeInfo\n\nfrom self_query_qdrant.chain import create_chain\n\nchain = create_chain(\n    llm=Cohere(),\n    embeddings=HuggingFaceEmbeddings(),\n    document_contents=\"Descriptions of cats, along with their names and breeds.\",\n    metadata_field_info=[\n        AttributeInfo(name=\"name\", description=\"Name of the cat\", type=\"string\"),\n        AttributeInfo(name=\"breed\", description=\"Cat's breed\", type=\"string\"),\n    ],\n    collection_name=\"cats\",\n)\n\n\nThe same goes for the initialize function that creates a Qdrant collection and indexes the documents:\n\nfrom langchain.schema import Document\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\nfrom self_query_qdrant.chain import initialize\n\ninitialize(\n    embeddings=HuggingFaceEmbeddings(),\n    collection_name=\"cats\",\n    documents=[\n        Document(\n            page_content=\"A mean lazy old cat who destroys furniture and eats lasagna\",\n            metadata={\"name\": \"Garfield\", \"breed\": \"Tabby\"},\n        ),\n        ...\n    ]\n)\n\n\nThe template is flexible and might be used for different sets of documents easily.\n\nLangSmith‚Äã\n\n(Optional) If you have access to LangSmith, configure it to help trace, monitor and debug LangChain applications. If you don't have access, skip this section.\n\nexport LANGCHAIN_TRACING_V2=true\nexport LANGCHAIN_API_KEY=<your-api-key>\nexport LANGCHAIN_PROJECT=<your-project>  # if not specified, defaults to \"default\"\n\n\nIf you are inside this directory, then you can spin up a LangServe instance directly by:\n\nlangchain serve\n\nLocal Server‚Äã\n\nThis will start the FastAPI app with a server running locally at http://localhost:8000\n\nYou can see all templates at http://127.0.0.1:8000/docs Access the playground at http://127.0.0.1:8000/self-query-qdrant/playground\n\nAccess the template from code with:\n\nfrom langserve.client import RemoteRunnable\n\nrunnable = RemoteRunnable(\"http://localhost:8000/self-query-qdrant\")\n\nPrevious\nrewrite_retrieve_read\nNext\nself-query-supabase"
}