{
	"title": "Eden AI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/llms/edenai",
	"html": "ComponentsLLMsEden AI\nEden AI\n\nEden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website: https://edenai.co/)\n\nThis example goes over how to use LangChain to interact with Eden AI models\n\nAccessing the EDENAI's API requires an API key,\n\nwhich you can get by creating an account https://app.edenai.run/user/register and heading here https://app.edenai.run/admin/account/settings\n\nOnce we have a key we'll want to set it as an environment variable by running:\n\nexport EDENAI_API_KEY=\"...\"\n\n\nIf you'd prefer not to set an environment variable you can pass the key in directly via the edenai_api_key named parameter\n\nwhen initiating the EdenAI LLM class:\n\nfrom langchain.llms import EdenAI\n\nllm = EdenAI(edenai_api_key=\"...\", provider=\"openai\", temperature=0.2, max_tokens=250)\n\nCalling a model‚Äã\n\nThe EdenAI API brings together various providers, each offering multiple models.\n\nTo access a specific model, you can simply add 'model' during instantiation.\n\nFor instance, let's explore the models provided by OpenAI, such as GPT3.5\n\ntext generation‚Äã\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\n\nllm = EdenAI(\n    feature=\"text\",\n    provider=\"openai\",\n    model=\"text-davinci-003\",\n    temperature=0.2,\n    max_tokens=250,\n)\n\nprompt = \"\"\"\nUser: Answer the following yes/no question by reasoning step by step. Can a dog drive a car?\nAssistant:\n\"\"\"\n\nllm(prompt)\n\nimage generation‚Äã\nimport base64\nfrom io import BytesIO\n\nfrom PIL import Image\n\n\ndef print_base64_image(base64_string):\n    # Decode the base64 string into binary data\n    decoded_data = base64.b64decode(base64_string)\n\n    # Create an in-memory stream to read the binary data\n    image_stream = BytesIO(decoded_data)\n\n    # Open the image using PIL\n    image = Image.open(image_stream)\n\n    # Display the image\n    image.show()\n\ntext2image = EdenAI(feature=\"image\", provider=\"openai\", resolution=\"512x512\")\n\nimage_output = text2image(\"A cat riding a motorcycle by Picasso\")\n\nprint_base64_image(image_output)\n\ntext generation with callback‚Äã\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nfrom langchain.llms import EdenAI\n\nllm = EdenAI(\n    callbacks=[StreamingStdOutCallbackHandler()],\n    feature=\"text\",\n    provider=\"openai\",\n    temperature=0.2,\n    max_tokens=250,\n)\nprompt = \"\"\"\nUser: Answer the following yes/no question by reasoning step by step. Can a dog drive a car?\nAssistant:\n\"\"\"\nprint(llm(prompt))\n\nChaining Calls‚Äã\nfrom langchain.chains import LLMChain, SimpleSequentialChain\nfrom langchain.prompts import PromptTemplate\n\nllm = EdenAI(feature=\"text\", provider=\"openai\", temperature=0.2, max_tokens=250)\ntext2image = EdenAI(feature=\"image\", provider=\"openai\", resolution=\"512x512\")\n\nprompt = PromptTemplate(\n    input_variables=[\"product\"],\n    template=\"What is a good name for a company that makes {product}?\",\n)\n\nchain = LLMChain(llm=llm, prompt=prompt)\n\nsecond_prompt = PromptTemplate(\n    input_variables=[\"company_name\"],\n    template=\"Write a description of a logo for this company: {company_name}, the logo should not contain text at all \",\n)\nchain_two = LLMChain(llm=llm, prompt=second_prompt)\n\nthird_prompt = PromptTemplate(\n    input_variables=[\"company_logo_description\"],\n    template=\"{company_logo_description}\",\n)\nchain_three = LLMChain(llm=text2image, prompt=third_prompt)\n\n# Run the chain specifying only the input variable for the first chain.\noverall_chain = SimpleSequentialChain(\n    chains=[chain, chain_two, chain_three], verbose=True\n)\noutput = overall_chain.run(\"hats\")\n\n# print the image\nprint_base64_image(output)\n\nPrevious\nDeepSparse\nNext\nFireworks"
}