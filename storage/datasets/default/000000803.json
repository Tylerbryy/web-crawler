{
	"title": "Zep | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/providers/zep",
	"html": "ProvidersMoreZep\nZep\nFast, Scalable Building Blocks for LLM Apps‚Äã\n\nZep is an open source platform for productionizing LLM apps. Go from a prototype built in LangChain or LlamaIndex, or a custom app, to production in minutes without rewriting code.\n\nKey Features:\n\nFast! Zep operates independently of the your chat loop, ensuring a snappy user experience.\nChat History Memory, Archival, and Enrichment, populate your prompts with relevant chat history, sumamries, named entities, intent data, and more.\nVector Search over Chat History and Documents Automatic embedding of documents, chat histories, and summaries. Use Zep's similarity or native MMR Re-ranked search to find the most relevant.\nManage Users and their Chat Sessions Users and their Chat Sessions are first-class citizens in Zep, allowing you to manage user interactions with your bots or agents easily.\nRecords Retention and Privacy Compliance Comply with corporate and regulatory mandates for records retention while ensuring compliance with privacy regulations such as CCPA and GDPR. Fulfill Right To Be Forgotten requests with a single API call\n\nZep project: https://github.com/getzep/zep Docs: https://docs.getzep.com/\n\nInstallation and Setup‚Äã\n\nInstall the Zep service. See the Zep Quick Start Guide.\n\nInstall the Zep Python SDK:\n\npip install zep_python\n\nZep Memory‚Äã\n\nZep's Memory API persists your app's chat history and metadata to a Session, enriches the memory, automatically generates summaries, and enables vector similarity search over historical chat messages and summaries.\n\nThere are two approaches to populating your prompt with chat history:\n\nRetrieve the most recent N messages (and potentionally a summary) from a Session and use them to construct your prompt.\nSearch over the Session's chat history for messages that are relevant and use them to construct your prompt.\n\nBoth of these approaches may be useful, with the first providing the LLM with context as to the most recent interactions with a human. The second approach enables you to look back further in the chat history and retrieve messages that are relevant to the current conversation in a token-efficient manner.\n\nfrom langchain.memory import ZepMemory\n\n\nSee a RAG App Example here.\n\nMemory Retriever‚Äã\n\nZep's Memory Retriever is a LangChain Retriever that enables you to retrieve messages from a Zep Session and use them to construct your prompt.\n\nThe Retriever supports searching over both individual messages and summaries of conversations. The latter is useful for providing rich, but succinct context to the LLM as to relevant past conversations.\n\nZep's Memory Retriever supports both similarity search and Maximum Marginal Relevance (MMR) reranking. MMR search is useful for ensuring that the retrieved messages are diverse and not too similar to each other\n\nSee a usage example.\n\nfrom langchain.retrievers import ZepRetriever\n\nZep VectorStore‚Äã\n\nZep's Document VectorStore API enables you to store and retrieve documents using vector similarity search. Zep doesn't require you to understand distance functions, types of embeddings, or indexing best practices. You just pass in your chunked documents, and Zep handles the rest.\n\nZep supports both similarity search and Maximum Marginal Relevance (MMR) reranking. MMR search is useful for ensuring that the retrieved documents are diverse and not too similar to each other.\n\nfrom langchain.vectorstores.zep import ZepVectorStore\n\n\nSee a usage example.\n\nPrevious\nYouTube\nNext\nZilliz"
}