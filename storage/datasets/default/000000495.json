{
	"title": "Azure OpenAI | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/chat/azure_chat_openai",
	"html": "ComponentsChat modelsAzure OpenAI\nAzure OpenAI\n\nThis notebook goes over how to connect to an Azure hosted OpenAI endpoint. We recommend having version openai>=1 installed.\n\nimport os\n\nfrom langchain.chat_models import AzureChatOpenAI\nfrom langchain.schema import HumanMessage\n\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://<your-endpoint>.openai.azure.com/\"\n\nmodel = AzureChatOpenAI(\n    openai_api_version=\"2023-05-15\",\n    azure_deployment=\"your-deployment-name\",\n)\n\nmessage = HumanMessage(\n    content=\"Translate this sentence from English to French. I love programming.\"\n)\nmodel([message])\n\n    AIMessage(content=\"J'adore la programmation.\")\n\nModel Versionâ€‹\n\nAzure OpenAI responses contain model property, which is name of the model used to generate the response. However unlike native OpenAI responses, it does not contain the version of the model, which is set on the deployment in Azure. This makes it tricky to know which version of the model was used to generate the response, which as result can lead to e.g. wrong total cost calculation with OpenAICallbackHandler.\n\nTo solve this problem, you can pass model_version parameter to AzureChatOpenAI class, which will be added to the model name in the llm output. This way you can easily distinguish between different versions of the model.\n\nfrom langchain.callbacks import get_openai_callback\n\nmodel = AzureChatOpenAI(\n    openai_api_version=\"2023-05-15\",\n    azure_deployment=\"gpt-35-turbo\",  # in Azure, this deployment has version 0613 - input and output tokens are counted separately\n)\nwith get_openai_callback() as cb:\n    model([message])\n    print(\n        f\"Total Cost (USD): ${format(cb.total_cost, '.6f')}\"\n    )  # without specifying the model version, flat-rate 0.002 USD per 1k input and output tokens is used\n\n\nWe can provide the model version to AzureChatOpenAI constructor. It will get appended to the model name returned by Azure OpenAI and cost will be counted correctly.\n\nmodel0613 = AzureChatOpenAI(\n    openai_api_version=\"2023-05-15\",\n    deployment_name=\"gpt-35-turbo\",\n    model_version=\"0613\",\n)\nwith get_openai_callback() as cb:\n    model0613([message])\n    print(f\"Total Cost (USD): ${format(cb.total_cost, '.6f')}\")\n\n    Total Cost (USD): $0.000044\n\nPrevious\nAnyscale\nNext\nAzureML Chat Online Endpoint"
}