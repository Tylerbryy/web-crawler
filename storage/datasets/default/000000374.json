{
	"title": "Elasticsearch | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/vectorstores/elasticsearch",
	"html": "ComponentsVector storesElasticsearch\nElasticsearch\n\nElasticsearch is a distributed, RESTful search and analytics engine, capable of performing both vector and lexical search. It is built on top of the Apache Lucene library.\n\nThis notebook shows how to use functionality related to the Elasticsearch database.\n\npip install elasticsearch openai tiktoken langchain\n\nRunning and connecting to Elasticsearchâ€‹\n\nThere are two main ways to setup an Elasticsearch instance for use with:\n\nElastic Cloud: Elastic Cloud is a managed Elasticsearch service. Signup for a free trial.\n\nTo connect to an Elasticsearch instance that does not require login credentials (starting the docker instance with security enabled), pass the Elasticsearch URL and index name along with the embedding object to the constructor.\n\nLocal Install Elasticsearch: Get started with Elasticsearch by running it locally. The easiest way is to use the official Elasticsearch Docker image. See the Elasticsearch Docker documentation for more information.\nRunning Elasticsearch via Dockerâ€‹\n\nExample: Run a single-node Elasticsearch instance with security disabled. This is not recommended for production use.\n\n    docker run -p 9200:9200 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" -e \"xpack.security.http.ssl.enabled=false\" docker.elastic.co/elasticsearch/elasticsearch:8.9.0\n\n\nOnce the Elasticsearch instance is running, you can connect to it using the Elasticsearch URL and index name along with the embedding object to the constructor.\n\nExample:\n\n        from langchain.vectorstores.elasticsearch import ElasticsearchStore\n        from langchain.embeddings.openai import OpenAIEmbeddings\n\n        embedding = OpenAIEmbeddings()\n        elastic_vector_search = ElasticsearchStore(\n            es_url=\"http://localhost:9200\",\n            index_name=\"test_index\",\n            embedding=embedding\n        )\n\nAuthenticationâ€‹\n\nFor production, we recommend you run with security enabled. To connect with login credentials, you can use the parameters api_key or es_user and es_password.\n\nExample:\n\n        from langchain.vectorstores import ElasticsearchStore\n        from langchain.embeddings import OpenAIEmbeddings\n\n        embedding = OpenAIEmbeddings()\n        elastic_vector_search = ElasticsearchStore(\n            es_url=\"http://localhost:9200\",\n            index_name=\"test_index\",\n            embedding=embedding,\n            es_user=\"elastic\",\n            es_password=\"changeme\"\n        )\n\nHow to obtain a password for the default \"elastic\" user?â€‹\n\nTo obtain your Elastic Cloud password for the default \"elastic\" user:\n\nLog in to the Elastic Cloud console at https://cloud.elastic.co\nGo to \"Security\" > \"Users\"\nLocate the \"elastic\" user and click \"Edit\"\nClick \"Reset password\"\nFollow the prompts to reset the password\nHow to obtain an API key?â€‹\n\nTo obtain an API key:\n\nLog in to the Elastic Cloud console at https://cloud.elastic.co\nOpen Kibana and go to Stack Management > API Keys\nClick \"Create API key\"\nEnter a name for the API key and click \"Create\"\nCopy the API key and paste it into the api_key parameter\nElastic Cloudâ€‹\n\nTo connect to an Elasticsearch instance on Elastic Cloud, you can use either the es_cloud_id parameter or es_url.\n\nExample:\n\n        from langchain.vectorstores.elasticsearch import ElasticsearchStore\n        from langchain.embeddings import OpenAIEmbeddings\n\n        embedding = OpenAIEmbeddings()\n        elastic_vector_search = ElasticsearchStore(\n            es_cloud_id=\"<cloud_id>\",\n            index_name=\"test_index\",\n            embedding=embedding,\n            es_user=\"elastic\",\n            es_password=\"changeme\"\n        )\n\n\nWe want to use OpenAIEmbeddings so we have to get the OpenAI API Key.\n\nimport getpass\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n\nBasic Exampleâ€‹\n\nThis example we are going to load \"state_of_the_union.txt\" via the TextLoader, chunk the text into 500 word chunks, and then index each chunk into Elasticsearch.\n\nOnce the data is indexed, we perform a simple query to find the top 4 chunks that similar to the query \"What did the president say about Ketanji Brown Jackson\".\n\nElasticsearch is running locally on localhost:9200 with docker. For more details on how to connect to Elasticsearch from Elastic Cloud, see connecting with authentication above.\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import ElasticsearchStore\n\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\n\nloader = TextLoader(\"../../modules/state_of_the_union.txt\")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\nembeddings = OpenAIEmbeddings()\n\ndb = ElasticsearchStore.from_documents(\n    docs,\n    embeddings,\n    es_url=\"http://localhost:9200\",\n    index_name=\"test-basic\",\n)\n\ndb.client.indices.refresh(index=\"test-basic\")\n\nquery = \"What did the president say about Ketanji Brown Jackson\"\nresults = db.similarity_search(query)\nprint(results)\n\n    [Document(page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâ€™s top legal minds, who will continue Justice Breyerâ€™s legacy of excellence.', metadata={'source': '../../modules/state_of_the_union.txt'}), Document(page_content='As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isnâ€™t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.', metadata={'source': '../../modules/state_of_the_union.txt'}), Document(page_content='A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since sheâ€™s been nominated, sheâ€™s received a broad range of supportâ€”from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.', metadata={'source': '../../modules/state_of_the_union.txt'}), Document(page_content='This is personal to me and Jill, to Kamala, and to so many of you. \\n\\nCancer is the #2 cause of death in Americaâ€“second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families.', metadata={'source': '../../modules/state_of_the_union.txt'})]\n\nMetadata\n\nElasticsearchStore supports metadata to stored along with the document. This metadata dict object is stored in a metadata object field in the Elasticsearch document. Based on the metadata value, Elasticsearch will automatically setup the mapping by infering the data type of the metadata value. For example, if the metadata value is a string, Elasticsearch will setup the mapping for the metadata object field as a string type.\n\n# Adding metadata to documents\nfor i, doc in enumerate(docs):\n    doc.metadata[\"date\"] = f\"{range(2010, 2020)[i % 10]}-01-01\"\n    doc.metadata[\"rating\"] = range(1, 6)[i % 5]\n    doc.metadata[\"author\"] = [\"John Doe\", \"Jane Doe\"][i % 2]\n\ndb = ElasticsearchStore.from_documents(\n    docs, embeddings, es_url=\"http://localhost:9200\", index_name=\"test-metadata\"\n)\n\nquery = \"What did the president say about Ketanji Brown Jackson\"\ndocs = db.similarity_search(query)\nprint(docs[0].metadata)\n\n    {'source': '../../modules/state_of_the_union.txt', 'date': '2016-01-01', 'rating': 2, 'author': 'John Doe'}\n\nFiltering Metadataâ€‹\n\nWith metadata added to the documents, you can add metadata filtering at query time.\n\nExample: Filter by Exact keywordâ€‹\n\nNotice: We are using the keyword subfield thats not analyzed\n\ndocs = db.similarity_search(\n    query, filter=[{\"term\": {\"metadata.author.keyword\": \"John Doe\"}}]\n)\nprint(docs[0].metadata)\n\n    {'source': '../../modules/state_of_the_union.txt', 'date': '2016-01-01', 'rating': 2, 'author': 'John Doe'}\n\nExample: Filter by Partial Matchâ€‹\n\nThis example shows how to filter by partial match. This is useful when you don't know the exact value of the metadata field. For example, if you want to filter by the metadata field author and you don't know the exact value of the author, you can use a partial match to filter by the author's last name. Fuzzy matching is also supported.\n\n\"Jon\" matches on \"John Doe\" as \"Jon\" is a close match to \"John\" token.\n\ndocs = db.similarity_search(\n    query,\n    filter=[{\"match\": {\"metadata.author\": {\"query\": \"Jon\", \"fuzziness\": \"AUTO\"}}}],\n)\nprint(docs[0].metadata)\n\n    {'source': '../../modules/state_of_the_union.txt', 'date': '2016-01-01', 'rating': 2, 'author': 'John Doe'}\n\nExample: Filter by Date Rangeâ€‹\ndocs = db.similarity_search(\n    \"Any mention about Fred?\",\n    filter=[{\"range\": {\"metadata.date\": {\"gte\": \"2010-01-01\"}}}],\n)\nprint(docs[0].metadata)\n\n    {'source': '../../modules/state_of_the_union.txt', 'date': '2012-01-01', 'rating': 3, 'author': 'John Doe', 'geo_location': {'lat': 40.12, 'lon': -71.34}}\n\nExample: Filter by Numeric Rangeâ€‹\ndocs = db.similarity_search(\n    \"Any mention about Fred?\", filter=[{\"range\": {\"metadata.rating\": {\"gte\": 2}}}]\n)\nprint(docs[0].metadata)\n\n    {'source': '../../modules/state_of_the_union.txt', 'date': '2012-01-01', 'rating': 3, 'author': 'John Doe', 'geo_location': {'lat': 40.12, 'lon': -71.34}}\n\nExample: Filter by Geo Distanceâ€‹\n\nRequires an index with a geo_point mapping to be declared for metadata.geo_location.\n\ndocs = db.similarity_search(\n    \"Any mention about Fred?\",\n    filter=[\n        {\n            \"geo_distance\": {\n                \"distance\": \"200km\",\n                \"metadata.geo_location\": {\"lat\": 40, \"lon\": -70},\n            }\n        }\n    ],\n)\nprint(docs[0].metadata)\n\n\nFilter supports many more types of queries than above.\n\nRead more about them in the documentation.\n\nDistance Similarity Algorithm\n\nElasticsearch supports the following vector distance similarity algorithms:\n\ncosine\neuclidean\ndot_product\n\nThe cosine similarity algorithm is the default.\n\nYou can specify the similarity Algorithm needed via the similarity parameter.\n\nNOTE Depending on the retrieval strategy, the similarity algorithm cannot be changed at query time. It is needed to be set when creating the index mapping for field. If you need to change the similarity algorithm, you need to delete the index and recreate it with the correct distance_strategy.\n\n\ndb = ElasticsearchStore.from_documents(\n    docs, \n    embeddings, \n    es_url=\"http://localhost:9200\", \n    index_name=\"test\",\n    distance_strategy=\"COSINE\"\n    # distance_strategy=\"EUCLIDEAN_DISTANCE\"\n    # distance_strategy=\"DOT_PRODUCT\"\n)\n\n\nRetrieval Strategies\n\nElasticsearch has big advantages over other vector only databases from its ability to support a wide range of retrieval strategies. In this notebook we will configure ElasticsearchStore to support some of the most common retrieval strategies.\n\nBy default, ElasticsearchStore uses the ApproxRetrievalStrategy.\n\nApproxRetrievalStrategyâ€‹\n\nThis will return the top k most similar vectors to the query vector. The k parameter is set when the ElasticsearchStore is initialized. The default value is 10.\n\ndb = ElasticsearchStore.from_documents(\n    docs,\n    embeddings,\n    es_url=\"http://localhost:9200\",\n    index_name=\"test\",\n    strategy=ElasticsearchStore.ApproxRetrievalStrategy(),\n)\n\ndocs = db.similarity_search(\n    query=\"What did the president say about Ketanji Brown Jackson?\", k=10\n)\n\nExample: Approx with hybridâ€‹\n\nThis example will show how to configure ElasticsearchStore to perform a hybrid retrieval, using a combination of approximate semantic search and keyword based search.\n\nWe use RRF to balance the two scores from different retrieval methods.\n\nTo enable hybrid retrieval, we need to set hybrid=True in ElasticsearchStore ApproxRetrievalStrategy constructor.\n\n\ndb = ElasticsearchStore.from_documents(\n    docs, \n    embeddings, \n    es_url=\"http://localhost:9200\", \n    index_name=\"test\",\n    strategy=ElasticsearchStore.ApproxRetrievalStrategy(\n        hybrid=True,\n    )\n)\n\n\nWhen hybrid is enabled, the query performed will be a combination of approximate semantic search and keyword based search.\n\nIt will use rrf (Reciprocal Rank Fusion) to balance the two scores from different retrieval methods.\n\nNote RRF requires Elasticsearch 8.9.0 or above.\n\n{\n    \"knn\": {\n        \"field\": \"vector\",\n        \"filter\": [],\n        \"k\": 1,\n        \"num_candidates\": 50,\n        \"query_vector\": [1.0, ..., 0.0],\n    },\n    \"query\": {\n        \"bool\": {\n            \"filter\": [],\n            \"must\": [{\"match\": {\"text\": {\"query\": \"foo\"}}}],\n        }\n    },\n    \"rank\": {\"rrf\": {}},\n}\n\nExample: Approx with Embedding Model in Elasticsearchâ€‹\n\nThis example will show how to configure ElasticsearchStore to use the embedding model deployed in Elasticsearch for approximate retrieval.\n\nTo use this, specify the model_id in ElasticsearchStore ApproxRetrievalStrategy constructor via the query_model_id argument.\n\nNOTE This requires the model to be deployed and running in Elasticsearch ml node. See notebook example on how to deploy the model with eland.\n\nAPPROX_SELF_DEPLOYED_INDEX_NAME = \"test-approx-self-deployed\"\n\n# Note: This does not have an embedding function specified\n# Instead, we will use the embedding model deployed in Elasticsearch\ndb = ElasticsearchStore(\n    es_cloud_id=\"<your cloud id>\",\n    es_user=\"elastic\",\n    es_password=\"<your password>\",\n    index_name=APPROX_SELF_DEPLOYED_INDEX_NAME,\n    query_field=\"text_field\",\n    vector_query_field=\"vector_query_field.predicted_value\",\n    strategy=ElasticsearchStore.ApproxRetrievalStrategy(\n        query_model_id=\"sentence-transformers__all-minilm-l6-v2\"\n    ),\n)\n\n# Setup a Ingest Pipeline to perform the embedding\n# of the text field\ndb.client.ingest.put_pipeline(\n    id=\"test_pipeline\",\n    processors=[\n        {\n            \"inference\": {\n                \"model_id\": \"sentence-transformers__all-minilm-l6-v2\",\n                \"field_map\": {\"query_field\": \"text_field\"},\n                \"target_field\": \"vector_query_field\",\n            }\n        }\n    ],\n)\n\n# creating a new index with the pipeline,\n# not relying on langchain to create the index\ndb.client.indices.create(\n    index=APPROX_SELF_DEPLOYED_INDEX_NAME,\n    mappings={\n        \"properties\": {\n            \"text_field\": {\"type\": \"text\"},\n            \"vector_query_field\": {\n                \"properties\": {\n                    \"predicted_value\": {\n                        \"type\": \"dense_vector\",\n                        \"dims\": 384,\n                        \"index\": True,\n                        \"similarity\": \"l2_norm\",\n                    }\n                }\n            },\n        }\n    },\n    settings={\"index\": {\"default_pipeline\": \"test_pipeline\"}},\n)\n\ndb.from_texts(\n    [\"hello world\"],\n    es_cloud_id=\"<cloud id>\",\n    es_user=\"elastic\",\n    es_password=\"<cloud password>\",\n    index_name=APPROX_SELF_DEPLOYED_INDEX_NAME,\n    query_field=\"text_field\",\n    vector_query_field=\"vector_query_field.predicted_value\",\n    strategy=ElasticsearchStore.ApproxRetrievalStrategy(\n        query_model_id=\"sentence-transformers__all-minilm-l6-v2\"\n    ),\n)\n\n# Perform search\ndb.similarity_search(\"hello world\", k=10)\n\nSparseVectorRetrievalStrategy (ELSER)â€‹\n\nThis strategy uses Elasticsearch's sparse vector retrieval to retrieve the top-k results. We only support our own \"ELSER\" embedding model for now.\n\nNOTE This requires the ELSER model to be deployed and running in Elasticsearch ml node.\n\nTo use this, specify SparseVectorRetrievalStrategy in ElasticsearchStore constructor.\n\n# Note that this example doesn't have an embedding function. This is because we infer the tokens at index time and at query time within Elasticsearch.\n# This requires the ELSER model to be loaded and running in Elasticsearch.\ndb = ElasticsearchStore.from_documents(\n    docs,\n    es_cloud_id=\"My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyQ2OGJhMjhmNDc1M2Y0MWVjYTk2NzI2ZWNkMmE5YzRkNyQ3NWI4ODRjNWQ2OTU0MTYzODFjOTkxNmQ1YzYxMGI1Mw==\",\n    es_user=\"elastic\",\n    es_password=\"GgUPiWKwEzgHIYdHdgPk1Lwi\",\n    index_name=\"test-elser\",\n    strategy=ElasticsearchStore.SparseVectorRetrievalStrategy(),\n)\n\ndb.client.indices.refresh(index=\"test-elser\")\n\nresults = db.similarity_search(\n    \"What did the president say about Ketanji Brown Jackson\", k=4\n)\nprint(results[0])\n\n    page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâ€™s top legal minds, who will continue Justice Breyerâ€™s legacy of excellence.' metadata={'source': '../../modules/state_of_the_union.txt'}\n\nExactRetrievalStrategyâ€‹\n\nThis strategy uses Elasticsearch's exact retrieval (also known as brute force) to retrieve the top-k results.\n\nTo use this, specify ExactRetrievalStrategy in ElasticsearchStore constructor.\n\n\ndb = ElasticsearchStore.from_documents(\n    docs, \n    embeddings, \n    es_url=\"http://localhost:9200\", \n    index_name=\"test\",\n    strategy=ElasticsearchStore.ExactRetrievalStrategy()\n)\n\nCustomise the Queryâ€‹\n\nWith custom_query parameter at search, you are able to adjust the query that is used to retrieve documents from Elasticsearch. This is useful if you want to want to use a more complex query, to support linear boosting of fields.\n\n# Example of a custom query thats just doing a BM25 search on the text field.\ndef custom_query(query_body: dict, query: str):\n    \"\"\"Custom query to be used in Elasticsearch.\n    Args:\n        query_body (dict): Elasticsearch query body.\n        query (str): Query string.\n    Returns:\n        dict: Elasticsearch query body.\n    \"\"\"\n    print(\"Query Retriever created by the retrieval strategy:\")\n    print(query_body)\n    print()\n\n    new_query_body = {\"query\": {\"match\": {\"text\": query}}}\n\n    print(\"Query thats actually used in Elasticsearch:\")\n    print(new_query_body)\n    print()\n\n    return new_query_body\n\n\nresults = db.similarity_search(\n    \"What did the president say about Ketanji Brown Jackson\",\n    k=4,\n    custom_query=custom_query,\n)\nprint(\"Results:\")\nprint(results[0])\n\n    Query Retriever created by the retrieval strategy:\n    {'query': {'bool': {'must': [{'text_expansion': {'vector.tokens': {'model_id': '.elser_model_1', 'model_text': 'What did the president say about Ketanji Brown Jackson'}}}], 'filter': []}}}\n    \n    Query thats actually used in Elasticsearch:\n    {'query': {'match': {'text': 'What did the president say about Ketanji Brown Jackson'}}}\n    \n    Results:\n    page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâ€™s top legal minds, who will continue Justice Breyerâ€™s legacy of excellence.' metadata={'source': '../../modules/state_of_the_union.txt'}\n\nCustomize the Document Builder\n\nWith doc_builder parameter at search, you are able to adjust how a Document is being built using data retrieved from Elasticsearch. This is especially useful if you have indices which were not created using Langchain.\n\nfrom typing import Dict\n\nfrom langchain.docstore.document import Document\n\n\ndef custom_document_builder(hit: Dict) -> Document:\n    src = hit.get(\"_source\", {})\n    return Document(\n        page_content=src.get(\"content\", \"Missing content!\"),\n        metadata={\n            \"page_number\": src.get(\"page_number\", -1),\n            \"original_filename\": src.get(\"original_filename\", \"Missing filename!\"),\n        },\n    )\n\n\nresults = db.similarity_search(\n    \"What did the president say about Ketanji Brown Jackson\",\n    k=4,\n    doc_builder=custom_document_builder,\n)\nprint(\"Results:\")\nprint(results[0])\n\nFAQ\nQuestion: Im getting timeout errors when indexing documents into Elasticsearch. How do I fix this?â€‹\n\nOne possible issue is your documents might take longer to index into Elasticsearch. ElasticsearchStore uses the Elasticsearch bulk API which has a few defaults that you can adjust to reduce the chance of timeout errors.\n\nThis is also a good idea when you're using SparseVectorRetrievalStrategy.\n\nThe defaults are:\n\nchunk_size: 500\nmax_chunk_bytes: 100MB\n\nTo adjust these, you can pass in the chunk_size and max_chunk_bytes parameters to the ElasticsearchStore add_texts method.\n\n    vector_store.add_texts(\n        texts,\n        bulk_kwargs={\n            \"chunk_size\": 50,\n            \"max_chunk_bytes\": 200000000\n        }\n    )\n\nUpgrading to ElasticsearchStore\n\nIf you're already using Elasticsearch in your langchain based project, you may be using the old implementations: ElasticVectorSearch and ElasticKNNSearch which are now deprecated. We've introduced a new implementation called ElasticsearchStore which is more flexible and easier to use. This notebook will guide you through the process of upgrading to the new implementation.\n\nWhat's new?â€‹\n\nThe new implementation is now one class called ElasticsearchStore which can be used for approx, exact, and ELSER search retrieval, via strategies.\n\nIm using ElasticKNNSearchâ€‹\n\nOld implementation:\n\n\nfrom langchain.vectorstores.elastic_vector_search import ElasticKNNSearch\n\ndb = ElasticKNNSearch(\n  elasticsearch_url=\"http://localhost:9200\",\n  index_name=\"test_index\",\n  embedding=embedding\n)\n\n\n\nNew implementation:\n\n\nfrom langchain.vectorstores.elasticsearch import ElasticsearchStore\n\ndb = ElasticsearchStore(\n  es_url=\"http://localhost:9200\",\n  index_name=\"test_index\",\n  embedding=embedding,\n  # if you use the model_id\n  # strategy=ElasticsearchStore.ApproxRetrievalStrategy( query_model_id=\"test_model\" )\n  # if you use hybrid search\n  # strategy=ElasticsearchStore.ApproxRetrievalStrategy( hybrid=True )\n)\n\n\nIm using ElasticVectorSearchâ€‹\n\nOld implementation:\n\n\nfrom langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n\ndb = ElasticVectorSearch(\n  elasticsearch_url=\"http://localhost:9200\",\n  index_name=\"test_index\",\n  embedding=embedding\n)\n\n\n\nNew implementation:\n\n\nfrom langchain.vectorstores.elasticsearch import ElasticsearchStore\n\ndb = ElasticsearchStore(\n  es_url=\"http://localhost:9200\",\n  index_name=\"test_index\",\n  embedding=embedding,\n  strategy=ElasticsearchStore.ExactRetrievalStrategy()\n)\n\n\ndb.client.indices.delete(\n    index=\"test-metadata, test-elser, test-basic\",\n    ignore_unavailable=True,\n    allow_no_indices=True,\n)\n\n    ObjectApiResponse({'acknowledged': True})\n\nPrevious\nDocArray InMemorySearch\nNext\nEpsilla"
}