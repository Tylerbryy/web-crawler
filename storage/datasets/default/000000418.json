{
	"title": "Custom LLM | 🦜️🔗 Langchain",
	"url": "https://python.langchain.com/docs/modules/model_io/llms/custom_llm",
	"html": "ModulesModel I/OLLMsCustom LLM\nCustom LLM\n\nThis notebook goes over how to create a custom LLM wrapper, in case you want to use your own LLM or a different wrapper than one that is supported in LangChain.\n\nThere is only one required thing that a custom LLM needs to implement:\n\nA _call method that takes in a string, some optional stop words, and returns a string\n\nThere is a second optional thing it can implement:\n\nAn _identifying_params property that is used to help with printing of this class. Should return a dictionary.\n\nLet's implement a very simple custom LLM that just returns the first n characters of the input.\n\nfrom typing import Any, List, Mapping, Optional\n\nfrom langchain.callbacks.manager import CallbackManagerForLLMRun\nfrom langchain.llms.base import LLM\n\nclass CustomLLM(LLM):\n    n: int\n\n    @property\n    def _llm_type(self) -> str:\n        return \"custom\"\n\n    def _call(\n        self,\n        prompt: str,\n        stop: Optional[List[str]] = None,\n        run_manager: Optional[CallbackManagerForLLMRun] = None,\n        **kwargs: Any,\n    ) -> str:\n        if stop is not None:\n            raise ValueError(\"stop kwargs are not permitted.\")\n        return prompt[: self.n]\n\n    @property\n    def _identifying_params(self) -> Mapping[str, Any]:\n        \"\"\"Get the identifying parameters.\"\"\"\n        return {\"n\": self.n}\n\n\nWe can now use this as an any other LLM.\n\nllm = CustomLLM(n=10)\n\nllm(\"This is a foobar thing\")\n\n    'This is a '\n\n\nWe can also print the LLM and see its custom print.\n\nprint(llm)\n\n    CustomLLM\n    Params: {'n': 10}\n\nPrevious\nAsync API\nNext\nCaching"
}