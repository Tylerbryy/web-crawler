{
	"title": "Psychic | 🦜️🔗 Langchain",
	"url": "https://python.langchain.com/docs/integrations/document_loaders/psychic",
	"html": "ComponentsDocument loadersPsychic\nPsychic\n\nThis notebook covers how to load documents from Psychic. See here for more details.\n\nPrerequisites​\nFollow the Quick Start section in this document\nLog into the Psychic dashboard and get your secret key\nInstall the frontend react library into your web app and have a user authenticate a connection. The connection will be created using the connection id that you specify.\nLoading documents​\n\nUse the PsychicLoader class to load in documents from a connection. Each connection has a connector id (corresponding to the SaaS app that was connected) and a connection id (which you passed in to the frontend library).\n\n# Uncomment this to install psychicapi if you don't already have it installed\npoetry run pip -q install psychicapi\n\n    \n    [notice] A new release of pip is available: 23.0.1 -> 23.1.2\n    [notice] To update, run: pip install --upgrade pip\n\nfrom langchain.document_loaders import PsychicLoader\nfrom psychicapi import ConnectorId\n\n# Create a document loader for google drive. We can also load from other connectors by setting the connector_id to the appropriate value e.g. ConnectorId.notion.value\n# This loader uses our test credentials\ngoogle_drive_loader = PsychicLoader(\n    api_key=\"7ddb61c1-8b6a-4d31-a58e-30d1c9ea480e\",\n    connector_id=ConnectorId.gdrive.value,\n    connection_id=\"google-test\",\n)\n\ndocuments = google_drive_loader.load()\n\nConverting the docs to embeddings​\n\nWe can now convert these documents into embeddings and store them in a vector database like Chroma\n\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.llms import OpenAI\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_documents(documents)\n\nembeddings = OpenAIEmbeddings()\ndocsearch = Chroma.from_documents(texts, embeddings)\nchain = RetrievalQAWithSourcesChain.from_chain_type(\n    OpenAI(temperature=0), chain_type=\"stuff\", retriever=docsearch.as_retriever()\n)\nchain({\"question\": \"what is psychic?\"}, return_only_outputs=True)\n\nPrevious\nPolars DataFrame\nNext\nPubMed"
}