{
	"title": "BagelDB | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/vectorstores/bageldb",
	"html": "ComponentsVector storesBagelDB\nBagelDB\n\nBagelDB (Open Vector Database for AI), is like GitHub for AI data. It is a collaborative platform where users can create, share, and manage vector datasets. It can support private projects for independent developers, internal collaborations for enterprises, and public contributions for data DAOs.\n\nInstallation and Setup‚Äã\npip install betabageldb\n\nCreate VectorStore from texts‚Äã\nfrom langchain.vectorstores import Bagel\n\ntexts = [\"hello bagel\", \"hello langchain\", \"I love salad\", \"my car\", \"a dog\"]\n# create cluster and add texts\ncluster = Bagel.from_texts(cluster_name=\"testing\", texts=texts)\n\n# similarity search\ncluster.similarity_search(\"bagel\", k=3)\n\n    [Document(page_content='hello bagel', metadata={}),\n     Document(page_content='my car', metadata={}),\n     Document(page_content='I love salad', metadata={})]\n\n# the score is a distance metric, so lower is better\ncluster.similarity_search_with_score(\"bagel\", k=3)\n\n    [(Document(page_content='hello bagel', metadata={}), 0.27392977476119995),\n     (Document(page_content='my car', metadata={}), 1.4783176183700562),\n     (Document(page_content='I love salad', metadata={}), 1.5342965126037598)]\n\n# delete the cluster\ncluster.delete_cluster()\n\nCreate VectorStore from docs‚Äã\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\n\nloader = TextLoader(\"../../modules/state_of_the_union.txt\")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)[:10]\n\n# create cluster with docs\ncluster = Bagel.from_documents(cluster_name=\"testing_with_docs\", documents=docs)\n\n# similarity search\nquery = \"What did the president say about Ketanji Brown Jackson\"\ndocs = cluster.similarity_search(query)\nprint(docs[0].page_content[:102])\n\n    Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the \n\nGet all text/doc from Cluster‚Äã\ntexts = [\"hello bagel\", \"this is langchain\"]\ncluster = Bagel.from_texts(cluster_name=\"testing\", texts=texts)\ncluster_data = cluster.get()\n\n# all keys\ncluster_data.keys()\n\n    dict_keys(['ids', 'embeddings', 'metadatas', 'documents'])\n\n# all values and keys\ncluster_data\n\n    {'ids': ['578c6d24-3763-11ee-a8ab-b7b7b34f99ba',\n      '578c6d25-3763-11ee-a8ab-b7b7b34f99ba',\n      'fb2fc7d8-3762-11ee-a8ab-b7b7b34f99ba',\n      'fb2fc7d9-3762-11ee-a8ab-b7b7b34f99ba',\n      '6b40881a-3762-11ee-a8ab-b7b7b34f99ba',\n      '6b40881b-3762-11ee-a8ab-b7b7b34f99ba',\n      '581e691e-3762-11ee-a8ab-b7b7b34f99ba',\n      '581e691f-3762-11ee-a8ab-b7b7b34f99ba'],\n     'embeddings': None,\n     'metadatas': [{}, {}, {}, {}, {}, {}, {}, {}],\n     'documents': ['hello bagel',\n      'this is langchain',\n      'hello bagel',\n      'this is langchain',\n      'hello bagel',\n      'this is langchain',\n      'hello bagel',\n      'this is langchain']}\n\ncluster.delete_cluster()\n\nCreate cluster with metadata & filter using metadata‚Äã\ntexts = [\"hello bagel\", \"this is langchain\"]\nmetadatas = [{\"source\": \"notion\"}, {\"source\": \"google\"}]\n\ncluster = Bagel.from_texts(cluster_name=\"testing\", texts=texts, metadatas=metadatas)\ncluster.similarity_search_with_score(\"hello bagel\", where={\"source\": \"notion\"})\n\n    [(Document(page_content='hello bagel', metadata={'source': 'notion'}), 0.0)]\n\n# delete the cluster\ncluster.delete_cluster()\n\nPrevious\nAzure Cognitive Search\nNext\nBaidu Cloud ElasticSearch VectorSearch"
}