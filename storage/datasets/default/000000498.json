{
	"title": "Baidu Qianfan | ğŸ¦œï¸ğŸ”— Langchain",
	"url": "https://python.langchain.com/docs/integrations/chat/baidu_qianfan_endpoint",
	"html": "ComponentsChat modelsBaidu Qianfan\nBaidu Qianfan\n\nBaidu AI Cloud Qianfan Platform is a one-stop large model development and service operation platform for enterprise developers. Qianfan not only provides including the model of Wenxin Yiyan (ERNIE-Bot) and the third-party open-source models, but also provides various AI development tools and the whole set of development environment, which facilitates customers to use and develop large model applications easily.\n\nBasically, those model are split into the following type:\n\nEmbedding\nChat\nCompletion\n\nIn this notebook, we will introduce how to use langchain with Qianfan mainly in Chat corresponding to the package langchain/chat_models in langchain:\n\nAPI Initializationâ€‹\n\nTo use the LLM services based on Baidu Qianfan, you have to initialize these parameters:\n\nYou could either choose to init the AK,SK in environment variables or init params:\n\nexport QIANFAN_AK=XXX\nexport QIANFAN_SK=XXX\n\nCurrent supported models:â€‹\nERNIE-Bot-turbo (default models)\nERNIE-Bot\nBLOOMZ-7B\nLlama-2-7b-chat\nLlama-2-13b-chat\nLlama-2-70b-chat\nQianfan-BLOOMZ-7B-compressed\nQianfan-Chinese-Llama-2-7B\nChatGLM2-6B-32K\nAquilaChat-7B\n\"\"\"For basic init and call\"\"\"\nimport os\n\nfrom langchain.chat_models import QianfanChatEndpoint\nfrom langchain.chat_models.base import HumanMessage\n\nos.environ[\"QIANFAN_AK\"] = \"your_ak\"\nos.environ[\"QIANFAN_SK\"] = \"your_sk\"\n\nchat = QianfanChatEndpoint(\n    streaming=True,\n)\nres = chat([HumanMessage(content=\"write a funny joke\")])\n\n    [INFO] [09-15 20:00:29] logging.py:55 [t:139698882193216]: requesting llm api endpoint: /chat/eb-instant\n\nfrom langchain.chat_models import QianfanChatEndpoint\nfrom langchain.schema import HumanMessage\n\nchatLLM = QianfanChatEndpoint(\n    streaming=True,\n)\nres = chatLLM.stream([HumanMessage(content=\"hi\")], streaming=True)\nfor r in res:\n    print(\"chat resp:\", r)\n\n\nasync def run_aio_generate():\n    resp = await chatLLM.agenerate(\n        messages=[[HumanMessage(content=\"write a 20 words sentence about sea.\")]]\n    )\n    print(resp)\n\n\nawait run_aio_generate()\n\n\nasync def run_aio_stream():\n    async for res in chatLLM.astream(\n        [HumanMessage(content=\"write a 20 words sentence about sea.\")]\n    ):\n        print(\"astream\", res)\n\n\nawait run_aio_stream()\n\n    [INFO] [09-15 20:00:36] logging.py:55 [t:139698882193216]: requesting llm api endpoint: /chat/eb-instant\n    [INFO] [09-15 20:00:37] logging.py:55 [t:139698882193216]: async requesting llm api endpoint: /chat/eb-instant\n\n\n    chat resp: content='æ‚¨å¥½ï¼Œæ‚¨ä¼¼ä¹è¾“å…¥' additional_kwargs={} example=False\n    chat resp: content='äº†ä¸€ä¸ªè¯é¢˜æ ‡ç­¾ï¼Œè¯·é—®éœ€è¦æˆ‘å¸®æ‚¨æ‰¾åˆ°ä»€ä¹ˆèµ„æ–™æˆ–è€…å¸®åŠ©æ‚¨è§£ç­”ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ' additional_kwargs={} example=False\n    chat resp: content='' additional_kwargs={} example=False\n\n\n    [INFO] [09-15 20:00:39] logging.py:55 [t:139698882193216]: async requesting llm api endpoint: /chat/eb-instant\n\n\n    generations=[[ChatGeneration(text=\"The sea is a vast expanse of water that covers much of the Earth's surface. It is a source of travel, trade, and entertainment, and is also a place of scientific exploration and marine conservation. The sea is an important part of our world, and we should cherish and protect it.\", generation_info={'finish_reason': 'finished'}, message=AIMessage(content=\"The sea is a vast expanse of water that covers much of the Earth's surface. It is a source of travel, trade, and entertainment, and is also a place of scientific exploration and marine conservation. The sea is an important part of our world, and we should cherish and protect it.\", additional_kwargs={}, example=False))]] llm_output={} run=[RunInfo(run_id=UUID('d48160a6-5960-4c1d-8a0e-90e6b51a209b'))]\n    astream content='The sea is a vast' additional_kwargs={} example=False\n    astream content=' expanse of water, a place of mystery and adventure. It is the source of many cultures and civilizations, and a center of trade and exploration. The sea is also a source of life and beauty, with its unique marine life and diverse' additional_kwargs={} example=False\n    astream content=' coral reefs. Whether you are swimming, diving, or just watching the sea, it is a place that captivates the imagination and transforms the spirit.' additional_kwargs={} example=False\n\nUse different models in Qianfanâ€‹\n\nIn the case you want to deploy your own model based on Ernie Bot or third-party open-source model, you could follow these steps:\n\nï¼ˆOptional, if the model are included in the default models, skip itï¼‰Deploy your model in Qianfan Console, get your own customized deploy endpoint.\nSet up the field called endpoint in the initialization:\nchatBloom = QianfanChatEndpoint(\n    streaming=True,\n    model=\"BLOOMZ-7B\",\n)\nres = chatBloom([HumanMessage(content=\"hi\")])\nprint(res)\n\n    [INFO] [09-15 20:00:50] logging.py:55 [t:139698882193216]: requesting llm api endpoint: /chat/bloomz_7b1\n\n\n    content='ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚' additional_kwargs={} example=False\n\nModel Params:â€‹\n\nFor now, only ERNIE-Bot and ERNIE-Bot-turbo support model params below, we might support more models in the future.\n\ntemperature\ntop_p\npenalty_score\nres = chat.stream(\n    [HumanMessage(content=\"hi\")],\n    **{\"top_p\": 0.4, \"temperature\": 0.1, \"penalty_score\": 1},\n)\n\nfor r in res:\n    print(r)\n\n    [INFO] [09-15 20:00:57] logging.py:55 [t:139698882193216]: requesting llm api endpoint: /chat/eb-instant\n\n\n    content='æ‚¨å¥½ï¼Œæ‚¨ä¼¼ä¹è¾“å…¥' additional_kwargs={} example=False\n    content='äº†ä¸€ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²ï¼Œä½†å¹¶æ²¡æœ‰ç»™å‡ºå…·ä½“çš„é—®é¢˜æˆ–åœºæ™¯ã€‚' additional_kwargs={} example=False\n    content='å¦‚æœæ‚¨èƒ½æä¾›æ›´å¤šä¿¡æ¯ï¼Œæˆ‘å¯ä»¥æ›´å¥½åœ°å›ç­”æ‚¨çš„é—®é¢˜ã€‚' additional_kwargs={} example=False\n    content='' additional_kwargs={} example=False\n\nPrevious\nBaichuan Chat\nNext\nBedrock Chat"
}