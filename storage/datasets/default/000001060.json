{
	"title": "Context | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/callbacks/context",
	"html": "ComponentsCallbacksContext\nContext\n\nContext provides user analytics for LLM powered products and features.\n\nWith Context, you can start understanding your users and improving their experiences in less than 30 minutes.\n\nIn this guide we will show you how to integrate with Context.\n\nInstallation and Setup‚Äã\npip install context-python --upgrade\n\nGetting API Credentials‚Äã\n\nTo get your Context API token:\n\nGo to the settings page within your Context account (https://with.context.ai/settings).\nGenerate a new API Token.\nStore this token somewhere secure.\nSetup Context‚Äã\n\nTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.\n\nEnsure you have installed the context-python package before using the handler.\n\nimport os\n\nfrom langchain.callbacks import ContextCallbackHandler\n\ntoken = os.environ[\"CONTEXT_API_TOKEN\"]\n\ncontext_callback = ContextCallbackHandler(token)\n\nUsage‚Äã\nUsing the Context callback within a chat model‚Äã\n\nThe Context callback handler can be used to directly record transcripts between users and AI assistants.\n\nExample‚Äã\nimport os\n\nfrom langchain.callbacks import ContextCallbackHandler\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import (\n    HumanMessage,\n    SystemMessage,\n)\n\ntoken = os.environ[\"CONTEXT_API_TOKEN\"]\n\nchat = ChatOpenAI(\n    headers={\"user_id\": \"123\"}, temperature=0, callbacks=[ContextCallbackHandler(token)]\n)\n\nmessages = [\n    SystemMessage(\n        content=\"You are a helpful assistant that translates English to French.\"\n    ),\n    HumanMessage(content=\"I love programming.\"),\n]\n\nprint(chat(messages))\n\nUsing the Context callback within Chains‚Äã\n\nThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.\n\nNote: Ensure that you pass the same context object to the chat model and the chain.\n\nWrong:\n\nchat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])\nchain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])\n\n\nCorrect:\n\nhandler = ContextCallbackHandler(token)\nchat = ChatOpenAI(temperature=0.9, callbacks=[callback])\nchain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])\n\nExample‚Äã\nimport os\n\nfrom langchain.callbacks import ContextCallbackHandler\nfrom langchain.chains import LLMChain\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    HumanMessagePromptTemplate,\n)\n\ntoken = os.environ[\"CONTEXT_API_TOKEN\"]\n\nhuman_message_prompt = HumanMessagePromptTemplate(\n    prompt=PromptTemplate(\n        template=\"What is a good name for a company that makes {product}?\",\n        input_variables=[\"product\"],\n    )\n)\nchat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\ncallback = ContextCallbackHandler(token)\nchat = ChatOpenAI(temperature=0.9, callbacks=[callback])\nchain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])\nprint(chain.run(\"colorful socks\"))\n\nPrevious\nConfident\nNext\nInfino"
}