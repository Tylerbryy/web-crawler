{
	"title": "Apify Dataset | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/document_loaders/apify_dataset",
	"html": "ComponentsDocument loadersApify Dataset\nApify Dataset\n\nApify Dataset is a scalable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of Apify Actors‚Äîserverless cloud programs for various web scraping, crawling, and data extraction use cases.\n\nThis notebook shows how to load Apify datasets to LangChain.\n\nPrerequisites‚Äã\n\nYou need to have an existing dataset on the Apify platform. If you don't have one, please first check out this notebook on how to use Apify to extract content from documentation, knowledge bases, help centers, or blogs.\n\n#!pip install apify-client\n\n\nFirst, import ApifyDatasetLoader into your source code:\n\nfrom langchain.document_loaders import ApifyDatasetLoader\nfrom langchain.document_loaders.base import Document\n\n\nThen provide a function that maps Apify dataset record fields to LangChain Document format.\n\nFor example, if your dataset items are structured like this:\n\n{\n    \"url\": \"https://apify.com\",\n    \"text\": \"Apify is the best web scraping and automation platform.\"\n}\n\n\nThe mapping function in the code below will convert them to LangChain Document format, so that you can use them further with any LLM model (e.g. for question answering).\n\nloader = ApifyDatasetLoader(\n    dataset_id=\"your-dataset-id\",\n    dataset_mapping_function=lambda dataset_item: Document(\n        page_content=dataset_item[\"text\"], metadata={\"source\": dataset_item[\"url\"]}\n    ),\n)\n\ndata = loader.load()\n\nAn example with question answering‚Äã\n\nIn this example, we use data from a dataset to answer a question.\n\nfrom langchain.docstore.document import Document\nfrom langchain.document_loaders import ApifyDatasetLoader\nfrom langchain.indexes import VectorstoreIndexCreator\n\nloader = ApifyDatasetLoader(\n    dataset_id=\"your-dataset-id\",\n    dataset_mapping_function=lambda item: Document(\n        page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n    ),\n)\n\nindex = VectorstoreIndexCreator().from_loaders([loader])\n\nquery = \"What is Apify?\"\nresult = index.query_with_sources(query)\n\nprint(result[\"answer\"])\nprint(result[\"sources\"])\n\n     Apify is a platform for developing, running, and sharing serverless cloud programs. It enables users to create web scraping and automation tools and publish them on the Apify platform.\n    \n    https://docs.apify.com/platform/actors, https://docs.apify.com/platform/actors/running/actors-in-store, https://docs.apify.com/platform/security, https://docs.apify.com/platform/actors/examples\n\nPrevious\nAlibaba Cloud MaxCompute\nNext\nArcGIS"
}