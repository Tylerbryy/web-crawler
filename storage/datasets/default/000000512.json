{
	"title": "OpenAI | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/chat/openai",
	"html": "ComponentsChat modelsOpenAI\nOpenAI\n\nThis notebook covers how to get started with OpenAI chat models.\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    HumanMessagePromptTemplate,\n    SystemMessagePromptTemplate,\n)\nfrom langchain.schema import HumanMessage, SystemMessage\n\nchat = ChatOpenAI(temperature=0)\n\n\nThe above cell assumes that your OpenAI API key is set in your environment variables. If you would rather manually specify your API key and/or organization ID, use the following code:\n\nchat = ChatOpenAI(temperature=0, openai_api_key=\"YOUR_API_KEY\", openai_organization=\"YOUR_ORGANIZATION_ID\")\n\n\nRemove the openai_organization parameter should it not apply to you.\n\nmessages = [\n    SystemMessage(\n        content=\"You are a helpful assistant that translates English to French.\"\n    ),\n    HumanMessage(\n        content=\"Translate this sentence from English to French. I love programming.\"\n    ),\n]\nchat(messages)\n\n    AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)\n\n\nYou can make use of templating by using a MessagePromptTemplate. You can build a ChatPromptTemplate from one or more MessagePromptTemplates. You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, which you can convert to a string or Message object, depending on whether you want to use the formatted value as input to an llm or chat model.\n\nFor convenience, there is a from_template method exposed on the template. If you were to use this template, this is what it would look like:\n\ntemplate = (\n    \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n)\nsystem_message_prompt = SystemMessagePromptTemplate.from_template(template)\nhuman_template = \"{text}\"\nhuman_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\nchat_prompt = ChatPromptTemplate.from_messages(\n    [system_message_prompt, human_message_prompt]\n)\n\n# get a chat completion from the formatted messages\nchat(\n    chat_prompt.format_prompt(\n        input_language=\"English\", output_language=\"French\", text=\"I love programming.\"\n    ).to_messages()\n)\n\n    AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)\n\nFine-tuning‚Äã\n\nYou can call fine-tuned OpenAI models by passing in your corresponding modelName parameter.\n\nThis generally takes the form of ft:{OPENAI_MODEL_NAME}:{ORG_NAME}::{MODEL_ID}. For example:\n\nfine_tuned_model = ChatOpenAI(\n    temperature=0, model_name=\"ft:gpt-3.5-turbo-0613:langchain::7qTVM5AR\"\n)\n\nfine_tuned_model(messages)\n\n    AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)\n\nPrevious\nOllama\nNext\nAliCloud PAI EAS"
}