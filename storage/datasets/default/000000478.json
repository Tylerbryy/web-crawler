{
	"title": "OpenAI Multi Functions Agent | ğŸ¦œï¸ğŸ”— Langchain",
	"url": "https://python.langchain.com/docs/modules/agents/agent_types/openai_multi_functions_agent",
	"html": "ModulesAgentsAgent TypesOpenAI Multi Functions Agent\nOpenAI Multi Functions Agent\n\nThis notebook showcases using an agent that uses the OpenAI functions ability to respond to the prompts of the user using a Large Language Model.\n\nInstall openai, google-search-results packages which are required as the LangChain packages call them internally.\n\npip install openai google-search-results\n\nfrom langchain.agents import AgentType, Tool, initialize_agent\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.utilities import SerpAPIWrapper\n\n\nThe agent is given the ability to perform search functionalities with the respective tool\n\nSerpAPIWrapper:\n\nThis initializes the SerpAPIWrapper for search functionality (search).\n\nimport getpass\nimport os\n\nos.environ[\"SERPAPI_API_KEY\"] = getpass.getpass()\n\n    Â·Â·Â·Â·Â·Â·Â·Â·\n\n# Initialize the OpenAI language model\n# Replace <your_api_key> in openai_api_key=\"<your_api_key>\" with your actual OpenAI key.\nllm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n\n# Initialize the SerpAPIWrapper for search functionality\n# Replace <your_api_key> in serpapi_api_key=\"<your_api_key>\" with your actual SerpAPI key.\nsearch = SerpAPIWrapper()\n\n# Define a list of tools offered by the agent\ntools = [\n    Tool(\n        name=\"Search\",\n        func=search.run,\n        description=\"Useful when you need to answer questions about current events. You should ask targeted questions.\",\n    ),\n]\n\nmrkl = initialize_agent(\n    tools, llm, agent=AgentType.OPENAI_MULTI_FUNCTIONS, verbose=True\n)\n\n# Do this so we can see exactly what's going on under the hood\nfrom langchain.globals import set_debug\n\nset_debug(True)\n\nmrkl.run(\"What is the weather in LA and SF?\")\n\n    [chain/start] [1:chain:AgentExecutor] Entering Chain run with input:\n    {\n      \"input\": \"What is the weather in LA and SF?\"\n    }\n    [llm/start] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      \"prompts\": [\n        \"System: You are a helpful AI assistant.\\nHuman: What is the weather in LA and SF?\"\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] [2.91s] Exiting LLM run with output:\n    {\n      \"generations\": [\n        [\n          {\n            \"text\": \"\",\n            \"generation_info\": null,\n            \"message\": {\n              \"content\": \"\",\n              \"additional_kwargs\": {\n                \"function_call\": {\n                  \"name\": \"tool_selection\",\n                  \"arguments\": \"{\\n  \\\"actions\\\": [\\n    {\\n      \\\"action_name\\\": \\\"Search\\\",\\n      \\\"action\\\": {\\n        \\\"tool_input\\\": \\\"weather in Los Angeles\\\"\\n      }\\n    },\\n    {\\n      \\\"action_name\\\": \\\"Search\\\",\\n      \\\"action\\\": {\\n        \\\"tool_input\\\": \\\"weather in San Francisco\\\"\\n      }\\n    }\\n  ]\\n}\"\n                }\n              },\n              \"example\": false\n            }\n          }\n        ]\n      ],\n      \"llm_output\": {\n        \"token_usage\": {\n          \"prompt_tokens\": 81,\n          \"completion_tokens\": 75,\n          \"total_tokens\": 156\n        },\n        \"model_name\": \"gpt-3.5-turbo-0613\"\n      },\n      \"run\": null\n    }\n    [tool/start] [1:chain:AgentExecutor > 3:tool:Search] Entering Tool run with input:\n    \"{'tool_input': 'weather in Los Angeles'}\"\n    [tool/end] [1:chain:AgentExecutor > 3:tool:Search] [608.693ms] Exiting Tool run with output:\n    \"Mostly cloudy early, then sunshine for the afternoon. High 76F. Winds SW at 5 to 10 mph. Humidity59%.\"\n    [tool/start] [1:chain:AgentExecutor > 4:tool:Search] Entering Tool run with input:\n    \"{'tool_input': 'weather in San Francisco'}\"\n    [tool/end] [1:chain:AgentExecutor > 4:tool:Search] [517.475ms] Exiting Tool run with output:\n    \"Partly cloudy this evening, then becoming cloudy after midnight. Low 53F. Winds WSW at 10 to 20 mph. Humidity83%.\"\n    [llm/start] [1:chain:AgentExecutor > 5:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      \"prompts\": [\n        \"System: You are a helpful AI assistant.\\nHuman: What is the weather in LA and SF?\\nAI: {'name': 'tool_selection', 'arguments': '{\\\\n  \\\"actions\\\": [\\\\n    {\\\\n      \\\"action_name\\\": \\\"Search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"tool_input\\\": \\\"weather in Los Angeles\\\"\\\\n      }\\\\n    },\\\\n    {\\\\n      \\\"action_name\\\": \\\"Search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"tool_input\\\": \\\"weather in San Francisco\\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}'}\\nFunction: Mostly cloudy early, then sunshine for the afternoon. High 76F. Winds SW at 5 to 10 mph. Humidity59%.\\nAI: {'name': 'tool_selection', 'arguments': '{\\\\n  \\\"actions\\\": [\\\\n    {\\\\n      \\\"action_name\\\": \\\"Search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"tool_input\\\": \\\"weather in Los Angeles\\\"\\\\n      }\\\\n    },\\\\n    {\\\\n      \\\"action_name\\\": \\\"Search\\\",\\\\n      \\\"action\\\": {\\\\n        \\\"tool_input\\\": \\\"weather in San Francisco\\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}'}\\nFunction: Partly cloudy this evening, then becoming cloudy after midnight. Low 53F. Winds WSW at 10 to 20 mph. Humidity83%.\"\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 5:llm:ChatOpenAI] [2.33s] Exiting LLM run with output:\n    {\n      \"generations\": [\n        [\n          {\n            \"text\": \"The weather in Los Angeles is mostly cloudy with a high of 76Â°F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53Â°F and a humidity of 83%.\",\n            \"generation_info\": null,\n            \"message\": {\n              \"content\": \"The weather in Los Angeles is mostly cloudy with a high of 76Â°F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53Â°F and a humidity of 83%.\",\n              \"additional_kwargs\": {},\n              \"example\": false\n            }\n          }\n        ]\n      ],\n      \"llm_output\": {\n        \"token_usage\": {\n          \"prompt_tokens\": 307,\n          \"completion_tokens\": 54,\n          \"total_tokens\": 361\n        },\n        \"model_name\": \"gpt-3.5-turbo-0613\"\n      },\n      \"run\": null\n    }\n    [chain/end] [1:chain:AgentExecutor] [6.37s] Exiting Chain run with output:\n    {\n      \"output\": \"The weather in Los Angeles is mostly cloudy with a high of 76Â°F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53Â°F and a humidity of 83%.\"\n    }\n\n\n\n\n\n    'The weather in Los Angeles is mostly cloudy with a high of 76Â°F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53Â°F and a humidity of 83%.'\n\nConfiguring max iteration behaviorâ€‹\n\nTo make sure that our agent doesn't get stuck in excessively long loops, we can set max_iterations. We can also set an early stopping method, which will determine our agent's behavior once the number of max iterations is hit. By default, the early stopping uses method force which just returns that constant string. Alternatively, you could specify method generate which then does one FINAL pass through the LLM to generate an output.\n\nmrkl = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.OPENAI_FUNCTIONS,\n    verbose=True,\n    max_iterations=2,\n    early_stopping_method=\"generate\",\n)\n\nmrkl.run(\"What is the weather in NYC today, yesterday, and the day before?\")\n\n    [chain/start] [1:chain:AgentExecutor] Entering Chain run with input:\n    {\n      \"input\": \"What is the weather in NYC today, yesterday, and the day before?\"\n    }\n    [llm/start] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      \"prompts\": [\n        \"System: You are a helpful AI assistant.\\nHuman: What is the weather in NYC today, yesterday, and the day before?\"\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] [1.27s] Exiting LLM run with output:\n    {\n      \"generations\": [\n        [\n          {\n            \"text\": \"\",\n            \"generation_info\": null,\n            \"message\": {\n              \"lc\": 1,\n              \"type\": \"constructor\",\n              \"id\": [\n                \"langchain\",\n                \"schema\",\n                \"messages\",\n                \"AIMessage\"\n              ],\n              \"kwargs\": {\n                \"content\": \"\",\n                \"additional_kwargs\": {\n                  \"function_call\": {\n                    \"name\": \"Search\",\n                    \"arguments\": \"{\\n  \\\"query\\\": \\\"weather in NYC today\\\"\\n}\"\n                  }\n                }\n              }\n            }\n          }\n        ]\n      ],\n      \"llm_output\": {\n        \"token_usage\": {\n          \"prompt_tokens\": 79,\n          \"completion_tokens\": 17,\n          \"total_tokens\": 96\n        },\n        \"model_name\": \"gpt-3.5-turbo-0613\"\n      },\n      \"run\": null\n    }\n    [tool/start] [1:chain:AgentExecutor > 3:tool:Search] Entering Tool run with input:\n    \"{'query': 'weather in NYC today'}\"\n    [tool/end] [1:chain:AgentExecutor > 3:tool:Search] [3.84s] Exiting Tool run with output:\n    \"10:00 am Â· Feels Like85Â° Â· WindSE 4 mph Â· Humidity78% Â· UV Index3 of 11 Â· Cloud Cover81% Â· Rain Amount0 in ...\"\n    [llm/start] [1:chain:AgentExecutor > 4:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      \"prompts\": [\n        \"System: You are a helpful AI assistant.\\nHuman: What is the weather in NYC today, yesterday, and the day before?\\nAI: {'name': 'Search', 'arguments': '{\\\\n  \\\"query\\\": \\\"weather in NYC today\\\"\\\\n}'}\\nFunction: 10:00 am Â· Feels Like85Â° Â· WindSE 4 mph Â· Humidity78% Â· UV Index3 of 11 Â· Cloud Cover81% Â· Rain Amount0 in ...\"\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 4:llm:ChatOpenAI] [1.24s] Exiting LLM run with output:\n    {\n      \"generations\": [\n        [\n          {\n            \"text\": \"\",\n            \"generation_info\": null,\n            \"message\": {\n              \"lc\": 1,\n              \"type\": \"constructor\",\n              \"id\": [\n                \"langchain\",\n                \"schema\",\n                \"messages\",\n                \"AIMessage\"\n              ],\n              \"kwargs\": {\n                \"content\": \"\",\n                \"additional_kwargs\": {\n                  \"function_call\": {\n                    \"name\": \"Search\",\n                    \"arguments\": \"{\\n  \\\"query\\\": \\\"weather in NYC yesterday\\\"\\n}\"\n                  }\n                }\n              }\n            }\n          }\n        ]\n      ],\n      \"llm_output\": {\n        \"token_usage\": {\n          \"prompt_tokens\": 142,\n          \"completion_tokens\": 17,\n          \"total_tokens\": 159\n        },\n        \"model_name\": \"gpt-3.5-turbo-0613\"\n      },\n      \"run\": null\n    }\n    [tool/start] [1:chain:AgentExecutor > 5:tool:Search] Entering Tool run with input:\n    \"{'query': 'weather in NYC yesterday'}\"\n    [tool/end] [1:chain:AgentExecutor > 5:tool:Search] [1.15s] Exiting Tool run with output:\n    \"New York Temperature Yesterday. Maximum temperature yesterday: 81 Â°F (at 1:51 pm) Minimum temperature yesterday: 72 Â°F (at 7:17 pm) Average temperature ...\"\n    [llm/start] [1:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      \"prompts\": [\n        \"System: You are a helpful AI assistant.\\nHuman: What is the weather in NYC today, yesterday, and the day before?\\nAI: {'name': 'Search', 'arguments': '{\\\\n  \\\"query\\\": \\\"weather in NYC today\\\"\\\\n}'}\\nFunction: 10:00 am Â· Feels Like85Â° Â· WindSE 4 mph Â· Humidity78% Â· UV Index3 of 11 Â· Cloud Cover81% Â· Rain Amount0 in ...\\nAI: {'name': 'Search', 'arguments': '{\\\\n  \\\"query\\\": \\\"weather in NYC yesterday\\\"\\\\n}'}\\nFunction: New York Temperature Yesterday. Maximum temperature yesterday: 81 Â°F (at 1:51 pm) Minimum temperature yesterday: 72 Â°F (at 7:17 pm) Average temperature ...\"\n      ]\n    }\n    [llm/end] [1:llm:ChatOpenAI] [2.68s] Exiting LLM run with output:\n    {\n      \"generations\": [\n        [\n          {\n            \"text\": \"Today in NYC, the weather is currently 85Â°F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81Â°F at 1:51 pm, and the minimum temperature was 72Â°F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information.\",\n            \"generation_info\": null,\n            \"message\": {\n              \"lc\": 1,\n              \"type\": \"constructor\",\n              \"id\": [\n                \"langchain\",\n                \"schema\",\n                \"messages\",\n                \"AIMessage\"\n              ],\n              \"kwargs\": {\n                \"content\": \"Today in NYC, the weather is currently 85Â°F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81Â°F at 1:51 pm, and the minimum temperature was 72Â°F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information.\",\n                \"additional_kwargs\": {}\n              }\n            }\n          }\n        ]\n      ],\n      \"llm_output\": {\n        \"token_usage\": {\n          \"prompt_tokens\": 160,\n          \"completion_tokens\": 91,\n          \"total_tokens\": 251\n        },\n        \"model_name\": \"gpt-3.5-turbo-0613\"\n      },\n      \"run\": null\n    }\n    [chain/end] [1:chain:AgentExecutor] [10.18s] Exiting Chain run with output:\n    {\n      \"output\": \"Today in NYC, the weather is currently 85Â°F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81Â°F at 1:51 pm, and the minimum temperature was 72Â°F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information.\"\n    }\n\n\n\n\n\n    'Today in NYC, the weather is currently 85Â°F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81Â°F at 1:51 pm, and the minimum temperature was 72Â°F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information.'\n\n\nNotice that we never get around to looking up the weather the day before yesterday, due to hitting our max_iterations limit.\n\nPrevious\nOpenAI functions\nNext\nOpenAI tools"
}