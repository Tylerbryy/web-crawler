{
	"title": "Memgraph QA chain | ðŸ¦œï¸ðŸ”— Langchain",
	"url": "https://python.langchain.com/docs/use_cases/graph/graph_memgraph_qa",
	"html": "Graph queryingMemgraph QA chain\nMemgraph QA chain\n\nThis notebook shows how to use LLMs to provide a natural language interface to a Memgraph database. To complete this tutorial, you will need Docker and Python 3.x installed.\n\nTo follow along with this tutorial, ensure you have a running Memgraph instance. You can download and run it in a local Docker container by executing the following script:\n\ndocker run \\\n    -it \\\n    -p 7687:7687 \\\n    -p 7444:7444 \\\n    -p 3000:3000 \\\n    -e MEMGRAPH=\"--bolt-server-name-for-init=Neo4j/\" \\\n    -v mg_lib:/var/lib/memgraph memgraph/memgraph-platform\n\n\nYou will need to wait a few seconds for the database to start. If the process completes successfully, you should see something like this:\n\nmgconsole X.X\nConnected to 'memgraph://127.0.0.1:7687'\nType :help for shell usage\nQuit the shell by typing Ctrl-D(eof) or :quit\nmemgraph>\n\n\nNow you can start playing with Memgraph!\n\nBegin by installing and importing all the necessary packages. We'll use the package manager called pip, along with the --user flag, to ensure proper permissions. If you've installed Python 3.4 or a later version, pip is included by default. You can install all the required packages using the following command:\n\npip install langchain openai neo4j gqlalchemy --user\n\n\nYou can either run the provided code blocks in this notebook or use a separate Python file to experiment with Memgraph and LangChain.\n\nimport os\n\nfrom gqlalchemy import Memgraph\nfrom langchain.chains import GraphCypherQAChain\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.graphs import MemgraphGraph\nfrom langchain.prompts import PromptTemplate\n\n\nWe're utilizing the Python library GQLAlchemy to establish a connection between our Memgraph database and Python script. To execute queries, we can set up a Memgraph instance as follows:\n\nmemgraph = Memgraph(host=\"127.0.0.1\", port=7687)\n\nPopulating the databaseâ€‹\n\nYou can effortlessly populate your new, empty database using the Cypher query language. Don't worry if you don't grasp every line just yet, you can learn Cypher from the documentation here. Running the following script will execute a seeding query on the database, giving us data about a video game, including details like the publisher, available platforms, and genres. This data will serve as a basis for our work.\n\n# Creating and executing the seeding query\nquery = \"\"\"\n    MERGE (g:Game {name: \"Baldur's Gate 3\"})\n    WITH g, [\"PlayStation 5\", \"Mac OS\", \"Windows\", \"Xbox Series X/S\"] AS platforms,\n            [\"Adventure\", \"Role-Playing Game\", \"Strategy\"] AS genres\n    FOREACH (platform IN platforms |\n        MERGE (p:Platform {name: platform})\n        MERGE (g)-[:AVAILABLE_ON]->(p)\n    )\n    FOREACH (genre IN genres |\n        MERGE (gn:Genre {name: genre})\n        MERGE (g)-[:HAS_GENRE]->(gn)\n    )\n    MERGE (p:Publisher {name: \"Larian Studios\"})\n    MERGE (g)-[:PUBLISHED_BY]->(p);\n\"\"\"\n\nmemgraph.execute(query)\n\nRefresh graph schemaâ€‹\n\nYou're all set to instantiate the Memgraph-LangChain graph using the following script. This interface will allow us to query our database using LangChain, automatically creating the required graph schema for generating Cypher queries through LLM.\n\ngraph = MemgraphGraph(url=\"bolt://localhost:7687\", username=\"\", password=\"\")\n\n\nIf necessary, you can manually refresh the graph schema as follows.\n\ngraph.refresh_schema()\n\n\nTo familiarize yourself with the data and verify the updated graph schema, you can print it using the following statement.\n\nprint(graph.schema)\n\nNode properties are the following:\nNode name: 'Game', Node properties: [{'property': 'name', 'type': 'str'}]\nNode name: 'Platform', Node properties: [{'property': 'name', 'type': 'str'}]\nNode name: 'Genre', Node properties: [{'property': 'name', 'type': 'str'}]\nNode name: 'Publisher', Node properties: [{'property': 'name', 'type': 'str'}]\n\nRelationship properties are the following:\n\nThe relationships are the following:\n['(:Game)-[:AVAILABLE_ON]->(:Platform)']\n['(:Game)-[:HAS_GENRE]->(:Genre)']\n['(:Game)-[:PUBLISHED_BY]->(:Publisher)']\n\nQuerying the databaseâ€‹\n\nTo interact with the OpenAI API, you must configure your API key as an environment variable using the Python os package. This ensures proper authorization for your requests. You can find more information on obtaining your API key here.\n\nos.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n\n\nYou should create the graph chain using the following script, which will be utilized in the question-answering process based on your graph data. While it defaults to GPT-3.5-turbo, you might also consider experimenting with other models like GPT-4 for notably improved Cypher queries and outcomes. We'll utilize the OpenAI chat, utilizing the key you previously configured. We'll set the temperature to zero, ensuring predictable and consistent answers. Additionally, we'll use our Memgraph-LangChain graph and set the verbose parameter, which defaults to False, to True to receive more detailed messages regarding query generation.\n\nchain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, model_name=\"gpt-3.5-turbo\"\n)\n\n\nNow you can start asking questions!\n\nresponse = chain.run(\"Which platforms is Baldur's Gate 3 available on?\")\nprint(response)\n\n> Entering new GraphCypherQAChain chain...\nGenerated Cypher:\nMATCH (g:Game {name: 'Baldur\\'s Gate 3'})-[:AVAILABLE_ON]->(p:Platform)\nRETURN p.name\nFull Context:\n[{'p.name': 'PlayStation 5'}, {'p.name': 'Mac OS'}, {'p.name': 'Windows'}, {'p.name': 'Xbox Series X/S'}]\n\n> Finished chain.\nBaldur's Gate 3 is available on PlayStation 5, Mac OS, Windows, and Xbox Series X/S.\n\nresponse = chain.run(\"Is Baldur's Gate 3 available on Windows?\")\nprint(response)\n\n> Entering new GraphCypherQAChain chain...\nGenerated Cypher:\nMATCH (:Game {name: 'Baldur\\'s Gate 3'})-[:AVAILABLE_ON]->(:Platform {name: 'Windows'})\nRETURN true\nFull Context:\n[{'true': True}]\n\n> Finished chain.\nYes, Baldur's Gate 3 is available on Windows.\n\nChain modifiersâ€‹\n\nTo modify the behavior of your chain and obtain more context or additional information, you can modify the chain's parameters.\n\nReturn direct query resultsâ€‹\n\nThe return_direct modifier specifies whether to return the direct results of the executed Cypher query or the processed natural language response.\n\n# Return the result of querying the graph directly\nchain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, return_direct=True\n)\n\nresponse = chain.run(\"Which studio published Baldur's Gate 3?\")\nprint(response)\n\n> Entering new GraphCypherQAChain chain...\nGenerated Cypher:\nMATCH (:Game {name: 'Baldur\\'s Gate 3'})-[:PUBLISHED_BY]->(p:Publisher)\nRETURN p.name\n\n> Finished chain.\n[{'p.name': 'Larian Studios'}]\n\nReturn query intermediate stepsâ€‹\n\nThe return_intermediate_steps chain modifier enhances the returned response by including the intermediate steps of the query in addition to the initial query result.\n\n# Return all the intermediate steps of query execution\nchain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, return_intermediate_steps=True\n)\n\nresponse = chain(\"Is Baldur's Gate 3 an Adventure game?\")\nprint(f\"Intermediate steps: {response['intermediate_steps']}\")\nprint(f\"Final response: {response['result']}\")\n\n> Entering new GraphCypherQAChain chain...\nGenerated Cypher:\nMATCH (g:Game {name: 'Baldur\\'s Gate 3'})-[:HAS_GENRE]->(genre:Genre {name: 'Adventure'})\nRETURN g, genre\nFull Context:\n[{'g': {'name': \"Baldur's Gate 3\"}, 'genre': {'name': 'Adventure'}}]\n\n> Finished chain.\nIntermediate steps: [{'query': \"MATCH (g:Game {name: 'Baldur\\\\'s Gate 3'})-[:HAS_GENRE]->(genre:Genre {name: 'Adventure'})\\nRETURN g, genre\"}, {'context': [{'g': {'name': \"Baldur's Gate 3\"}, 'genre': {'name': 'Adventure'}}]}]\nFinal response: Yes, Baldur's Gate 3 is an Adventure game.\n\nLimit the number of query resultsâ€‹\n\nThe top_k modifier can be used when you want to restrict the maximum number of query results.\n\n# Limit the maximum number of results returned by query\nchain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, top_k=2\n)\n\nresponse = chain.run(\"What genres are associated with Baldur's Gate 3?\")\nprint(response)\n\n> Entering new GraphCypherQAChain chain...\nGenerated Cypher:\nMATCH (:Game {name: 'Baldur\\'s Gate 3'})-[:HAS_GENRE]->(g:Genre)\nRETURN g.name\nFull Context:\n[{'g.name': 'Adventure'}, {'g.name': 'Role-Playing Game'}]\n\n> Finished chain.\nBaldur's Gate 3 is associated with the genres Adventure and Role-Playing Game.\n\nAdvanced querying\n\nAs the complexity of your solution grows, you might encounter different use-cases that require careful handling. Ensuring your application's scalability is essential to maintain a smooth user flow without any hitches.\n\nLet's instantiate our chain once again and attempt to ask some questions that users might potentially ask.\n\nchain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, model_name=\"gpt-3.5-turbo\"\n)\n\nresponse = chain.run(\"Is Baldur's Gate 3 available on PS5?\")\nprint(response)\n\n> Entering new GraphCypherQAChain chain...\nGenerated Cypher:\nMATCH (g:Game {name: 'Baldur\\'s Gate 3'})-[:AVAILABLE_ON]->(p:Platform {name: 'PS5'})\nRETURN g.name, p.name\nFull Context:\n[]\n\n> Finished chain.\nI'm sorry, but I don't have the information to answer your question.\n\n\nThe generated Cypher query looks fine, but we didn't receive any information in response. This illustrates a common challenge when working with LLMs - the misalignment between how users phrase queries and how data is stored. In this case, the difference between user perception and the actual data storage can cause mismatches. Prompt refinement, the process of honing the model's prompts to better grasp these distinctions, is an efficient solution that tackles this issue. Through prompt refinement, the model gains increased proficiency in generating precise and pertinent queries, leading to the successful retrieval of the desired data.\n\nPrompt refinementâ€‹\n\nTo address this, we can adjust the initial Cypher prompt of the QA chain. This involves adding guidance to the LLM on how users can refer to specific platforms, such as PS5 in our case. We achieve this using the LangChain PromptTemplate, creating a modified initial prompt. This modified prompt is then supplied as an argument to our refined Memgraph-LangChain instance.\n\nCYPHER_GENERATION_TEMPLATE = \"\"\"\nTask:Generate Cypher statement to query a graph database.\nInstructions:\nUse only the provided relationship types and properties in the schema.\nDo not use any other relationship types or properties that are not provided.\nSchema:\n{schema}\nNote: Do not include any explanations or apologies in your responses.\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\nDo not include any text except the generated Cypher statement.\nIf the user asks about PS5, Play Station 5 or PS 5, that is the platform called PlayStation 5.\n\nThe question is:\n{question}\n\"\"\"\n\nCYPHER_GENERATION_PROMPT = PromptTemplate(\n    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n)\n\nchain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0),\n    cypher_prompt=CYPHER_GENERATION_PROMPT,\n    graph=graph,\n    verbose=True,\n    model_name=\"gpt-3.5-turbo\",\n)\n\nresponse = chain.run(\"Is Baldur's Gate 3 available on PS5?\")\nprint(response)\n\n> Entering new GraphCypherQAChain chain...\nGenerated Cypher:\nMATCH (g:Game {name: 'Baldur\\'s Gate 3'})-[:AVAILABLE_ON]->(p:Platform {name: 'PlayStation 5'})\nRETURN g.name, p.name\nFull Context:\n[{'g.name': \"Baldur's Gate 3\", 'p.name': 'PlayStation 5'}]\n\n> Finished chain.\nYes, Baldur's Gate 3 is available on PlayStation 5.\n\n\nNow, with the revised initial Cypher prompt that includes guidance on platform naming, we are obtaining accurate and relevant results that align more closely with user queries.\n\nThis approach allows for further improvement of your QA chain. You can effortlessly integrate extra prompt refinement data into your chain, thereby enhancing the overall user experience of your app.\n\nPrevious\nKuzuQAChain\nNext\nNebulaGraphQAChain"
}