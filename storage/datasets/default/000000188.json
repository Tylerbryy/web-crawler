{
	"title": "AWS | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/platforms/aws",
	"html": "ProvidersAWS\nAWS\n\nAll functionality related to Amazon AWS platform\n\nLLMs‚Äã\nBedrock‚Äã\n\nSee a usage example.\n\nfrom langchain.llms.bedrock import Bedrock\n\nAmazon API Gateway‚Äã\n\nAmazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \"front door\" for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.\n\nAPI Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. API Gateway has no minimum fees or startup costs. You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales.\n\nSee a usage example.\n\nfrom langchain.llms import AmazonAPIGateway\n\napi_url = \"https://<api_gateway_id>.execute-api.<region>.amazonaws.com/LATEST/HF\"\n# These are sample parameters for Falcon 40B Instruct Deployed from Amazon SageMaker JumpStart\nmodel_kwargs = {\n    \"max_new_tokens\": 100,\n    \"num_return_sequences\": 1,\n    \"top_k\": 50,\n    \"top_p\": 0.95,\n    \"do_sample\": False,\n    \"return_full_text\": True,\n    \"temperature\": 0.2,\n}\nllm = AmazonAPIGateway(api_url=api_url, model_kwargs=model_kwargs)\n\nSageMaker Endpoint‚Äã\n\nAmazon SageMaker is a system that can build, train, and deploy machine learning (ML) models with fully managed infrastructure, tools, and workflows.\n\nWe use SageMaker to host our model and expose it as the SageMaker Endpoint.\n\nSee a usage example.\n\nfrom langchain.llms import SagemakerEndpoint\nfrom langchain.llms.sagemaker_endpoint import LLMContentHandler\n\nText Embedding Models‚Äã\nBedrock‚Äã\n\nSee a usage example.\n\nfrom langchain.embeddings import BedrockEmbeddings\n\nSageMaker Endpoint‚Äã\n\nSee a usage example.\n\nfrom langchain.embeddings import SagemakerEndpointEmbeddings\nfrom langchain.llms.sagemaker_endpoint import ContentHandlerBase\n\nDocument loaders‚Äã\nAWS S3 Directory and File‚Äã\n\nAmazon Simple Storage Service (Amazon S3) is an object storage service. AWS S3 Directory AWS S3 Buckets\n\nSee a usage example for S3DirectoryLoader.\n\nSee a usage example for S3FileLoader.\n\nfrom langchain.document_loaders import S3DirectoryLoader, S3FileLoader\n\nMemory‚Äã\nAWS DynamoDB‚Äã\n\nAWS DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.\n\nWe have to configure the AWS CLI.\n\nWe need to install the boto3 library.\n\npip install boto3\n\n\nSee a usage example.\n\nfrom langchain.memory import DynamoDBChatMessageHistory\n\nPrevious\nAnthropic\nNext\nGoogle"
}