{
	"title": "Jina | 🦜️🔗 Langchain",
	"url": "https://python.langchain.com/docs/integrations/providers/jina",
	"html": "ProvidersMoreJina\nJina\n\nThis page covers how to use the Jina ecosystem within LangChain. It is broken into two parts: installation and setup, and then references to specific Jina wrappers.\n\nInstallation and Setup​\nInstall the Python SDK with pip install jina\nGet a Jina AI Cloud auth token from here and set it as an environment variable (JINA_AUTH_TOKEN)\nWrappers​\nEmbeddings​\n\nThere exists a Jina Embeddings wrapper, which you can access with\n\nfrom langchain.embeddings import JinaEmbeddings\n\n\nFor a more detailed walkthrough of this, see this notebook\n\nDeployment​\n\nLangchain-serve, powered by Jina, helps take LangChain apps to production with easy to use REST/WebSocket APIs and Slack bots.\n\nUsage​\n\nInstall the package from PyPI.\n\npip install langchain-serve\n\n\nWrap your LangChain app with the @serving decorator.\n\n# app.py\nfrom lcserve import serving\n\n@serving\ndef ask(input: str) -> str:\n    from langchain.chains import LLMChain\n    from langchain.llms import OpenAI\n    from langchain.agents import AgentExecutor, ZeroShotAgent\n    \n    tools = [...] # list of tools\n    prompt = ZeroShotAgent.create_prompt(\n        tools, input_variables=[\"input\", \"agent_scratchpad\"],\n    )\n    llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n    agent = ZeroShotAgent(\n        llm_chain=llm_chain, allowed_tools=[tool.name for tool in tools]\n    )\n    agent_executor = AgentExecutor.from_agent_and_tools(\n        agent=agent, \n        tools=tools, \n        verbose=True,\n    )\n    return agent_executor.run(input)\n\n\nDeploy on Jina AI Cloud with lc-serve deploy jcloud app. Once deployed, we can send a POST request to the API endpoint to get a response.\n\ncurl -X 'POST' 'https://<your-app>.wolf.jina.ai/ask' \\\n -d '{\n  \"input\": \"Your Question here?\",\n  \"envs\": {\n     \"OPENAI_API_KEY\": \"sk-***\"\n  }\n}'\n\n\nYou can also self-host the app on your infrastructure with Docker-compose or Kubernetes. See here for more details.\n\nLangchain-serve also allows to deploy the apps with WebSocket APIs and Slack Bots both on Jina AI Cloud or self-hosted infrastructure.\n\nPrevious\nJavelin AI Gateway\nNext\nJohnsnowlabs"
}