{
	"title": "Argilla | ü¶úÔ∏èüîó Langchain",
	"url": "https://python.langchain.com/docs/integrations/callbacks/argilla",
	"html": "ComponentsCallbacksArgilla\nArgilla\n\nArgilla is an open-source data curation platform for LLMs. Using Argilla, everyone can build robust language models through faster data curation using both human and machine feedback. We provide support for each step in the MLOps cycle, from data labeling to model monitoring.\n\nIn this guide we will demonstrate how to track the inputs and responses of your LLM to generate a dataset in Argilla, using the ArgillaCallbackHandler.\n\nIt's useful to keep track of the inputs and outputs of your LLMs to generate datasets for future fine-tuning. This is especially useful when you're using a LLM to generate data for a specific task, such as question answering, summarization, or translation.\n\nInstallation and Setup‚Äã\npip install argilla --upgrade\npip install openai\n\nGetting API Credentials‚Äã\n\nTo get the Argilla API credentials, follow the next steps:\n\nGo to your Argilla UI.\nClick on your profile picture and go to \"My settings\".\nThen copy the API Key.\n\nIn Argilla the API URL will be the same as the URL of your Argilla UI.\n\nTo get the OpenAI API credentials, please visit https://platform.openai.com/account/api-keys\n\nimport os\n\nos.environ[\"ARGILLA_API_URL\"] = \"...\"\nos.environ[\"ARGILLA_API_KEY\"] = \"...\"\n\nos.environ[\"OPENAI_API_KEY\"] = \"...\"\n\nSetup Argilla‚Äã\n\nTo use the ArgillaCallbackHandler we will need to create a new FeedbackDataset in Argilla to keep track of your LLM experiments. To do so, please use the following code:\n\nimport argilla as rg\n\nfrom packaging.version import parse as parse_version\n\nif parse_version(rg.__version__) < parse_version(\"1.8.0\"):\n    raise RuntimeError(\n        \"`FeedbackDataset` is only available in Argilla v1.8.0 or higher, please \"\n        \"upgrade `argilla` as `pip install argilla --upgrade`.\"\n    )\n\ndataset = rg.FeedbackDataset(\n    fields=[\n        rg.TextField(name=\"prompt\"),\n        rg.TextField(name=\"response\"),\n    ],\n    questions=[\n        rg.RatingQuestion(\n            name=\"response-rating\",\n            description=\"How would you rate the quality of the response?\",\n            values=[1, 2, 3, 4, 5],\n            required=True,\n        ),\n        rg.TextQuestion(\n            name=\"response-feedback\",\n            description=\"What feedback do you have for the response?\",\n            required=False,\n        ),\n    ],\n    guidelines=\"You're asked to rate the quality of the response and provide feedback.\",\n)\n\nrg.init(\n    api_url=os.environ[\"ARGILLA_API_URL\"],\n    api_key=os.environ[\"ARGILLA_API_KEY\"],\n)\n\ndataset.push_to_argilla(\"langchain-dataset\")\n\n\nüìå NOTE: at the moment, just the prompt-response pairs are supported as FeedbackDataset.fields, so the ArgillaCallbackHandler will just track the prompt i.e. the LLM input, and the response i.e. the LLM output.\n\nTracking‚Äã\n\nTo use the ArgillaCallbackHandler you can either use the following code, or just reproduce one of the examples presented in the following sections.\n\nfrom langchain.callbacks import ArgillaCallbackHandler\n\nargilla_callback = ArgillaCallbackHandler(\n    dataset_name=\"langchain-dataset\",\n    api_url=os.environ[\"ARGILLA_API_URL\"],\n    api_key=os.environ[\"ARGILLA_API_KEY\"],\n)\n\nScenario 1: Tracking an LLM‚Äã\n\nFirst, let's just run a single LLM a few times and capture the resulting prompt-response pairs in Argilla.\n\nfrom langchain.callbacks import ArgillaCallbackHandler, StdOutCallbackHandler\nfrom langchain.llms import OpenAI\n\nargilla_callback = ArgillaCallbackHandler(\n    dataset_name=\"langchain-dataset\",\n    api_url=os.environ[\"ARGILLA_API_URL\"],\n    api_key=os.environ[\"ARGILLA_API_KEY\"],\n)\ncallbacks = [StdOutCallbackHandler(), argilla_callback]\n\nllm = OpenAI(temperature=0.9, callbacks=callbacks)\nllm.generate([\"Tell me a joke\", \"Tell me a poem\"] * 3)\n\n    LLMResult(generations=[[Generation(text='\\n\\nQ: What did the fish say when he hit the wall? \\nA: Dam.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe Moon \\n\\nThe moon is high in the midnight sky,\\nSparkling like a star above.\\nThe night so peaceful, so serene,\\nFilling up the air with love.\\n\\nEver changing and renewing,\\nA never-ending light of grace.\\nThe moon remains a constant view,\\nA reminder of life‚Äôs gentle pace.\\n\\nThrough time and space it guides us on,\\nA never-fading beacon of hope.\\nThe moon shines down on us all,\\nAs it continues to rise and elope.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. What did one magnet say to the other magnet?\\nA. \"I find you very attractive!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\"\\n\\nThe world is charged with the grandeur of God.\\nIt will flame out, like shining from shook foil;\\nIt gathers to a greatness, like the ooze of oil\\nCrushed. Why do men then now not reck his rod?\\n\\nGenerations have trod, have trod, have trod;\\nAnd all is seared with trade; bleared, smeared with toil;\\nAnd wears man's smudge and shares man's smell: the soil\\nIs bare now, nor can foot feel, being shod.\\n\\nAnd for all this, nature is never spent;\\nThere lives the dearest freshness deep down things;\\nAnd though the last lights off the black West went\\nOh, morning, at the brown brink eastward, springs ‚Äî\\n\\nBecause the Holy Ghost over the bent\\nWorld broods with warm breast and with ah! bright wings.\\n\\n~Gerard Manley Hopkins\", generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ: What did one ocean say to the other ocean?\\nA: Nothing, they just waved.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\"\\n\\nA poem for you\\n\\nOn a field of green\\n\\nThe sky so blue\\n\\nA gentle breeze, the sun above\\n\\nA beautiful world, for us to love\\n\\nLife is a journey, full of surprise\\n\\nFull of joy and full of surprise\\n\\nBe brave and take small steps\\n\\nThe future will be revealed with depth\\n\\nIn the morning, when dawn arrives\\n\\nA fresh start, no reason to hide\\n\\nSomewhere down the road, there's a heart that beats\\n\\nBelieve in yourself, you'll always succeed.\", generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'completion_tokens': 504, 'total_tokens': 528, 'prompt_tokens': 24}, 'model_name': 'text-davinci-003'})\n\n\nScenario 2: Tracking an LLM in a chain‚Äã\n\nThen we can create a chain using a prompt template, and then track the initial prompt and the final response in Argilla.\n\nfrom langchain.callbacks import ArgillaCallbackHandler, StdOutCallbackHandler\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\nargilla_callback = ArgillaCallbackHandler(\n    dataset_name=\"langchain-dataset\",\n    api_url=os.environ[\"ARGILLA_API_URL\"],\n    api_key=os.environ[\"ARGILLA_API_KEY\"],\n)\ncallbacks = [StdOutCallbackHandler(), argilla_callback]\nllm = OpenAI(temperature=0.9, callbacks=callbacks)\n\ntemplate = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\nTitle: {title}\nPlaywright: This is a synopsis for the above play:\"\"\"\nprompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\nsynopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)\n\ntest_prompts = [{\"title\": \"Documentary about Bigfoot in Paris\"}]\nsynopsis_chain.apply(test_prompts)\n\n    \n    \n    > Entering new LLMChain chain...\n    Prompt after formatting:\n    You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n    Title: Documentary about Bigfoot in Paris\n    Playwright: This is a synopsis for the above play:\n    \n    > Finished chain.\n\n\n\n\n\n    [{'text': \"\\n\\nDocumentary about Bigfoot in Paris focuses on the story of a documentary filmmaker and their search for evidence of the legendary Bigfoot creature in the city of Paris. The play follows the filmmaker as they explore the city, meeting people from all walks of life who have had encounters with the mysterious creature. Through their conversations, the filmmaker unravels the story of Bigfoot and finds out the truth about the creature's presence in Paris. As the story progresses, the filmmaker learns more and more about the mysterious creature, as well as the different perspectives of the people living in the city, and what they think of the creature. In the end, the filmmaker's findings lead them to some surprising and heartwarming conclusions about the creature's existence and the importance it holds in the lives of the people in Paris.\"}]\n\n\nScenario 3: Using an Agent with Tools‚Äã\n\nFinally, as a more advanced workflow, you can create an agent that uses some tools. So that ArgillaCallbackHandler will keep track of the input and the output, but not about the intermediate steps/thoughts, so that given a prompt we log the original prompt and the final response to that given prompt.\n\nNote that for this scenario we'll be using Google Search API (Serp API) so you will need to both install google-search-results as pip install google-search-results, and to set the Serp API Key as os.environ[\"SERPAPI_API_KEY\"] = \"...\" (you can find it at https://serpapi.com/dashboard), otherwise the example below won't work.\n\nfrom langchain.agents import AgentType, initialize_agent, load_tools\nfrom langchain.callbacks import ArgillaCallbackHandler, StdOutCallbackHandler\nfrom langchain.llms import OpenAI\n\nargilla_callback = ArgillaCallbackHandler(\n    dataset_name=\"langchain-dataset\",\n    api_url=os.environ[\"ARGILLA_API_URL\"],\n    api_key=os.environ[\"ARGILLA_API_KEY\"],\n)\ncallbacks = [StdOutCallbackHandler(), argilla_callback]\nllm = OpenAI(temperature=0.9, callbacks=callbacks)\n\ntools = load_tools([\"serpapi\"], llm=llm, callbacks=callbacks)\nagent = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    callbacks=callbacks,\n)\nagent.run(\"Who was the first president of the United States of America?\")\n\n    \n    \n    > Entering new AgentExecutor chain...\n     I need to answer a historical question\n    Action: Search\n    Action Input: \"who was the first president of the United States of America\" \n    Observation: George Washington\n    Thought: George Washington was the first president\n    Final Answer: George Washington was the first president of the United States of America.\n    \n    > Finished chain.\n\n\n\n\n\n    'George Washington was the first president of the United States of America.'\n\n\nPrevious\nCallbacks\nNext\nConfident"
}